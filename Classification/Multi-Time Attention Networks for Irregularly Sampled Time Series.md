# Multi-Time Attention Networks for Irregularly Sampled Time Series

### 1. 핵심 주장과 주요 기여 요약[1]

**Multi-Time Attention Networks (mTANs)**는 비정상적으로 샘플링된(irregularly sampled) 다변량 시계열 데이터를 처리하기 위한 새로운 딥러닝 프레임워크입니다. 이 논문의 세 가지 주요 기여는 다음과 같습니다:[1]

(1) **학습 가능한 시간 어텐션 메커니즘**: 고정된 커널 함수 대신 데이터로부터 시간적 유사도를 학습하는 유연한 방식을 제공합니다. 이는 이전의 보간 기반 모델(예: Shukla & Marlin, 2019)보다 표현력이 우수합니다.

(2) **시간적으로 분포된 잠재 표현(temporally distributed latent representation)**: 시계열 데이터의 국소 구조(local structure)를 더 잘 포착하기 위해 단일 시점이 아닌 여러 참조 시점(reference points)에서 잠재 표현을 유지합니다.

(3) **높은 성능과 효율성**: 최신 방법들과 동등하거나 우수한 보간(interpolation) 및 분류(classification) 성능을 제공하면서 훈련 시간을 **85~100배 단축**합니다.

---

### 2. 문제 정의, 제안 방법, 모델 구조 및 성능[1]

#### 2.1 해결하고자 하는 문제[1]

비정상적으로 샘플링된 시계열 데이터는 의료(전자의료기록), 기후 과학, 생태학, 천문학 등 다양한 분야에서 발생합니다. 이러한 데이터는 두 가지 근본적인 문제를 야기합니다:

- **시간 축의 불규칙성**: 관측 시점들 사이의 간격이 일정하지 않음
- **다변량 정렬 부재**: 서로 다른 변수가 서로 다른 시점에 관측됨

기존의 RNN 기반 방법들은 규칙적인 시간 간격을 가정하며, 벡터의 일부만 관측되는 경우를 직접 처리하지 못합니다.

#### 2.2 제안하는 방법 (수식 포함)[1]

**시간 임베딩(Time Embedding)**:

mTAN은 연속 시간 점 $$t$$를 고차원 공간으로 임베딩하기 위해 H개의 임베딩 함수를 사용합니다:[1]

$$
\phi_h(t)[i] = \begin{cases}
\omega_0^h \cdot t + \alpha_0^h, & \text{if } i = 0 \\
\sin(\omega_i^h \cdot t + \alpha_i^h), & \text{if } 0 < i < d_r
\end{cases}
$$

여기서 $$\omega_i^h$$와 $$\alpha_i^h$$는 학습 가능한 주파수와 위상 매개변수입니다. 선형 항은 비주기적 패턴을, 주기 항은 시계열의 주기성을 포착합니다.

**Multi-Time Attention 메커니즘**:[1]

쿼리 시점 $$t$$에서의 임베딩 $$\hat{x}_{hd}(t, s)$$는 다음과 같이 정의됩니다:

$$
\hat{x}_{hd}(t, s) = \sum_{i=1}^{L_d} \kappa_h(t, t_i^d) x_i^d
$$

여기서 어텐션 가중치 $$\kappa_h(t, t_i^d)$$는:

$$
\kappa_h(t, t_i^d) = \frac{\exp\left(\phi_h(t)w v^T \phi_h(t_i^d)^T / \sqrt{d_k}\right)}{\sum_{i'=1}^{L_d} \exp\left(\phi_h(t)w v^T \phi_h(t_{i'}^d)^T / \sqrt{d_k}\right)}
$$

**전체 mTAN 출력**:

차원 j의 최종 임베딩은:

$$
\text{mTAN}(t, s)[j] = \sum_{h=1}^{H} \sum_{d=1}^{D} \hat{x}_{hd}(t, s) \cdot U_{hdj}
$$

이는 여러 시간 임베딩과 데이터 차원에 걸친 학습된 선형 조합입니다.

#### 2.3 모델 구조[1]

논문은 **인코더-디코더 기반 변분 자동인코더(VAE) 프레임워크**를 제안합니다:

**디코더(생성 과정)**:
- 잠재 상태 $$z_k \sim p(z_k)$$에서 시작
- RNN 디코더로 처리: $$h_{RNN}^{dec} = \text{RNN}^{dec}(z)$$
- mTAND 모듈을 통한 보간: $$h_{TAN}^{dec} = \text{mTAND}^{dec}(t, h_{RNN}^{dec})$$
- 완전 연결 디코더로 최종 출력 생성: $$x_{id} \sim \mathcal{N}(f^{dec}(h_{i,TAN}^{dec})[d], \sigma^2)$$

**인코더(추론 네트워크)**:
- 입력 시계열을 mTAND 모듈에 통과: $$h_{TAN}^{enc} = \text{mTAND}^{enc}(r, s)$$
- RNN 인코더로 처리: $$h_{RNN}^{enc} = \text{RNN}^{enc}(h_{TAN}^{enc})$$
- 각 참조 시점에서 가우시안 분포 생성: $$z_k \sim q_\gamma(z_k | \mu_k, \sigma_k^2)$$

#### 2.4 학습 목표[1]

정규화된 ELBO(Evidence Lower Bound)를 최대화합니다:

$$
L_{NVAE}(\theta, \gamma) = \sum_{n=1}^{N} \frac{1}{\sum_d L_d^n} \left[\mathbb{E}_{q_\gamma(z|r,s_n)}[\log p_\theta(x_n|z, t_n)] - D_{KL}(q_\gamma(z|r,s_n)||p(z))\right]
$$

분류 작업의 경우, 감독 항이 추가됩니다:

$$
L_{supervised}(\theta, \gamma, \delta) = L_{NVAE}(\theta, \gamma) + \lambda \mathbb{E}_{q_\gamma(z|r,s_n)}[\log p_\delta(y_n|z)]
$$

#### 2.5 성능 결과[1]

**PhysioNet 보간 작업(Table 1)**:
- mTAND-Full은 모든 관측 비율(50%-90%)에서 기존 방법들을 크게 능가
- 50% 관측: mTAND-Full = 4.139 (vs. L-ODE-ODE = 6.721, RNN-VAE = 13.418)
- **4.18-3.25배 성능 향상**

**PhysioNet 분류(Table 2)**:
- mTAND-Full AUC: 0.858 ± 0.004 (vs. ODE-RNN = 0.833, L-ODE-ODE = 0.829)
- **훈련 시간**: 0.2분/epoch (vs. ODE-RNN = 16.5분, L-ODE-ODE = 22분)
- **85~100배 더 빠름**

**MIMIC-III 분류**:
- mTAND-Full AUC: 0.8544 (ODE-RNN과 통계적으로 유의미한 차이 없음)
- 하지만 훈련 속도에서 현저히 우수

**Human Activity 분류**:
- mTAND 기반 정확도: 0.910 (vs. ODE-RNN = 0.885, IP-Nets = 0.869)

***

### 3. 모델의 일반화 성능 향상 가능성 (중점)[1]

#### 3.1 일반화 설계 원리[1]

**시간적으로 분산된 표현의 장점**:

논문은 합성 데이터 실험(부록 A.2)을 통해 mTANS가 단일 시점 잠재 표현(latent ODE)보다 국소 구조를 더 잘 포착함을 시연합니다. Figure 3의 시각화에서 mTANS의 보간이 Latent ODE보다 세밀한 세부 사항을 유지합니다.

**학습 가능한 시간 커널의 이점**:

표 3의 절제 연구(ablation study)에서:
- PhysioNet에서 학습된 시간 임베딩 vs. 고정 위치 인코딩: **0.845 → 0.858 (1.5% 향상)**
- MIMIC-III: **0.843 → 0.854 (1.3% 향상)**

고정 RBF 커널 vs. 학습된 유사도 커널(표 4):
- PhysioNet: 0.819 → 0.854 (**4.3% 향상**)
- Human Activity: 0.869 → 0.907 (**4.4% 향상**)

#### 3.2 정규화 메커니즘[1]

**ELBO 정규화**: 비정상 샘플링 시계열의 불균형을 완화하기 위해 각 데이터 케이스의 총 관측값 수로 정규화합니다. 이는 길이가 긴 시계열에 모델이 과도하게 집중되는 것을 방지합니다.

**KL 어닐링**: PhysioNet 실험에서 KL 디버전스 가중치를 0.99 계수로 감소시키면 성능이 향상됩니다.

#### 3.3 다양한 데이터 구조에 대한 견고성[1]

- **부분 관측 벡터 처리**: 각 시점에서 서로 다른 차원만 관측되는 경우를 직접 처리하여 별도의 imputation 단계가 불필요
- **계산 효율성**: 마스킹을 통한 병렬화 가능으로 GPU에서 효율적 구현
- **참조 점 적응성**: $$\rho(s)$$ 함수로 데이터 자체에 따라 참조 시점을 동적 선택 가능

#### 3.4 일반화 성능의 한계 요인[1]

**고정 분산 가정**: 디코더가 고정 분산 $$\sigma^2 = 0.01$$을 사용하여 이질성(heteroscedasticity) 있는 데이터에 제한적

**참조 점 선택의 민감도**: 분류 작업에서 128개 고정 참조 점을 사용하지만, 최적값이 데이터마다 다를 수 있음

**MIMIC-III에서의 경미한 성능**: ODE 기반 모델과 유사한 성능으로, 매우 긴 시계열이나 복잡한 동역학에서의 우수성 미검증

---

### 4. 앞으로의 연구에 미치는 영향과 고려사항[1]

#### 4.1 연구에 미치는 영향[1]

**범용 인터페이스로서의 mTAN 모듈**:

논문 저자들은 mTAN 모듈이 VAE 외의 다양한 신경망 아키텍처(GAN, CNN 등)와 결합 가능하다고 강조합니다. 이는 비정상 샘플링 시계열 처리의 새로운 패러다임을 제시합니다.

**의료 영상 분석으로의 확장**:

본 모델이 해결하는 전자의료기록의 희소성과 비정상 샘플링 문제는 다음 분야로 확대될 수 있습니다:
- 생리 신호 모니터링
- 질병 진행 모델링
- 환자 이상 감지

**효율성-성능 트레이드오프 재정의**:

ODE 기반 모델(Neural ODE, Latent ODE)이 주류였던 시대에서, mTANS는 **85-100배 빠른 훈련과 비교 가능한 또는 우수한 성능**을 제시하여 실무 배포 가능성을 높입니다.

#### 4.2 앞으로 연구 시 고려할 점[1]

**1) 분산 추정 개선**:
- 고정 분산 대신 데이터 의존적 분산 학습
- 이질분산(heteroscedastic) 출력 분포 도입

**2) 시간 임베딩의 해석성**:
- 학습된 주파수 $$\omega_i^h$$의 물리적 의미 분석
- 도메인별 사전(prior) 정보 통합 가능성

**3) 장기 의존성 모델링**:
- 현재 모델은 상대적으로 단기 국소 구조에 집중
- 트랜스포머 기반 아키텍처와의 비교

**4) 부분 관측 메커니즘 명시화**:
- 부재가 무작위(MCAR)인지, 시스템적(MNAR)인지에 따른 영향 분석
- 선택 편향(selection bias) 완화 방법 개발

**5) 외분(extrapolation) 능력 평가**:
- 현재는 보간(interpolation)에 중점, 예측(forecasting) 성능 평가 필요
- 불확실성 정량화 개선

**6) 참조 점 최적화**:
- 적응형 참조 점 선택 메커니즘
- 계산 복잡도와 표현력의 균형

**7) 도메인 적응(domain adaptation)**:
- 의료 데이터로 사전학습된 모델을 다른 도메인(기후, 생태)으로 전이 가능성
- 적은 데이터 영역(few-shot)에서의 성능

**8) 확장성 검증**:
- 초고차원(extremely high-dimensional) 데이터에 대한 성능
- 대규모 배치 처리 시 메모리 효율성

***

### 종합 평가

**Multi-Time Attention Networks**는 비정상 샘플링 시계열 처리의 중요한 진전을 나타냅니다. 특히:

✓ **기술적 혁신**: 학습 가능한 시간 어텐션과 시간적으로 분산된 표현의 조합은 새로운 개념
✓ **실용적 효율성**: 85-100배 빠른 훈련은 대규모 의료 데이터 응용에 중대
✓ **포괄성**: 부분 관측 벡터를 직접 처리하여 실제 데이터 특성 반영
✓ **견고한 평가**: 3개 데이터셋, 보간과 분류 작업, 광범위한 절제 연구

하지만 향후 연구는 **장기 의존성 모델링**, **확률적 불확실성 정량화**, **도메인 일반화** 측면에서의 개선에 집중해야 합니다. 이는 임상 의사결정, 환경 모니터링 등 고위험 응용에서 모델의 신뢰성과 해석성을 크게 향상시킬 것입니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/882bf562-ecc3-4f00-b891-48cac92fd499/2101.10318v2.pdf)
