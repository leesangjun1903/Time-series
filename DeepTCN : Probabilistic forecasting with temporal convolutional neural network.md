# Probabilistic forecasting with temporal convolutional neural network

## 핵심 주장과 주요 기여

이 논문은 다중 관련 시계열의 확률적 예측을 위한 **Deep Temporal Convolutional Network (DeepTCN)** 프레임워크를 제안합니다. 주요 기여는 다음과 같습니다:[1]

- **CNN 기반 확률적 예측 프레임워크**: 매개변수적(parametric)과 비매개변수적(non-parametric) 접근 방식을 모두 지원하는 확률 밀도 추정 프레임워크 제안[1]
- **높은 확장성과 확장성**: 시계열 간 잠재 상관관계 학습 및 데이터 희소성, 콜드 스타트 상황을 포함한 복잡한 실제 예측 상황 처리 능력[1]
- **외생 변수 통합**: 프로모션 계획이나 날씨 예보와 같은 외생 공변량을 유연하게 포함할 수 있는 모델[1]
- **우수한 성능**: 점 예측과 확률적 예측 작업 모두에서 최첨단 방법들과 비교하여 우수한 성능 달성[1]

## 해결하고자 하는 문제와 제안 방법

### 문제 정의
전통적인 자기회귀 생성 모델들은 다음과 같은 한계를 가집니다:

**기존 접근 방식의 문제점:**
- 순차적 예측으로 인한 오차 누적
- 훈련 및 예측 단계에서의 효율성 문제
- 수천 또는 수백만 개의 관련 시계열 처리 시 계산 자원 문제[1]

### 제안 방법

**1. 직접 예측 전략**
기존의 자기회귀 방식:

$$P(y_{(t+1):(t+τ)} | y_{1:t}) = \prod_{ω=1}^{τ} p(y_{t+ω} | y_{1:t+ω-1})$$

제안하는 직접 예측 방식:

$$P(y_{(t+1):(t+τ)} | y_{1:t}) = \prod_{ω=1}^{τ} p(y_{t+ω} | y_{1:t})$$

**2. 외생 변수를 포함한 확장**

$$P(y_{(t+1):(t+τ)} | y_{1:t}) = \prod_{ω=1}^{τ} p(y_{t+ω} | y_{1:t}, X^{(i)}_{t+ω}, i = 1, ..., N)$$

여기서 $X^{(i)}_{t+ω}$는 미래의 공변량을 나타냅니다.[1]

## 모델 구조

### 전체 아키텍처
DeepTCN은 **Encoder-Decoder** 구조를 채택합니다:

**1. 인코더: 확장된 인과 합성곱(Dilated Causal Convolutions)**
- 시간적 의존성 포착을 위한 스택된 잔여 블록
- 확장된 인과 합성곱의 출력:

$$s(t) = (x *\_d w)(t) = \sum_{k=0}^{K-1} w(k)x(t - d \cdot k)$$

여기서 $d$는 확장 인수, $K$는 커널 크기입니다.[1]

**2. 디코더: 잔여 신경망 변형(ResNet-V)**
동적 회귀 모델에서 영감을 받은 구조:

$$δ^{(i)}\_{t+ω} = R(X^{(i)}_{t+ω}) + h^{(i)}_t$$

여기서 $h^{(i)}_t$는 인코더의 잠재 출력, $R(·)$는 전달 함수 역할을 하는 비선형 함수입니다.[1]

### 확률적 예측 프레임워크

**1. 매개변수적 접근 방식**
가우시안 분포 가정 하에:

$$P(y^{(i)}\_{t+ω}) \sim G(μ^{(i)}\_{t+ω}, σ^{(i)}_{t+ω})$$

손실 함수:

$$L_G = \frac{1}{2}\log(2π) + \log(σ) + \frac{(y-μ)^2}{2σ^2}$$

**2. 비매개변수적 접근 방식**
분위수 회귀 기반:

```math
L_q(y, \hat{y}_q) = q(y - \hat{y}_q)_+ + (1-q)(\hat{y}_q - y)_+
```

여기서 $(y)_+ = \max(0, y)$이고 $q ∈ (0,1)$ 입니다.[1]

## 성능 향상 및 한계

### 성능 향상
**1. JD.com 데이터셋 결과**
- JD-demand와 JD-shipment 데이터셋에서 SARIMA와 lightGBM 대비 우수한 성능
- 특히 역사적 쇼핑 축제 데이터가 없는 Short-series에서 현저한 성능 향상[1]

**2. 공개 데이터셋 결과**
- Traffic 데이터셋: QL50/QL90에서 0.058/0.040으로 최고 성능
- Parts 데이터셋: QL50/QL90에서 0.533/0.462로 우수한 성능[1]

**3. 콜드 스타트 상황 처리**
- 새로운 제품이나 창고와 같은 콜드 스타트 상황에서도 다른 유사한 시계열로부터 학습하여 효과적인 예측 수행[1]

### 한계점
- **분포 가정의 제약**: 매개변수적 접근에서 특정 확률 분포 가정 필요
- **하이퍼파라미터 민감성**: 확장 인수, 커널 크기 등의 설정에 따른 성능 변화
- **계산 복잡성**: 대규모 시계열에서의 메모리 및 계산 요구사항

## 모델의 일반화 성능 향상

### 표현 학습을 통한 일반화
**1. 임베딩 학습**
- Product_id, day-of-week 등의 범주형 변수를 밀집 벡터로 매핑
- 시계열 간 유사 패턴 학습을 통한 예측 정확도 향상[1]

**2. 교차 학습 능력**
- 관련 시계열 간의 패턴 공유 학습
- 역사적 데이터가 부족한 시계열의 예측 성능 향상[1]

**3. 계절성 및 외부 요인 처리**
- Hour-of-day, day-of-week, 휴일 지시자 등을 통한 계절성 포착
- 쇼핑 축제("11.11")와 같은 특별 이벤트 효과 학습[1]

### 민감도 분석 결과
5, 6, 7층 인코더 아키텍처 비교에서:
- 5층보다 6, 7층에서 더 나은 성능
- 6층과 7층 간의 성능 차이는 미미하여 모델의 매개변수에 대한 강건성 확인[1]

## 향후 연구에 미치는 영향과 고려사항

### 학술적 영향
**1. CNN 기반 시계열 예측의 새로운 패러다임**
- RNN 기반 모델의 한계를 극복하는 효율적인 대안 제시
- 병렬 처리 가능한 비자기회귀 모델의 효과성 입증

**2. 다중 시계열 예측 방법론 발전**
- 시계열 간 상관관계 활용의 중요성 강조
- 콜드 스타트 문제 해결을 위한 새로운 접근법 제시

### 향후 연구 고려사항

**1. 모델 확장성**
- 더 복잡한 시계열 패턴을 위한 아키텍처 개선
- 다양한 확률 분포에 대한 매개변수적 접근 확장

**2. 실시간 적용성**
- 온라인 학습 및 적응적 업데이트 메커니즘 개발
- 대규모 시계열에서의 효율적인 추론 방법 연구

**3. 해석가능성 향상**
- 모델의 의사결정 과정에 대한 해석 가능성 개선
- 예측 불확실성의 원인 분석 도구 개발

**4. 도메인 특화 최적화**
- 특정 도메인(금융, 에너지, 소매 등)에 특화된 모델 변형 연구
- 도메인 지식 통합을 위한 방법론 개발

이 연구는 시계열 예측 분야에서 CNN 기반 접근법의 가능성을 보여주며, 특히 다중 시계열 환경에서의 확률적 예측 방법론 발전에 중요한 기여를 하고 있습니다.

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/9ab7e6b6-ae0e-4a5e-a2c6-c99fc88ff6ea/1-s2.0-S0925231220303441-main.pdf
