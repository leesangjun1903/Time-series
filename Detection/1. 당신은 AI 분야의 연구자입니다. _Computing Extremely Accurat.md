<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" style="height:64px;margin-right:32px"/>

# 1. 당신은 AI 분야의 연구자입니다. "Computing Extremely Accurate Quantiles Using t-Digests"의 핵심 주장과 주요 기여를 간결하게 요약하세요.

2. 이 논문이 "해결하고자 하는 문제, 제안하는 방법(수식 포함), 모델 구조, 성능 향상 및 한계"를 중심으로 자세하게 설명하세요.
3.특히 "모델의 일반화 성능 향상 가능성"과 관련된 내용을 중점적으로 다뤄 주세요.
4.요약 후에는 "해당 논문이 앞으로의 연구에 미치는 영향과 앞으로 연구 시 고려할 점"도 자세히 기술해 주세요.
“2020년 이후 관련 최신 연구 비교 분석”
수식을 LaTeX 코드로 답변 형식을 맞춰주고, LaTeX 렌더링을 위해 마크다운에 달러 기호를 사용해 주세요.
3. 핵심 주장과 주요 기여 (간결 요약)

- 이 논문은 스트리밍 환경에서 **극단 분위수(예: 99.9%, 99.99%)까지 상대오차 기준으로 매우 정확하게** 추정할 수 있는 소형 스케치 자료구조 t‑digest를 제안한다.[^1_1][^1_2]
- t‑digest는 실수값 스트림을 1차원 클러스터(centroid)로 압축하되, 분포의 꼬리(tail) 근처일수록 클러스터를 더 작게 만들어 $q$ 근처에서의 오차를 $q(1-q)$에 비례해 억제한다.[^1_1]
- 기존 Q‑digest 등과 비교해 같은 메모리일 때 tail 분위수에서 몇 자릿수 이상 더 정확하며, 병렬/분산 환경에서 독립 스케치를 무손실에 가깝게 병합할 수 있다.[^1_3][^1_1]

***

## 2. 논문이 다루는 문제, 제안 방법, 구조, 성능 및 한계

### 2.1 해결하고자 하는 문제

- 대규모 스트림에서 중위수, 95/99/99.9 분위수, trimmed mean 등 순위 기반 통계를 **온라인으로**, 그리고 **상수 크기 혹은 약한 증가 메모리**로 추정하는 문제를 다룬다.[^1_1]
- 기존 Greenwald–Khanna, Q‑digest, Munro–Paterson 계열 알고리즘은
    - tail에서의 **절대 오차**만 제어하고, 상대오차는 보장하지 못하며,[^1_1]
    - 값의 도메인이 정수/유한 범위에 묶이거나, 병렬 병합이 어렵거나, 많은 메모리를 요구한다.[^1_4][^1_1]
- 목표:

1) $q \to 0,1$ 근처에서도 $\max(q,1-q)$에 비례하는 상대오차,
2) 작은 스케치 크기(요약 메모리 $\Theta(\delta)$),
3) 스트리밍/병렬 환경에서 merge 가능(mergeable)한 구조를 동시에 달성.[^1_1]


### 2.2 제안 방법: t‑digest와 핵심 수식

#### 2.2.1 클러스터/센트로이드 기반 요약

- 입력 스트림 $X = \{x_1,\dots,x_n\} \subset \mathbb{R}$를 **분할(partition)** $\pi_i \subset X$로 나누고, 각 클러스터 $C_i$에 대해
    - weight(샘플 수) $|C_i|$,
    - 평균(centroid)

$$
\mu_i = \frac{1}{|C_i|}\sum_{x\in C_i} x
$$

를 유지한다.[^1_1]
- 클러스터들은 $\mu_i$ 기준으로 정렬되어 있고, 각 $C_i$에 대해 왼쪽/오른쪽 누적 weight

$$
W_{\text{left}}(C_i) = \sum_{j<i} |C_j|,\quad
W_{\text{right}}(C_i) = \sum_{j>i} |C_j|
$$

를 정의하여 해당 클러스터가 담당하는 **분위수 구간**을 표현한다.[^1_1]


#### 2.2.2 스케일 함수와 k‑size 제약

- t‑digest의 핵심은 각 클러스터의 “분위수 길이”를 **비선형 스케일 함수** $k(q)$로 제한하는 것이다.[^1_1]
- 한 클러스터 $C$에 해당하는 분위수 구간을

$$
q_{\text{left}} = \frac{W_{\text{left}}(C)}{n},\quad
q_{\text{right}} = q_{\text{left}} + \frac{|C|}{n}
$$

로 두면, k‑size는

$$
|C|_k = k(q_{\text{right}}) - k(q_{\text{left}})
$$

이고, t‑digest에서는 모든 다중 샘플 클러스터에 대해

$$
|C|_k \le 1
$$

이 되도록 강제한다.[^1_1]
- 대표적인 스케일 함수는 다음과 같다.[^1_1]

1. “아크사인” 형태 (기본형, $k_1$)

$$
k_1(q) = \frac{\delta}{2\pi}\sin^{-1}(2q - 1)
$$
2. 로그 기반 함수들 ($k_2, k_3$; tail에 더 강한 제약)

$$
k_2(q) = \frac{\delta}{4 \log n/\delta + 24}\log\frac{q}{1-q}
$$

$$
k_3(q) =
\frac{\delta}{4 \log n/\delta + 21}
\begin{cases}
\log(2q), & q \le 1/2\\[3pt]
-\log(2(1-q)), & q > 1/2
\end{cases}
$$
- 이 제약으로 인해 $q$가 0이나 1에 가까운 영역에서는 허용 가능한 $|C|$가 매우 작아지고, 중간 $q\approx 0.5$ 근처에서는 더 큰 $|C|$를 허용한다.[file:1]
- 이때 $\delta$는 **compression 파라미터**로, 클러스터 개수 $m$은 대략

$$
\frac{\delta}{2} \lesssim m \le \lceil \delta \rceil
$$

범위에 머물며 $n$과 거의 무관하다.[file:1][]


#### 2.2.3 두 가지 빌드 알고리즘

1) **Merging t‑digest (버퍼+병합)**[file:1]

- 크기 $c_1$인 버퍼에 샘플을 채운 뒤, 버퍼와 기존 centroids를 합쳐 정렬하고, 왼쪽에서 오른쪽으로 스캔하면서 k‑size 조건을 만족하는 범위 내에서 인접 centroids를 병합한다.[file:1]
- 병합 시, 현재까지의 누적 분위수 $q_0$와 상한 $q_{\text{limit}} = k^{-1}(k(q_0)+1)$를 사용해 새로운 클러스터에 더 샘플을 추가할 수 있는지 테스트한다.[file:1]
- 버퍼 크기와 $\delta$의 선택으로 **속도–정확도–메모리** 트레이드오프를 조절한다.[file:1]

2) **Clustering t‑digest (온라인 클러스터링)**[file:1]

- 새 샘플 $(x_n, w_n)$이 들어오면,
    - 거리 $|\mu_i - x_n|$가 최소인 centroids 집합을 찾고,
    - 거기에 $w_n$를 추가했을 때 $|C_i|_k \le 1$인 centroid만 남겨, 그 중 weight가 가장 큰 centroid에 병합하거나,
    - 없으면 새로운 centroid를 생성한다.[file:1]
- 클러스터 수가 $K\delta$ (예: $K\in[3,10]$)를 넘으면 한 번의 merge를 수행해 다시 압축한다.[file:1]


#### 2.2.4 CDF/분위수 추정(보간)

- 완전 병합된 t‑digest는 각 클러스터 내부의 **순서 정보**를 잃기 때문에, 분위수 계산 시 다음 가정을 사용해 CDF를 근사한다.[file:1]

1) 다중 샘플 클러스터에서는 절반은 centroid보다 왼쪽, 절반은 오른쪽에 있다고 본다.
2) 두 클러스터 사이의 샘플은 균일 분포로 가정한다.
- 두 다중 샘플 클러스터 $(\mu_i, w_i), (\mu_{i+1}, w_{i+1})$ 사이에서 $x$에 대한 CDF는 선형 보간으로 근사된다.[file:1]
- 싱글톤 클러스터( $w_i = 1$ )는 특정 위치에서 CDF가 한 번에 $1/n$만큼 점프하는 “계단”으로 처리해 tail에서의 정확도를 크게 높인다.[file:1]
- 첫/마지막 클러스터는, 특히 $k_1$ 사용 시 여러 샘플을 가질 수 있으므로, 가장 바깥쪽 샘플이 정확히 min/max에 있다는 사실을 이용해 외삽 보간을 개선한다.[file:1]


### 2.3 모델(자료구조) 구조

- **구성 요소**[file:1][]
    - 정렬된 centroid 리스트 $C = [(\mu_i, w_i)]_{i=1}^m$
    - 전체 샘플 수 $n = \sum_i w_i$
    - 스케일 함수 $k$, 역함수 $k^{-1}$, compression 파라미터 $\delta$
- 특성
    - **(약) 정렬성(weak ordering)**: 병합 및 온라인 빌드 과정에서 완전한 strict ordering은 약해질 수 있지만, 잘 설계된 stratified merge를 통해 인접 클러스터 간에서만 overlap이 발생하도록 제어한다.[file:1]
    - **Mergeability**: 서로 다른 스트림에서 만든 t‑digest들을 centroid 수준에서 합친 뒤, 다시 k‑size 제약을 만족하도록 병합하면 하나의 유효한 t‑digest가 된다.[file:1][]
    - **저장 형식**: centroid 값 간 차이를 single‑precision float로 저장하고, weight는 variable‑byte integer로 저장하는 식으로 약 500–1000 bytes에 10^5–10^6 샘플을 요약할 수 있다.[file:1]


### 2.4 성능 향상

#### 정밀도

- 실험에서 $n=10^6$, $\delta=100$, 균등분포 샘플에 대해 $k_1,k_2,k_3$ 모두
    - 절대오차는 $q\to 0,1$에서 ppm(10^-6) 수준으로 감소하고,[file:1]
    - $k_2,k_3$는 $q\le 0.001$ 구간에서 최대 절대오차가 한 자릿수 ppm 수준, 즉 10^-6~10^-5의 정확도를 보여준다.[file:1]
- 상대오차 측면에서 $k_2,k_3$는 $q\in[10^{-3},10^{-1}]$ 범위까지 상대오차를 잘 제어하지만, $q\approx 10^{-5}$ 근처에서는 상대오차가 일시적으로 증가하고, 그보다 작은 $q$에서는 대부분 싱글톤 클러스터로 바뀌어 오차가 다시 0에 수렴한다.[file:1]
- Q‑digest와 동일한 메모리(약 1 kB) 조건에서, t‑digest는 전체 $q$ 영역에서 절대오차가 1–2자릿수 이상 작고, 특히 tail에서는 3–5자릿수까지 더 정확하다.[file:1][]


#### 시간/메모리

- compress 파라미터 $\delta$에 대해 메모리 사용량은 $O(\delta)$이고, $\delta$ 증가에 따라 tail 정확도는 빠르게 개선된다.[file:1][]
- 버퍼+병합 방식에서 샘플당 평균 시간은 정렬 비용과 k‑평가 횟수에 의해

$$
O(\log c_1) + O(\delta / c_1)
$$

수준이며, 실험에서는 $c_1 \approx 10\delta$에서 좋은 타협점을 보인다.[file:1]
- 수억~수십억 샘플에서도 수백 ms 이내에 스케치를 구축할 수 있고, 병렬 환경(예: Hadoop, Druid, Spark, Redis, Druid, TimescaleDB 등)에 이미 널리 채택되어 있다.[file:1][][][]


### 2.5 한계

1. **이론적 최악 경우 보장 부재**
    - t‑digest는 경험적으로 매우 정확하지만, $\varepsilon n$ 수준의 worst‑case rank error에 대한 강한 이론 보장을 제공하지 않는다.[][]
    - 이후 연구들은 “t‑digest는 스케치 크기를 키워도 최악 경우 오차가 임의로 커질 수 있다”고 지적했다.[][][]
2. **정확도 분석의 경험 의존성**
    - 논문은 다양한 분포(균등, 지수, 스큐 데이터)에 대한 실험을 통해 정확도를 보이지만, 이론적 에러 상계는 부분적으로만 논의된다.[file:1][][]
3. **비정수/실수 전용**
    - Q‑digest는 정수 도메인에서 작동하는 반면, t‑digest는 실수 도메인에는 매우 일반적이지만, “어떤 순서집합이라도 평균 연산이 정의되면 적용 가능”이라는 수준에서 구현 복잡도가 증가할 수 있다.[file:1][]
4. **편향과 분포 가정**
    - 클러스터 내부/사이의 선형 보간 가정은 극단적으로 구조화된 분포에서 편향을 유발할 수 있다.[file:1][]

***

## 3. 일반화 성능(Generalization)과 관련된 논의

논문이 “일반화 성능”이라는 용어를 직접 사용하지는 않지만, 알고리즘이 **다양한 분포, 입력 순서, 시스템 구조에서 안정적으로 높은 정확도를 유지한다**는 의미에서의 일반화 가능성을 다음과 같이 읽을 수 있다.

### 3.1 분포 및 스큐에 대한 로버스트니스

- t‑digest는 값의 실제 분포에 따라 클러스터 크기가 자동 조절되며, 특히 tail 근처에서 클러스터 크기를 줄이는 k‑스케일링으로 **스큐된 분포나 heavy‑tail 분포에서 tail 분위수의 상대오차를 제어**한다.[file:1]
- 실험에서 지수분포, skewed 분포, 정렬/역정렬 입력 순서 등 다양한 스트림에서 유사한 tail 정확도를 보여, 특정 분포에 overfitting된 방식이 아니라 **분포 전반에서 안정적인 성능**을 보인다.[file:1][]


### 3.2 입력 순서 및 병합 구조에 대한 일반화

- 온라인 알고리즘 특성상 입력 순서가 매우 구조화되어 있을 수 있는데, 단순한 한 방향 merge만 사용할 경우 초기 클러스터가 비대칭적으로 성장해 weak ordering이 심해지고, 이것이 tail 오차를 키운다.[file:1]
- 논문은
    - merge 방향을 번갈아가며 처리하고,
    - stratified merging(임시로 더 큰 $\delta$로 클러스터를 쌓았다가 마지막에 다시 작은 $\delta$로 재병합) 전략을 사용해
다양한 입력 순서에서도 유사한 정확도를 얻도록 설계한다.[file:1]
- 이는 t‑digest라는 “모델”이 특정 스트림 패턴에 민감하기보다는, 구현 전략을 통해 **입력 순서에 대해 일반화된 동작**을 하도록 만든 것으로 해석할 수 있다.


### 3.3 분산/병렬 환경에서의 일반화

- t‑digest는 **mergeable sketch**이므로, 서로 다른 노드/파티션에서 각자 학습(?)된 스케치를 병합하여 전체 분포를 표현할 수 있다.[file:1][][]
- 논문은
    - 5, 20, 100 파티션으로 나누어 스케치를 만든 뒤 병합한 경우와
    - 단일 스트림에서 직접 만든 경우를 비교할 때, stratified merge를 쓰면 정확도 차이가 거의 없거나 오히려 병렬화가 accuracy를 개선할 수 있음을 보인다.[file:1]
- 이는 “각 파티션의 부분 분포가 달라도, 병합된 t‑digest가 전체 분포의 tail과 중앙 분위수를 안정적으로 표현”한다는 의미에서 **데이터 분할/분산 구조에 대한 일반화 성능**을 시사한다.


### 3.4 2020년 이후 후속·대체 기법과의 관점

- 2020년 이후 연구들은 t‑digest의 **실무적 성공은 인정하되, 이론적 일반화 보장(최악 경우 오차)이 부족하다**는 점을 지적하고, 이를 보완/대체하는 스케치를 제안한다.[][][][]
    - **UDDSketch** (2020)[][]
        - 지수적 binning과 동적 재배치를 사용해 tail 정밀도와 mergeability를 갖춘 로그-스케일 quantile sketch.
        - 실험적으로 t‑digest, DDSketch보다 우수하거나 비슷한 정확도와 속도를 보이며, 이론적 에러/크기 보장 제공.
    - **Worst-case comparison of relative error quantile algorithms** (Cormode et al., 2021 부류)[]
        - t‑digest와 ReqSketch를 비교하면서, t‑digest는 **상수 크기여도 최악 입력에서 상대오차가 임의로 커질 수 있음**을 보인다.
        - 반면 ReqSketch는 이론적 error bound를 가지지만, 어떤 분포에서는 실무 성능이 더 낫거나 비슷한 수준.
    - **Streaming quantiles with learned interpolation** (2023)[]
        - “학습된 보간(learned interpolation)”을 통해 KLL 기반 스케치가 실제 데이터에서 t‑digest 수준의 성능을 가지면서, $\varepsilon$-approximate worst-case 보장을 유지하도록 설계한다.
        - t‑digest가 보여준 “실제 데이터에서의 좋은 일반화 성능”을, 이론적으로 보강하려는 시도.
    - **KLL 개선 및 변형** (2022, sweep-compactor KLL)[]
        - KLL의 상수항을 줄이고 업데이트 시간을 향상시켜, 실무 정확도를 2배, 다른 알고리즘 대비 4배 이상 개선. 실험상 t‑digest와 비슷하거나 더 나은 정확도 및 이론적 보장을 동시에 지향.
    - **SplineSketch** (2024/2025)[][][]
        - 입력 구간을 동적으로 분할하고 각 구간에서 **단조 cubic spline**을 맞추는 방식으로,
            - t‑digest보다 2–20배 작은 오류(최대오차 기준으로는 두 자릿수 이상 개선)와
            - 균일하게 bounded rank error를 제공한다.
        - 실제 데이터에서는 t‑digest의 tail 정확도를 대부분 상회하면서, worst‑case error도 제한한다.
- 요약하면, t‑digest는 “많은 분포와 시스템 상황에 **경험적으로** 잘 일반화되는 실무 표준”이 되었고, 이후 연구는 **이 수준의 실무 성능 + 강한 일반화(최악 경우) 이론 보장**을 동시에 만족시키려는 방향으로 발전했다.[][][]

***

## 4. 향후 연구에 미치는 영향과 앞으로의 연구 고려 사항

### 4.1 영향

1. **실무 표준 스케치로의 채택**
    - t‑digest는 시간지연/지연시간(Latency) 모니터링, 분산 DB/TSDB(Elasticsearch, Druid, TimescaleDB, Redis, Lucene 등)에서 **사실상 표준 quantile sketch**로 채택되었다.[file:1][][][][]
    - 이는 “소형, mergeable, tail‑focused quantile sketch”라는 설계 패턴을 정립하여, 이후 모든 스트리밍 quantile 알고리즘들의 기준점(baseline)이 되었다.[][]
2. **tail‑중심 에러 목표와 스케일 함수 개념의 확산**
    - t‑digest의 스케일 함수 $k(q)$와 “k‑size ≤ 1” 제약은, tail 중심 에러 제어를 위한 일반적인 설계 도구로 자리 잡았고, 이후 UDDSketch, DDSketch, SplineSketch 등 다양한 스케치에서 비슷한 non‑uniform quantile 배분 아이디어가 사용된다.[file:1][][][]
3. **mergeable sketch + 분산 시스템 통합**
    - t‑digest의 병합 가능성과 작은 사이즈는 OLAP/streaming 시스템에서 **사전 스케치 후 질의 시 병합**이라는 패턴을 촉진했고, 이는 M4, Quancurrent 등 per‑flow 및 concurrent quantile 스케치 프레임워크에도 계승되었다.[file:1][][][]

### 4.2 향후 연구 시 고려할 점

1. **이론적 일반화(에러 보장)와 실무 성능의 동시 추구**
    - 새로운 알고리즘이나 t‑digest 변형을 설계할 때,
        - t‑digest‑급 tail 정확도와 작은 스케치 크기,
        - KLL/ReqSketch/UDDSketch/SplineSketch류의 worst‑case rank error 보장을 동시에 달성하는 것이 핵심 과제이다.[][][][]
    - 예:
        - 스케일 함수 $k(q)$와 클러스터링 규칙에 대해, rank error와 클러스터 수의 상계를 동시에 증명하고,
        - 실제 분포(heavy‑tail, multi‑modal, spikes)에 대한 보장형 에러 분석을 시도할 수 있다.
2. **학습 기반/적응형 스케일 함수와 보간**
    - 최근 “learned interpolation” 접근처럼, 분포 특성을 온라인으로 추정해
        - 스케일 함수 혹은 클러스터링 규칙을 데이터에 맞게 적응시키되,
        - 여전히 worst‑case 에러를 제한하는 프레임워크가 중요하다.[][]
    - t‑digest의 선형 보간을 spline, piecewise polynomial, 혹은 quantile regression 기반으로 교체하는 것도 한 방향이며, SplineSketch가 이를 구체화한 예다.[][][]
3. **동시성·다중 키(per‑key)·페더레이션 환경**
    - M4, MagnifierSketch 같은 per‑key quantile 프레임워크가 t‑digest, DDSketch, ReqSketch 등을 내부 모듈로 사용하고 있다.[][][]
    - 향후 연구에서는
        - per‑key 환경에서의 충돌/해시 노이즈가 quantile generalization에 미치는 영향,
        - 대규모 분산/페더레이션 환경에서 부분 스케치 병합 순서/토폴로지가 에러에 끼치는 영향을 이론적으로 분석할 필요가 있다.[][]
4. **정확도–자원–지연시간 사이의 시스템적 트레이드오프 모델링**
    - t‑digest 논문은 버퍼 크기, $\delta$, merge 빈도가 정확도, 속도, 메모리 사이의 3‑자 trade‑off를 형성함을 보여준다.[file:1]
    - 앞으로의 연구에서는
        - 주어진 SLA(예: tail latency 99.9‑percentile 오차 ≤ X, 쿼리 지연 ≤ Y ms) 하에서
        - 어떤 스케치/파라미터 조합이 최적인지,
        - workload‑adaptive configuration(동적으로 $\delta$, 버퍼, 스케일 함수 변경)을 설계하는 것이 중요하다.[][]
5. **어려운 입력에 대한 강건성 테스트와 실패 모드 분석**
    - 후속 연구는 t‑digest를 포함한 스케치들에 대해 “고의적으로 어려운” 입력(heavy spikes, adversarial order, 매우 좁은/bimodal 분포)을 설계해 worst‑case를 측정하고 있다.[][][][]
    - 새로운 알고리즘을 설계할 때는
        - 이런 입력 클래스에 대한 에러 상계 및 실험 평가,
        - 스케치가 “어디에서 실패하는지”를 명확히 규명하는 것이 일반화 성능 이해에 필수적이다.

요약하면, 이 논문은 **tail‑중심 상대오차 제어, 소형·mergeable sketch, 다양한 분포/입력/시스템에서의 높은 실무 일반화 성능**이라는 세 가지 축을 결합한 첫 대표적 작업이며, 이후 연구는 이를 기준선으로 삼아 **이론적 worst‑case 보장과 학습/적응적 설계**를 결합하는 방향으로 확장되고 있다.[file:1][][][]
<span style="display:none">[^1_10][^1_11][^1_12][^1_13][^1_14][^1_15][^1_16][^1_17][^1_18][^1_19][^1_20][^1_21][^1_22][^1_23][^1_24][^1_25][^1_26][^1_27][^1_28][^1_29][^1_30][^1_31][^1_32][^1_33][^1_34][^1_35][^1_36][^1_37][^1_38][^1_39][^1_40][^1_41][^1_42][^1_43][^1_44][^1_5][^1_6][^1_7][^1_8][^1_9]</span>

<div align="center">⁂</div>

[^1_1]: 1902.04023v1.pdf

[^1_2]: https://www.semanticscholar.org/paper/4bb034bbf8e6fa411645e7883176dc31bf5ccf66

[^1_3]: https://www.sciencedirect.com/science/article/pii/S2665963820300403

[^1_4]: https://arxiv.org/pdf/2001.06561.pdf

[^1_5]: https://arxiv.org/html/2504.01206v2

[^1_6]: https://arxiv.org/pdf/2102.09299.pdf

[^1_7]: https://arxiv.org/pdf/2404.03847.pdf

[^1_8]: https://arxiv.org/html/2511.22070v1

[^1_9]: https://www.arxiv.org/pdf/2511.22070.pdf

[^1_10]: https://arxiv.org/html/2509.24815v1

[^1_11]: https://arxiv.org/html/2504.01206v1

[^1_12]: https://arxiv.org/pdf/2504.01206.pdf

[^1_13]: https://arxiv.org/html/2510.07929v1

[^1_14]: https://arxiv.org/html/2505.06835v1

[^1_15]: https://arxiv.org/pdf/2004.08604.pdf

[^1_16]: https://arxiv.org/html/2602.10870v1

[^1_17]: https://arxiv.org/html/2507.19690v1

[^1_18]: https://arxiv.org/pdf/2211.04612.pdf

[^1_19]: https://ieeexplore.ieee.org/document/11015726/

[^1_20]: https://arxiv.org/abs/2304.07652

[^1_21]: https://ieeexplore.ieee.org/document/10597853/

[^1_22]: https://arxiv.org/abs/2504.01206

[^1_23]: https://link.springer.com/10.1007/s10614-023-10472-6

[^1_24]: https://arxiv.org/pdf/2101.06758.pdf

[^1_25]: http://arxiv.org/pdf/1903.09919.pdf

[^1_26]: https://pmc.ncbi.nlm.nih.gov/articles/PMC2818137/

[^1_27]: http://arxiv.org/pdf/1903.09921.pdf

[^1_28]: https://dl.acm.org/doi/pdf/10.1145/3639280

[^1_29]: https://pmc.ncbi.nlm.nih.gov/articles/PMC4317647/

[^1_30]: https://arxiv.org/pdf/2309.12667.pdf

[^1_31]: http://arxiv.org/pdf/2404.03847.pdf

[^1_32]: https://dl.acm.org/doi/10.1145/3709717

[^1_33]: https://datasketches.apache.org/docs/tdigest/tdigest.html

[^1_34]: https://github.com/timescale/timescaledb-toolkit/discussions/113

[^1_35]: https://druid.apache.org/docs/latest/development/extensions-contrib/tdigestsketch-quantiles/

[^1_36]: https://pmc.ncbi.nlm.nih.gov/articles/PMC9783260/

[^1_37]: https://github.com/spenczar/tdigest

[^1_38]: https://github.com/tdunning/t-digest

[^1_39]: http://arxiv.org/abs/2208.09265

[^1_40]: https://redis.io/docs/latest/develop/data-types/probabilistic/t-digest/

[^1_41]: https://cs.uwaterloo.ca/~kdaudjee/Daudjee_Sketches.pdf

[^1_42]: https://arxiv.org/abs/1902.04023

[^1_43]: https://redis.io/docs/latest/commands/tdigest.quantile/

[^1_44]: https://iditkeidar.com/wp-content/uploads/2023/01/QuancurrentThesis.pdf

