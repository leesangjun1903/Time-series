# Fast Unsupervised Online Drift Detection Using Incremental Kolmogorov-Smirnov Test
## 1. 핵심 주장과 주요 기여 (간결 요약)

- 스트림 데이터에서 반복적으로 Kolmogorov–Smirnov(KS) 검정을 수행하면 $O(N\log N)$ 비용 때문에 온라인 적용이 비효율적이라는 문제를 지적한다.[^1_1]
- Treap(랜덤화 이진 탐색 트리)와 lazy propagation을 이용해 “Incremental KS(IKS)”를 제안하여, 샘플의 삽입·삭제는 $O(\log N)$, KS 통계량 계산은 $O(1)$에 수행하는 알고리즘을 제시한다.[^1_1]
- 이 IKS를 활용해 **라벨 없이** 개념 드리프트를 감지하는 온라인 방법과, 드리프트 검출 후 소량의 라벨만 요청하는 모델 적응 전략(모델 교체, $\alpha/\beta$ 변환, Adaptree)을 제안한다.[^1_1]

***

## 2. 논문이 해결하고자 하는 문제

### 2.1 문제 정의: 라벨 부족·지연 하의 개념 드리프트

- 데이터 스트림은 시계열적으로 유입되며, 분포가 시간에 따라 변하는 개념 드리프트(concept drift)가 발생한다.[^1_1]
- 다수의 기존 스트림 분류 알고리즘은 “예측 직후 곧바로 모든 정답 라벨이 주어진다”는 비현실적인 가정을 두며, 실제 응용(전력 수요 예측, 주가 예측, 센서 기반 이벤트 인식 등)에서는 라벨 지연(verification latency) 또는 라벨 희소성이 일반적이다.[^1_1]
- 따라서, (1) **라벨 없이** 분포 변화를 감지하고, (2) 드리프트가 감지된 시점에만 **제한된 수의 라벨**을 요청해 모델을 갱신하는 방법이 필요하다.[^1_1]

이 논문은 KS 검정을 기반으로, 위 두 요구를 동시에 만족하는 **빠른 비모수 통계 기반의 드리프트 검출·적응 프레임워크**를 제안한다.[^1_1]

***

## 3. 제안 방법: Incremental KS와 드리프트 검출

### 3.1 표준 Kolmogorov–Smirnov(KS) 검정 정리

두 일변량 샘플 $A=\{a_i\}_{i=1}^n$, $B=\{b_j\}_{j=1}^m$ 이 주어졌을 때, 귀무가설

$$
H_0: A, B \text{는 동일 분포에서 생성됨}
$$

을 검정하기 위해 경험분포함수(empirical CDF)를

$$
F_C(x)=\frac{1}{|C|}\sum_{c\in C,\, c\le x} 1
$$

로 정의한다.[^1_1]

KS 통계량 $D$는

$$
D=\sup_x |F_A(x)-F_B(x)|=\max_{x\in A\cup B}|F_A(x)-F_B(x)|
$$

로 정의되며, 유의수준 $\alpha$에서

$$
D > c(\alpha)\sqrt{\frac{n+m}{nm}}
$$

이면 귀무가설을 기각하여 두 분포가 다르다고 판단한다.[^1_1]

표준 구현은 샘플 정렬이 필요하므로 $O((n+m)\log(n+m))$ 비용이 들며, 스트림에서 슬라이딩 윈도로 반복 수행하면 부담이 크다.[^1_1]

### 3.2 Incremental KS(IKS)의 핵심 아이디어와 수식

#### 3.2.1 $G(x)$ 변환과 $D$의 재표현

- 샘플의 크기 $|A|$, $|B|$가 항상 $|A|=r|B|$ (상수 $r$)를 만족한다고 가정한다(예: 같은 길이의 두 윈도우면 $r=1$).[^1_1]
- 아래와 같이 정수 누적 카운트 $F'_A, F'_B$를 정의한다.

$$
F'_A(x) = \sum_{a\in A,\, a\le x} 1,\quad
F'_B(x) = \sum_{b\in B,\, b\le x} r
$$
- 이때

$$
G(x)=F'_A(x)-F'_B(x)
$$

로 놓으면, KS 통계량은

$$
D=\frac{1}{|A|}\max\left(\max_{x\in A\cup B} G(x),\; -\min_{x\in A\cup B} G(x)\right)
  \tag{1}
$$

로 계산할 수 있다.[^1_1]

#### 3.2.2 Treap 기반 자료구조

- 모든 관측값 $o_i\in A\cup B$를 정렬된 순서 $o_1\le\cdots\le o_{|A|+|B|}$로 저장하고, 각 원소에 대응하는 $g_i=G(o_i)$를 유지한다.[^1_1]
- 새로운 관측값 $o_j$를 삽입할 때 이전 원소 $o_{j-1}$의 값 $g_{j-1}$에서 시작해
    - $o_j\in A$이면 $g_j=g_{j-1}+1$
    - $o_j\in B$이면 $g_j=g_{j-1}-r$
로 설정하고, 인덱스 $i>j$에 대해 모든 $g_i$에 위와 동일한 상수 $v\in\{1,-r\}$를 더한다.[^1_1]
- 삭제 시에는 반대로, 지워지는 위치 이후의 $g_i$에서 상수 $v$를 빼준다.[^1_1]

이 연산을 효율적으로 구현하기 위해,

- 키: 관측값(피처 값)
- 값: $g_i$
- 우선순위: 난수

로 Treap(카르테시안 트리) 구조를 사용하고,

- Merge, Split, SplitFirst, SplitLast, IncreaseBy(서브트리 전체에 상수 더하기) 연산을 lazy propagation으로 지원한다.[^1_1]

이때

- 삽입·삭제: $O(\log N)$ (높이가 로그 성장하는 randomized BST 특성)[^1_1]
- 서브트리 $g_i$의 최소/최대값은 루트에 캐시되므로 업데이트 후 $O(1)$ 조회 가능 → 식 (1)에 따라 $D$는 $O(1)$.[^1_1]


#### 3.2.3 KS 테스트 절차 (Incremental 버전)

- IKS에서 KS 테스트 함수는

$$
D = \frac{\max(\text{Treap.Max}, -\text{Treap.Min})}{|A|}
$$

$$
\text{threshold} = c(\alpha)\sqrt{\frac{n+m}{nm}}
$$

$$
D > \text{threshold} \Rightarrow H_0 \text{ 기각(드리프트 감지)}
$$

와 같이 구현된다.[^1_1]

#### 3.2.4 $|A|=r|B|$ 제약과 워크어라운드

- 제약: IKS는 $|A|=r|B|$ (상수 $r$)일 때 표준 KS와 동일한 $D$를 보장한다.[^1_1]
- 스트림 설정에서 일반적으로 두 슬라이딩 윈도우 크기를 동일하게 두므로 $r=1$이면 제약이 자연스럽게 만족된다.[^1_1]
- 한 윈도우가 고정되고 다른 쪽이 증가할 때 $m=kn$인 시점마다 표준 KS와 완전히 일치하고, 인접 $k$ 사이에는 근사 오차가 점점 작아진다고 논의한다.[^1_1]
- $|A|\neq |B|$인 경우에는 샘플 중복(예: $m=2n$일 때 $A$를 두 번 삽입)으로 $|A|=|B|$를 맞추면 KS 통계량과临계값이 그대로 유지되는 점을 활용하라고 제안한다.[^1_1]


### 3.3 드리프트 검출 및 모델 구조

#### 3.3.1 참조 윈도우 vs 현재 윈도우

각 피처 $X_d$에 대해 다음 두 샘플을 유지한다.[^1_1]

- **Reference set**: 현재 분류 모델을 학습하는 데 사용된 $W$개의 과거 인스턴스의 해당 피처 값 (고정).
- **Current set**: 스트림에서 가장 최근 $W$개의 인스턴스의 피처 값으로 이루어진 슬라이딩 윈도우 (계속 갱신).

각 새 인스턴스가 도착·분류될 때마다,

- 현재 윈도우를 업데이트(삽입·삭제)하고 각 피처별로 IKS를 수행하여 reference vs current의 분포 차이를 검정한다.[^1_1]
- 귀무가설이 기각되면 그 피처에서 **드리프트 발생**으로 판단한다.[^1_1]

확률 추정이 가능한 분류기(예: Naive Bayes)를 사용하는 경우,

- **피처 공간 대신 출력 확률(클래스 posterior)**에 대해서도 동일한 구조로 reference/current 집합을 구성하고 KS 검정을 적용할 수 있다.[^1_1]


#### 3.3.2 모델 구조 및 적응 전략

베이스 분류기로 1-NN, Naive Bayes, Decision Tree를 사용하고, 드리프트 감지 후 3가지 적응 메커니즘을 제안한다.[^1_1]

1. **Model Replacement (MR)**
    - 어떤 피처에서든 드리프트가 감지되면,
        - 현재 윈도우의 인스턴스에 대한 **정답 라벨을 요청**하고,
        - 그 $W$개로 새 모델을 학습한 뒤 reference set을 현재 윈도우로 갱신한다.[^1_1]
    - 모든 피처에 대해 동일한 window 기반 “리셋·재학습”을 수행하는 구조이다.
2. **$\alpha/\beta$ Transformation (AB)**
    - 드리프트를 유발한 특정 피처 $X_d$에 대해, reference set의 평균·표준편차를 current set의 통계량에 맞도록 선형 변환

$$
x' = \alpha x + \beta
$$

로 조정한다.[^1_1]
    - 변환된 reference와 current가 다시 KS로 “동일 분포”로 판정되면, 변환된 reference 데이터로 **모델 재학습**을 수행한다(추가 라벨 요청 없음).[^1_1]
    - KS가 여전히 차이를 보고하면 MR로 fallback.[^1_1]
    - 기본 가정은 “드리프트가 평균·분산 변화(단조/모노토닉 형태)로 근사 가능하다”는 것이다.[^1_1]
3. **Adaptree (AT)**
    - 결정트리 전용 적응 전략.[^1_1]
    - 트리의 각 내부 노드가 사용하는 피처에 대해 별도의 reference set을 유지한다.[^1_1]
    - 특정 피처에서 드리프트가 감지되면,
        - **그 피처를 사용해 분기하는 노드에 도달하는 인스턴스에 대해서만 라벨을 요청**하고,[^1_1]
        - 그 피처의 reference set을 현재 윈도우 값으로 업데이트한 뒤 서브트리를 재학습한다.[^1_1]
    - 상위 노드의 reference set은 그대로 두어, 트리의 일부만 국소적으로 적응하도록 설계한다.[^1_1]

비교를 위해 Zliobaite(2010)의 “두 개의 연속 슬라이딩 윈도우” 방식(Consecutive Sliding Windows Detection, CD)도 구현해 Naive Bayes와 결합하여 비교한다.[^1_2][^1_1]

***

## 4. 성능 향상과 한계

### 4.1 시간 복잡도 및 IKS 성능

실험 1: 샘플 크기가 계속 증가하는 경우 (두 샘플 모두 1→5000까지).[^1_1]

- Standard KS: 전체 과정 평균 12.76초.[^1_1]
- Optimized KS(정렬 유지, 삽입·삭제만 선형 삽입/삭제): 1.03초.[^1_1]
- IKS: 0.049초 (약 20× 빠름, standard 대비 260× 빠름 수준).[^1_1]

실험 2: 고정 길이 슬라이딩 윈도우(10000 길이 스트림, 윈도우 크기 100~1000).[^1_1]

- 윈도우 크기 1000에서:
    - Standard KS: 5.33초.
    - Optimized KS: 0.96초.
    - IKS: 0.041초 (OKS 대비 20×, standard 대비 >100×).[^1_1]

→ **KS 기반 드리프트 검출을 실시간 대규모 스트림에 적용 가능하게 만든다**는 점이 가장 큰 시스템적 기여이다.[^1_1]

### 4.2 분류 정확도 및 라벨 사용량

6개 실세계 스트림(일부는 인위적으로 드리프트 주입)에서, 1-NN / Naive Bayes / Decision Tree + 여러 전략을 비교한다.[^1_1]

- **Topline(TL)**: 항상 마지막 $W$개 인스턴스로 재학습 (라벨 100%).[^1_1]
- **BL1**: 드리프트 무시, 재학습 없음.[^1_1]
- **BL2**: MR와 동일 횟수로 무작위 시점에 재학습.[^1_1]


#### 4.2.1 Model Replacement

- MR는 항상 BL1/BL2보다 유의하게 높은 정확도를 얻으면서도, TL보다 **적은 라벨**로 근접한 성능을 달성한다.[^1_1]
- TL 대비 평균 정확도 비율:
    - 1-NN: 99.39%
    - Naive Bayes: 94.31%
    - Decision Tree: 93.69%.[^1_1]
- 라벨 사용 비율(TL=100% 대비):
    - 1-NN, NB: 47.59%
    - DT: 42.17%.[^1_1]

즉, **라벨 절반 이하**로도 거의 동일한 정확도에 도달하는 “라벨 효율적인” 적응이 가능함을 보인다.[^1_1]

#### 4.2.2 $\alpha/\beta$ Transformation

- 평균 라벨 사용량: TL의 16.89% 수준으로, MR 대비 크게 감소.[^1_1]
- 그러나 드리프트를 선형 변환으로 흡수할 수 있다는 가정이 맞지 않는 경우 성능 저하가 발생하며, MR보다 항상 낮은 정확도(평균 92.75% of TL)를 보인다.[^1_1]
- 따라서 **“라벨 극소화 vs 정확도”의 트레이드오프에서, 드리프트 유형(모노토닉/비모노토닉)에 따라 선택해야 하는 옵션**으로 해석할 수 있다.[^1_1]


#### 4.2.3 Adaptree

- DT에서 MR와 유사한 정확도(93.69% vs AT의 근사치)를 거의 유지하면서 라벨 비율을 35.62%까지 더 낮춘다.[^1_1]
- 트리 노드 단위로 국소적인 적응만 수행한다는 구조 덕분에, **라벨 효율성과 정확도 사이의 균형점**으로서 유망한 접근으로 제시된다.[^1_1]


#### 4.2.4 Zliobaite 방식(CD)와의 비교

- CD는 두 연속 슬라이딩 윈도우를 모두 이동시키는 방식으로, IKS 기반 reference–current 방식에 비해 정확도가 낮다(평균 82.15% of TL).[^1_1]
- 대신 라벨 사용량은 평균 16.37%로 매우 적다.[^1_1]
- 논문은 reference set을 고정하는 IKS 방식이 “현재 사용 중인 모델이 학습된 분포 vs 새 데이터 분포”를 직접 비교하므로 더 실용적이며 성능도 좋다고 결론짓는다.[^1_1]


### 4.3 한계 및 제약

1. **$|A|=r|B|$ 제약**
    - IKS의 이론적 정확도는 이 제약 하에서만 보장된다.[^1_1]
    - 일부 상황에서는 샘플 복제나 리샘플링(undersampling)이 필요하며, 이 과정이 추후 통계적 효율성에 영향을 줄 수 있다.
2. **피처 당 일변량 KS**
    - 피처별 KS로 드리프트를 감지하므로,
        - 특정 피처에만 국소적으로 나타나는 드리프트에는 민감하지만,
        - “개별 피처로는 미묘하지만 조합에서는 큰 변화”인 **순수한 다변량 드리프트**는 놓칠 수 있다.[^1_1]
    - 저자들도 “다변량 KS 또는 피처 맵핑을 쓰면 이런 경우를 포착 가능하지만 더 큰 샘플과 비용이 필요하다”고 언급한다.[^1_1]
3. **드리프트 감지–정확도 간 간접 관계**
    - KS는 데이터 분포의 변화를 측정할 뿐, **모델의 예측 성능이 실제로 악화되었는지 여부**와는 직접 연결되어 있지 않다.[^1_1]
    - 논문에서는 실험을 통해 “실제로 정확도 향상”을 보이지만, 이론적으로는 “분포 변화 ≠ 항상 성능 저하”라는 문제가 남는다.
4. **고차원 데이터에서의 확장성**
    - 모든 피처에 대해 Treap과 두 윈도우를 유지하면, 피처 수 $d$에 따라 $O(d)$개의 구조가 필요하다.[^1_1]
    - IKS 자체는 $O(\log N)$, $O(1)$이지만, 매우 고차원 딥러닝 표현에 직접 적용하기에는 피처 수가 부담이 될 수 있으며, 이후 연구(예: DriftLens)는 임베딩 공간에서의 분포거리 기반 접근으로 이 문제를 우회한다.[^1_3][^1_4]

***

## 5. 일반화 성능 관점에서의 해석

### 5.1 라벨 효율성과 일반화 간 관계

- IKS 기반 드리프트 검출은 **라벨 없이 분포 변화를 모니터링**하고,
    - **드리프트가 없을 때는 모델 재학습을 하지 않음** → 안정 구간에서는 데이터 분포가 비슷하므로, 지나친 업데이트로 인한 과적합이나 variance 증폭을 피할 수 있다.[^1_1]
    - **드리프트가 검출되면 그때만 라벨을 요청** → 최신 분포에 맞춘 재학습으로 bias를 줄이고, 라벨 사용량을 최적화한다.[^1_1]
- 실험에서 MR가 TL 대비 약 50%의 라벨로 거의 동일한 정확도(≥93.7%)를 달성한 것은,
    - “어디에서 분포가 바뀌는지”를 잘 포착하면, 모든 시점에서 라벨을 쓸 필요 없이도 비슷한 **일반화 성능**을 확보할 수 있음을 의미한다.[^1_1]


### 5.2 $\alpha/\beta$ 변환과 도메인 적응 관점

- $\alpha/\beta$ 변환은 “reference 분포를 current 분포에 선형 정규화”하여 드리프트를 보정한 뒤, **추가 라벨 없이** 재학습하는 방식이다.[^1_1]
- 이는 도메인 적응/코변수 이동(covariate shift) 상황에서 자주 쓰이는 feature-level alignment와 유사하며,
    - 분포 차이가 주로 1차·2차 모멘트(평균·분산) 변화로 설명되는 경우, 라벨 없이도 **새 도메인에 일반화**하는 효과를 낼 수 있다.[^1_1]
- 논문 결과에서, TL 라벨의 17% 수준만으로도 92.75%의 Topline 정확도를 유지한 것은, **라벨없는 feature 정규화가 실제 일반화 능력을 상당 부분 회복할 수 있음**을 보이는 경험적 증거로 해석할 수 있다.[^1_1]


### 5.3 Adaptree와 국소적 재학습

- Adaptree는 드리프트가 감지된 서브트리만 재학습하므로,
    - 안정적인 서브트리(과거 개념에도 잘 맞고 현재도 유효)는 유지 → 과거 지식을 보존하여 **재발(recurrence)하는 개념**에 대해 좋은 일반화 성능을 유지할 수 있다.[^1_1]
    - 변한 부분만 재학습 → 새로운 개념에 빠르게 적응하면서 라벨 요구량은 줄인다.[^1_1]
- 이는 continual learning/재발 개념(recurrent concept) 시나리오에서 중요한 설계 방향이며, 논문 결론에서도 “향후 재발 개념을 위해 과거 모델 앙상블을 사용하는 연구”를 제안한다.[^1_1]

요약하면, 이 논문은 “언제 라벨을 쓸지”를 통계적으로 제어함으로써, **라벨 효율성과 일반화 성능의 균형**을 실험적으로 제시하고 있다.

***

## 6. 2020년 이후 관련 최신 연구와 비교

IKS 이후, “비모수 통계 테스트 기반의 완전/부분 비지도 드리프트 검출”은 중요한 서브라인으로 자리잡았고, KS 기반과 그 확장이 활발히 연구되었다.[^1_5][^1_6][^1_7]

아래는 대표적인 개방형(오픈 액세스) 연구 몇 편이다.


| 연구(연도) | 핵심 아이디어 | IKS 대비 특징 |
| :-- | :-- | :-- |
| Raab et al., “Reactive Robust Soft LVQ with KS-based Windowing (KSWIN)” (2020)[^1_8][^1_9] | 슬라이딩 윈도우 내에서 KS 검정을 사용, LVQ 계열 분류기에 결합한 **반응형(reactive) 드리프트 검출** | IKS와 달리 “incremental KS 자료구조”는 사용하지 않지만, KS 기반 윈도우 비교를 표준화. 주로 분류기 성능 안정성 측면 실험. |
| Lu et al., “Bayesian Nonparametric Unsupervised Concept Drift Detection” (ACM TIST, 2020)[^1_2] | Pólya tree 기반 비모수 베이지안 이가설 검정을 스트림에 **incremental**하게 적용하여 분포 변화를 탐지 | KS-기반(점추정·临계값) 대신 후험 확률·위치정보 제공. 계산량은 더 크지만 해석력(어디서, 얼마나 변했는지)이 높다. |
| Mello et al., Klyushin–Petunin test 기반 온라인 변경점 탐지(2020)[^1_10] | 또 다른 비모수 테스트(K–P)를 온라인으로 구현, KS/윌콕슨과 성능 비교 | KS보다 일부 상황에서 더 높은 검출력 보고. IKS와 유사한 동기는 있으나, 구현과 수학적 가정이 다름. |
| Greco \& Cerquitelli, DriftLens (2024)[^1_3][^1_4] | 딥러닝 임베딩 공간의 분포 거리(가우시안 모델)를 이용한 **완전 비지도 드리프트 검출+설명** 프레임워크 | IKS가 원시 피처/단일 변수에 초점을 맞춘 반면, DriftLens는 고차원 표현에서 빠른 거리 계산·임계값 추정·레이블별 영향 분석까지 제공. KS 계열 방법이 초기 아이디어로 분류됨. |
| Olteanu et al., anomaly/change-point survey (2022)[^1_11] | 비지도 이상/변경점 검출의 최신 기법을 정리, KS 기반 방법을 중요한 통계적 도구로 분류 | IKS 류의 “incremental statistical test”는 여전히 유효하지만, 고차원에서는 커널·거리 기반 방법과 경쟁·보완 관계에 있다고 요약. |
| 최근 UCDD 벤치마크 \& survey (2025)[^1_6][^1_7][^1_12] | 완전 비지도 드리프트 검출 알고리즘들을 실세계 스트림에서 벤치마킹, KS·PSI·KL 기반 등 다양한 접근 비교 | IKS 논문은 초기 대표 KS 기반 검출로 자주 인용되며, 이후 기법들은 윈도우 선택, 임계값 자동 설정, 고차원 처리, 다변량 검정 등에서 확장을 시도. |

요약하면,

- **IKS의 기여**는 “KS를 스트림에서 실시간으로 쓰게 만든 효율적 구현 + 라벨 효율적 드리프트 적응 프레임워크”이고,[^1_13][^1_1]
- 이후 연구들은
    - 다른 비모수 검정(Polya tree, Klyushin–Petunin 등)으로 검출력·해석력을 확대하거나,[^1_10][^1_2]
    - 딥러닝 임베딩·고차원 표현에서의 비지도 드리프트 검출(DriftLens 등)로 일반화,[^1_4][^1_3]
    - 완전 비지도·멀티라벨·실세계 스트림에 대한 벤치마크와 윈도우/임계값 설계 이슈를 체계적으로 탐구하는 방향으로 발전하고 있다.[^1_12][^1_14][^1_6]

***

## 7. 앞으로의 연구 영향과 고려할 점

### 7.1 영향

1. **KS 기반 비지도 드리프트 검출의 표준 레퍼런스**
    - IKS는 이후 KS 기반 윈도우 비교 기법(KSWIN, KS-windowing 등)과 다양한 드리프트 탐지 프레임워크에서 인용되며, “KS를 스트림에 얹는 기본 패턴”을 제시했다.[^1_9][^1_15][^1_14]
2. **라벨 효율적(adaptive labeling) 개념의 구체화**
    - “라벨이 없을 때는 분포 비교로 모니터링, 변화가 있을 때만 라벨 요청”이라는 구조는, 이후 자원 제약 환경(엣지, 온라인 서비스)에서 널리 채택되는 설계 패턴이 되었다.[^1_16][^1_17]
3. **스트림용 비모수 테스트의 관심 확장**
    - IKS는 비모수 통계 검정을 스트림 설정에 맞게 “알고리즘화”하는 가능성을 보여 주었고, 이후 Polya tree, incremental KS 변형 등으로 일반화 시도가 이어졌다.[^1_18][^1_2]

### 7.2 앞으로 연구 시 고려할 점 / 확장 방향

1. **다변량·임베딩 공간으로의 확장**
    - IKS는 피처별 일변량 검정에 초점을 둔다. 향후 연구에서는
        - 고차원 임베딩(딥러닝 representation)에서의 **저비용 분포 거리**와,
        - 다변량 KS 또는 sliced/랜덤 projection 기반 근사 검정을 결합해, “조합적 드리프트”까지 포착하는 방향이 중요하다.[^1_3][^1_4]
2. **드리프트 감지와 성능 저하 간의 연결**
    - 순수 분포 변화가 아닌, **예측 성능에 영향을 주는 drift만** 선택적으로 반응하는 정책(예: loss-based, Lyapunov drift + penalty 기반 업데이트 정책 등)을 KS 계열 검출과 결합하는 것이 필요하다.[^1_16][^1_9]
3. **윈도우 크기와 임계값의 자동 튜닝**
    - IKS와 많은 통계 기반 검출법의 성능은 윈도우 크기 $W$, 유의수준 $\alpha$에 민감하다.[^1_19][^1_1]
    - 최근 연구들은 이들을 자동 조정하거나, drift severity·delay·FPR을 직접 제어하는 메타-정책을 탐구한다. IKS를 이런 “윈도우/임계값 자동 최적화” 프레임워크에 포함하는 것도 가치가 크다.[^1_20][^1_6]
4. **재발(recurrent) 개념과 앙상블**
    - 논문에서도 언급하듯, 과거 개념이 재등장할 수 있는 환경에서 IKS 기반 검출을 **과거 모델 앙상블/메모리**와 결합해, 재발 시 빠르게 전환·통합하는 전략이 중요하다.[^1_17][^1_1]
5. **일반화 보장에 대한 이론 분석**
    - 현재는 실험적으로 “라벨 절반으로도 거의 같은 정확도”를 보였지만,
    - 드리프트 빈도·규모, KS의 검출력, 라벨 요청 정책이 **일반화 에러 상계**에 어떻게 영향을 미치는지에 대한 이론적 분석은 앞으로의 핵심 과제이다.[^1_21][^1_22]

***

위 내용을 바탕으로, 후속 연구를 설계하실 때는

- (1) IKS의 효율적인 온라인 KS 구현을 재사용하면서,
- (2) 고차원 표현·다변량 드리프트,
- (3) 라벨/연산 비용을 명시적으로 고려한 업데이트 정책,
- (4) 성능 중심의 drift 정의 (loss 혹은 유틸리티 기반),
을 통합하는 방향을 고려해 볼 수 있다.
<span style="display:none">[^1_23][^1_24][^1_25][^1_26][^1_27][^1_28][^1_29][^1_30][^1_31][^1_32][^1_33][^1_34][^1_35][^1_36][^1_37][^1_38][^1_39][^1_40][^1_41][^1_42][^1_43][^1_44][^1_45][^1_46][^1_47]</span>

<div align="center">⁂</div>

[^1_1]: 2939672.2939836.pdf

[^1_2]: https://dl.acm.org/doi/10.1145/3420034

[^1_3]: https://arxiv.org/html/2406.17813v2

[^1_4]: https://arxiv.org/pdf/2406.17813.pdf

[^1_5]: https://arxiv.org/html/2406.17813v1

[^1_6]: https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1330257/full

[^1_7]: https://www.academicpublishers.org/journals/index.php/ijdsml/article/download/3565/4591/9013

[^1_8]: https://arxiv.org/pdf/2007.05432.pdf

[^1_9]: https://arxiv.org/html/2512.12289v1

[^1_10]: https://ieeexplore.ieee.org/document/9204193/

[^1_11]: https://arxiv.org/pdf/2212.13520.pdf

[^1_12]: https://www.academicpublishers.org/journals/index.php/ijdsml/article/view/3565

[^1_13]: https://research-information.bris.ac.uk/en/publications/fast-unsupervised-online-drift-detection-using-incremental-kolmog/

[^1_14]: https://yoksis.bilkent.edu.tr/pdf/files/15959.pdf

[^1_15]: https://aisel.aisnet.org/cgi/viewcontent.cgi?article=1360\&context=hicss-56

[^1_16]: https://arxiv.org/html/2505.24149v1

[^1_17]: https://arxiv.org/pdf/2505.17902.pdf

[^1_18]: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4266349

[^1_19]: https://arxiv.org/pdf/2602.06456.pdf

[^1_20]: https://arxiv.org/pdf/2511.09953.pdf

[^1_21]: https://arxiv.org/pdf/2210.04865.pdf

[^1_22]: http://arxiv.org/pdf/1010.4784.pdf

[^1_23]: https://www.semanticscholar.org/paper/Fast-Unsupervised-Online-Drift-Detection-Using-Test-Reis-Flach/be6fcf6647488822ceae57ccd3b5c6b06f5f3fe4

[^1_24]: https://arxiv.org/html/2507.02310v1

[^1_25]: https://arxiv.org/html/2601.08928v1

[^1_26]: https://www.arxiv.org/pdf/2508.16336.pdf

[^1_27]: https://arxiv.org/html/2508.16336

[^1_28]: http://link.springer.com/10.1007/978-981-15-0187-6_31

[^1_29]: https://ieeexplore.ieee.org/document/9356385/

[^1_30]: https://ejournal.radenintan.ac.id/index.php/tadris/article/view/6849

[^1_31]: https://dergipark.org.tr/en/doi/10.46463/ijrss.788883

[^1_32]: http://dergipark.org.tr/tr/doi/10.33715/inonusaglik.812385

[^1_33]: https://individualandsociety.org/journal/2020/2/internalization-of-the-thin-ideal-as-a-causal-risk-factor-and-a-mediator-of-intervention-effects-on-eating-disorder-symptoms-in-women

[^1_34]: https://www.semanticscholar.org/paper/bf344ef6051c5d5b4cd8571cb0e1348981093705

[^1_35]: https://public.scnchub.com/palr/index.php/palr/article/view/30/22

[^1_36]: https://arxiv.org/pdf/2307.00445.pdf

[^1_37]: https://arxiv.org/html/2410.10041v2

[^1_38]: https://arxiv.org/pdf/2211.06239.pdf

[^1_39]: https://arxiv.org/pdf/1712.00332.pdf

[^1_40]: https://www.mdpi.com/2076-3417/11/20/9644/pdf?version=1634529436

[^1_41]: https://arxiv.org/pdf/2501.02729.pdf

[^1_42]: https://dl.acm.org/doi/10.1145/2939672.2939836

[^1_43]: https://www.sciencedirect.com/science/article/pii/S0925231224017041

[^1_44]: https://www.sciencedirect.com/science/article/abs/pii/S1568494625012165

[^1_45]: https://www.kdd.org/kdd2016/papers/files/rpp0427-dos-reisA.pdf

[^1_46]: https://www.kdd.org/kdd2016/subtopic/view/fast-unsupervised-online-drift-detection-using-incremental-kolmogorov-smirn

[^1_47]: https://www.cs.unm.edu/~aumyfarhan1/publication/driftkais/chowdhury2021driftkais.pdf

