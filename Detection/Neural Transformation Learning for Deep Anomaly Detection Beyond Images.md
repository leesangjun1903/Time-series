# Neural Transformation Learning for Deep Anomaly Detection Beyond Images

### 1. 핵심 주장 및 주요 기여

이 논문은 **이미지를 넘어선 데이터(시계열, 테이블 데이터)의 이상 탐지를 위해 학습 가능한 신경망 변환(learnable neural transformations)을 제안**합니다. 논문의 중심 주장은 다음과 같습니다.[1]

이미지 데이터에서는 회전, 반사, 자르기 등 수동으로 설계된 변환이 자기지도학습(self-supervised learning)에서 잘 작동하지만, 시계열이나 테이블 데이터에서는 어떤 변환을 사용해야 하는지 명확하지 않다는 점입니다. 논문은 이를 해결하기 위해 **NeuTraL AD(Neural Transformation Learning for Anomaly Detection)** 방법을 제시하며, 핵심 기여는 다음과 같습니다.[1]

**주요 기여:**

1. **결정론적 대조 손실(Deterministic Contrastive Loss, DCL)**: 음수 샘플 분포 없이 직접 설계된 손실 함수로, 정규화나 적대적 훈련 없이도 유효한 변환을 학습합니다.[1]

2. **이론적 정당성 제공**: 기존 변환 예측 손실(LP)과 SimCLR 손실(LC)이 이상 탐지에 부적절함을 수학적으로 증명(Proposition 1-3)하고, DCL이 이들을 해결함을 보입니다.[1]

3. **시계열 및 테이블 데이터에서의 우수한 성능**: 에필렙시 데이터셋에서 AUC를 82.6%에서 92.6%로 향상시키고, 부정맥 데이터셋에서 F1 스코어를 60.3%로 개선했습니다.[1]

---

### 2. 해결하는 문제, 제안 방법, 모델 구조

#### **2.1 문제 정의**

논문이 해결하는 문제는 **도메인 특화 변환의 부재**입니다. 이미지 영역 외의 데이터에서 자기지도 이상 탐지를 적용할 때, 어떤 변환이 의미 있는 정보를 유지하면서도 다양한 관점을 제공할 수 있는지 알 수 없다는 점입니다.[1]

또한 기존 방법의 문제점은:
- **변환 예측 방식**: 상수 변환(constant transformation)이 최소값으로 수렴하는 문제 발생[1]
- **SimCLR 기반 방식**: 항등 변환(identity transformation)이 최소값이 되는 문제 발생[1]
- 추가적인 정규화나 적대적 훈련 필요[1]

#### **2.2 제안 방법: NeuTraL AD**

**아키텍처 개요:**
NeuTraL AD는 두 개의 주요 컴포넌트로 구성됩니다.[1]

1. **학습 가능한 변환 세트**: $$T = \{T_1, ..., T_K\}$$, 여기서 $$T_k: \mathcal{X} \to \mathcal{X}$$[1]
2. **인코더**: $$f: \mathcal{X} \to \mathcal{Z}$$ (특성 추출기)[1]

**손실 함수 및 수식:**

스코어 함수는 다음과 같이 정의됩니다:[1]

$$h(x^k, x^l) = \exp\left(\frac{\text{sim}(f(T_k(x)), f(T_l(x)))}{\tau}\right)$$

여기서 $$\text{sim}(z, z') = \frac{z^T z'}{\|z\| \|z'\|}$$ (코사인 유사도), $$\tau$$는 온도 매개변수입니다.[1]

**결정론적 대조 손실(DCL):**

$$\mathcal{L}_{\text{DCL}} = \mathbb{E}_{x \sim D} \sum_{k=1}^{K} \log \frac{h(x^k, x)}{h(x^k, x) + \sum_{l \neq k} h(x^k, x^l)}$$

이 손실의 핵심:
- **분자**: 변환된 샘플과 원본의 유사도를 최대화 → 의미론적 요구사항(Requirement 1)[1]
- **분모**: 서로 다른 변환 간의 거리를 최대화 → 다양성 요구사항(Requirement 2)[1]

**이상 탐지 점수:**

$$S(x) = \sum_{k=1}^{K} \log \frac{h(x^k, x)}{h(x^k, x) + \sum_{l \neq k} h(x^k, x^l)}$$

훈련 중 이 손실을 최소화하는 것이 테스트 시 이상 탐지 점수가 됩니다. 정상 샘플은 낮은 점수, 이상 샘플은 높은 점수를 가집니다.[1]

#### **2.3 변환 구조**

시계열 데이터의 변환은 마스크 기반으로 설계됩니다:[1]

**세 가지 매개변수화:**
1. **피드포워드**: $$T_k(x) = M_k(x)$$
2. **잔여(Residual)**: $$T_k(x) = M_k(x) + x$$
3. **곱셈(Multiplicative)**: $$T_k(x) = M_k(x) \odot x$$

마스크 $$M_k$$는 3개의 잔여 블록으로 이루어진 1D 합성곱 신경망입니다.[1]

***

### 3. 성능 향상 및 일반화 성능

#### **3.1 시계열 데이터 성능**

**One-vs-Rest 평가:**[1]

| 데이터셋 | 이전 최고 | NeuTraL AD | 향상도 |
|---------|---------|-----------|--------|
| SAD (음성) | 96.7% | **98.9%** | +2.2% |
| NATOPS (동작) | 94.7% | **94.5%** | - |
| CT (문자궤적) | 99.3% | **99.3%** | - |
| EPSY (뇌파신호) | 85.8% | **92.6%** | +6.8% |
| RS (라켓스포츠) | 87.7% | **87.7%** | - |

**N-vs-Rest 평가 (더 어려운 설정):**[1]

| 데이터셋 | One-class 설정 | N-vs-Rest 설정 |
|---------|---|---|
| SAD | 98.9% | 85.1% |
| NATOPS | 94.5% | 74.8% |
| EPSY | 92.6% | 80.5% |

#### **3.2 테이블 데이터 성능**

**F1-스코어 비교:**[1]

| 데이터셋 | Deep SVDD | GOAD | NeuTraL AD |
|---------|-----------|------|-----------|
| Arrhythmia | 53.9±3.1 | 52.0±2.3 | **60.3±1.1** |
| Thyroid | 70.8±1.8 | 74.5±1.1 | **76.8±1.9** |
| KDD | 99.0±0.1 | 98.4±0.2 | **99.3±0.1** |
| KDDRev | 98.6±0.2 | 98.9±0.3 | **99.1±0.1** |

#### **3.3 일반화 성능 관련 주요 발견**

**1. 변환 개수의 영향:**

논문의 Figure 6에서 보여주듯이, 변환 개수 K에 따른 성능을 분석했습니다.[1]

- K ≥ 4일 때 성능이 안정화됨[1]
- K가 증가할수록 변환이 보다 다양해지고, 무작위성이 줄어듦[1]
- K = 11 정도에서 포화 상태 도달[1]

**2. 매개변수화 선택의 견고성:**

DCL의 설계로 인해, 손실이 최소화되면 자동으로 의미론과 다양성이 보장됩니다. 따라서:[1]
- 피드포워드, 잔여, 곱셈 매개변수화 모두 유사한 성능 달성[1]
- 추가 정규화나 제약 불필요[1]

**3. 일반화 향상의 메커니즘:**

Figure 3의 시각화를 통해 NeuTraL AD의 일반화 성능 향상이 다음과 같이 작동함을 보여줍니다:[1]

- **정상 데이터**: 임베딩 공간 Z에서 서로 다른 변환들이 명확히 분리됨
- **이상 데이터**: 변환된 버전들이 임베딩 공간에서 겹침
- 이는 정상 vs. 이상 구분을 명확하게 함

***

### 4. 모델 한계

#### **4.1 이론적 한계**

**1. 라벨 정보 부재로 인한 변환 무용성:**

NeuTraL AD는 자기지도학습으로 변환을 학습하므로, 학습된 변환이 이상 탐지에 반드시 유용하다는 보장이 없습니다. 특히 K가 작을 때(K < 4) 성능 분산이 큼을 Figure 6에서 확인할 수 있습니다.[1]

#### **4.2 계산 자원 한계**

변환 기반 방법의 근본적 문제로, 메모리 요구량이 변환 개수에 따라 선형적으로 증가합니다.[1]

- Deep SVDD 대비 약 K배의 메모리 필요[1]
- K = 11일 때 상당한 메모리 오버헤드[1]

#### **4.3 데이터 타입별 성능 편차**

**시계열 데이터에서의 한계:**
- Racket Sports(RS) 데이터셋에서 수동 설계된 변환(fixed Ts)에 비해 성능 저하[1]
- 이는 도메인 지식이 매우 명확한 경우, 학습이 추가 가치를 제공하지 않을 수 있음을 시사

**N-vs-Rest 설정에서의 성능 저하:**
- 정상 데이터의 다양성이 증가하면 모든 방법의 성능이 감소[1]
- 특히 SAD 데이터셋에서 n > 3일 때 LOF가 NeuTraL AD보다 우수함[1]

#### **4.4 이미지 데이터에서의 미적용**

논문에서 명시적으로, 이미지 데이터에서는 수동 설계된 변환이 이미 매우 효과적이므로 NeuTraL AD의 이점이 없다고 언급합니다.[1]

***

### 5. 앞으로의 연구에 미치는 영향 및 고려사항

#### **5.1 연구 영향**

**1. 자기지도학습의 도메인 확장:**

기존에 이미지 중심이던 자기지도 이상 탐지를 시계열, 의료 데이터 등으로 확대하는 길을 열었습니다. 이는 데이터 부족 상황에서 대규모 라벨링 없이 강력한 이상 탐지기 개발을 가능하게 합니다.[1]

**2. 변환 학습의 이론적 기초:**

Proposition 1-3을 통해 변환 학습에 적절한 손실함수의 조건을 형식화했습니다. 이는 향후 다른 도메인에서의 변환 학습 방법 설계에 이론적 지침을 제공합니다.[1]

**3. 보건의료 응용 가능성:**

의료 데이터(부정맥, 갑상선)에서의 우수한 성능은 임상 현장에서의 적용 가능성을 제시합니다.

#### **5.2 향후 연구 시 고려사항**

**1. 변환 개수의 적응적 선택:**

현재는 고정된 K를 사용하지만, 데이터 복잡도에 따른 동적 K 선택이 필요할 수 있습니다. 이를 통해 메모리 효율성을 개선할 수 있습니다.[1]

**2. 라벨 정보 통합:**

약한 레이블(weak label) 또는 준지도학습 설정에서 NeuTraL AD를 확장하면, 의미 있는 변환을 더 효과적으로 학습할 수 있을 것입니다.

**3. 고차원 복잡 데이터에 대한 확장:**

현재는 수백~수천 차원 데이터에 초점이 있지만, 고차원(예: 이미지에 가까운 구조) 데이터나 그래프 구조 데이터로의 확장이 필요합니다.

**4. 메모리 효율성 개선:**

공유 가중치(weight sharing), 파라미터 압축, 또는 희소 변환(sparse transformations)을 통해 메모리 요구량을 감소시킬 수 있습니다.

**5. 동적 임계값 설정:**

현재 고정된 임계값 기반 이상 탐지를 개선하기 위해, 적응적 임계값 선택 메커니즘이 필요할 수 있습니다. 특히 클래스 불균형이 심한 상황에서 유용할 것입니다.

**6. 온라인 이상 탐지로의 확장:**

스트리밍 데이터 환경에서 변환을 점진적으로 업데이트하는 온라인 학습 알고리즘 개발이 실무적으로 중요합니다.

**7. 도메인 지식 활용:**

완전히 학습 기반이 아니라, 도메인 전문가의 지식(예: 의료 데이터에서 생리적으로 의미 있는 변환)을 사전정보로 통합하는 하이브리드 접근이 고려되어야 합니다.

***

## 결론

NeuTraL AD는 **이미지 이외의 데이터에서 학습 가능한 변환을 통한 자기지도 이상 탐지의 새로운 패러다임**을 제시합니다. 결정론적 대조 손실의 우아한 설계를 통해 추가 정규화 없이도 의미론과 다양성을 자동으로 보장하는 점이 핵심 혁신입니다. 특히 시계열과 의료 데이터에서의 우수한 성능은 실무적 임팩트를 시사하며, 제시된 이론적 분석은 향후 변환 학습 연구에 중요한 토대를 마련합니다. 다만 메모리 오버헤드, 라벨 정보 부재로 인한 변환 유용성 불확실성, N-vs-Rest 같은 도전적 설정에서의 성능 제한 등이 추가 연구의 과제로 남아 있습니다.[1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/97320c04-a7d5-48a0-9a79-307f5771686d/2103.16440v4.pdf)
