# Unsupervised Representation Learning for Time Series with Temporal Neighborhood Coding

### 핵심 주장과 주요 기여

**TNC(Temporal Neighborhood Coding)**는 라벨이 부족한 **비정상(non-stationary) 시계열 데이터**에서 일반화 가능한 표현을 학습하는 자기지도 학습(self-supervised) 프레임워크입니다. 이 논문의 핵심 주장은 시계열의 **국소적 평탄성(local smoothness)**을 활용하여 시간상 이웃(temporal neighborhood)을 정의하면, 이 이웃 내의 신호 분포와 비이웃 신호 분포를 표현 공간에서 구분할 수 있다는 것입니다.[1]

주요 기여는 세 가지입니다:[1]
1. **비정상 다변량 시계열을 위한 이웃 기반 비지도 학습 프레임워크** 제시
2. **통계적 검증을 통한 자동 경계 결정**: 증강 딕키-풀러(ADF) 검정을 사용하여 신호의 정상성 범위를 자동으로 파악
3. **양성 미표시 학습(Positive-Unlabeled Learning)의 개념 도입**: 대조 손실에서 음성 샘플 추출 시 발생하는 편향 보정

---

### 해결 문제와 제안 방법

#### 문제 정의

실제 시계열 데이터는 **고차원적이고 복잡**하며 **라벨이 부족**합니다. 특히 의료 분야에서는 환자의 임상 상태가 연속적으로 변화하지만, 이를 라벨링하는 것이 실질적으로 불가능합니다. 기존의 비지도 표현 학습 방법들(자동인코더, VAE 등)은 복잡한 시계열 재구성의 어려움이 있고, Contrastive Predictive Coding(CPC)이나 Triplet Loss 같은 방법들은 **비정상성을 충분히 다루지 못합니다.**[1]

#### 핵심 방법론

**1. 시간 이웃(Temporal Neighborhood) 정의**

시계열 신호 $$X \in \mathbb{R}^{D \times T}$$ (D: 특성 수, T: 시간 단계)에서 중심이 시점 t인 길이 δ의 윈도우를 $$W_t$$라고 정의합니다. 시간 이웃 $$N_t$$는 다음과 같이 정의됩니다:

$$
t^* \sim \mathcal{N}(t, \eta \cdot \delta)
$$

여기서 $$\eta$$는 이웃의 범위를 결정하는 매개변수이고, 신호가 정상성을 유지하는 대략적인 시간 범위를 나타냅니다.[1]

**2. ADF 검정을 통한 η 자동 결정**

$$\eta$$가 너무 작으면 이웃 내 샘플이 중복되어 엔코더가 겹치는 정보만 학습하고, 너무 크면 여러 상태에 걸쳐 신호가 정상이 아니게 됩니다. 이를 해결하기 위해 **Augmented Dickey-Fuller (ADF) 통계 검정**을 사용합니다. 각 윈도우 $$W_t$$에 대해:[1]

- $$\eta = 1$$부터 시작하여 점진적으로 증가
- 각 단계에서 p-값 계산
- **p-값이 임계값(0.01) 이상**이 되면 신호가 정상이 아니라고 판단하고 해당 η 설정

**3. 양성-미표시 학습 기반 손실 함수**

무작위로 음성 샘플을 추출할 때, 실제로는 같은 잠재 상태에 있는 신호들을 음성으로 표시할 수 있습니다. 이 **샘플링 편향**을 해결하기 위해 PU 학습의 개념을 도입합니다.[1]

- **이웃 내 샘플**: 양성으로 단위 가중치(w=1)로 처리
- **비이웃 샘플**: 혼합된 샘플로 취급, 가중치 $$w$$로 조정 (w: 비이웃 영역에서 양성 샘플일 확률)

**손실 함수:**

$$
\mathcal{L} = \mathbb{E}_{W_t \in X} \left[ \mathbb{E}_{W_l \in N_t} \log D(Z_t, Z_l) + \mathbb{E}_{W_k \notin N_t} \left( (1-w) \log(1-D(Z_t, Z_k)) + w \log D(Z_t, Z_k) \right) \right]
$$

여기서:
- $$D(Z_t, Z_k)$$: 판별기가 두 표현이 같은 이웃에 속할 확률
- $$\mathbb{E}_{W_t}$$: 윈도우에 대한 기댓값
- 첫 번째 항: 이웃 샘플은 구분되어야 함 (1에 가까움)
- 두 번째 항: 비이웃 샘플은 구분 안 됨 (0에 가까움, 단 가중치 보정)[1]

***

### 모델 구조

TNC는 두 가지 핵심 구성 요소로 이루어집니다:[1]

**1. 엔코더(Encoder)**
- 입력: $$W_t \in \mathbb{R}^{D}$$ (차원 D의 윈도우)
- 출력: $$Z_t = \text{Enc}(W_t) \in \mathbb{R}^{M}$$ (저차원 표현, M < D)
- 아키텍처: 신호 특성에 맞는 임의의 파라미터 모델 가능 (RNN, CNN 등)

**2. 판별기(Discriminator)**
- 입력: 두 표현 $$Z_t, Z_k$$
- 출력: 두 표현이 같은 이웃에 속할 확률 (0 또는 1)
- 다중 헤드 이진 분류기로 구현

**특징:**
- 판별기는 학습 중에만 사용되며 추론 시에는 버려집니다.
- 엔코더 아키텍처는 신호에 맞게 선택 가능 (유연성)

***

### 성능 향상 분석

#### 1. 클러스터링 성능

실험에서 여러 데이터셋(시뮬레이션, ECG, 인간 활동 인식)에 대해 평가했습니다:[1]

| 데이터셋 | 메트릭 | TNC | CPC | Triplet Loss |
|---------|--------|-----|-----|--------------|
| 시뮬레이션 | Silhouette | 0.71±0.01 | 0.51±0.03 | 0.61±0.08 |
| 시뮬레이션 | DBI | 0.36±0.01 | 0.84±0.06 | 0.64±0.12 |
| ECG | Silhouette | 0.44±0.02 | 0.26±0.02 | 0.25±0.01 |
| ECG | DBI | 0.74±0.04 | 1.44±0.04 | 1.30±0.03 |
| HAR | Silhouette | 0.61±0.02 | 0.58±0.02 | 0.17±0.01 |
| HAR | DBI | 0.52±0.04 | 0.57±0.05 | 1.76±0.20 |

**Silhouette 점수가 높을수록** (최대 1), **DBI가 낮을수록** 클러스터링 성능이 우수합니다. TNC는 모든 데이터셋에서 기준 방법들을 능가합니다. 특히 시뮬레이션 데이터에서 매우 높은 성능을 보입니다.[1]

#### 2. 분류 성능

선형 분류기를 사용한 다운스트림 분류 작업:[1]

| 데이터셋 | 메트릭 | TNC | CPC | Triplet Loss | Supervised |
|---------|--------|-----|-----|--------------|-----------|
| 시뮬레이션 | AUPRC | 0.99±0.00 | 0.69±0.06 | 0.78±0.01 | 0.99±0.00 |
| 시뮬레이션 | Accuracy | 97.52±0.13 | 70.26±6.48 | 76.66±1.40 | 98.56±0.13 |
| ECG | AUPRC | 0.55±0.01 | 0.42±0.01 | 0.47±0.00 | 0.67±0.01 |
| ECG | Accuracy | 77.79±0.84 | 68.64±0.49 | 75.51±1.26 | 94.81±0.28 |
| HAR | AUPRC | 0.94±0.007 | 0.93±0.006 | 0.71±0.007 | 0.98±0.00 |
| HAR | Accuracy | 88.32±0.12 | 86.43±1.41 | 63.60±3.37 | 92.03±2.48 |

TNC는 **지도 학습에 매우 가까운 성능**을 달성합니다. 특히 의료 ECG 데이터에서 77.79%의 정확도로 기준 모델들을 크게 앞섭니다.[1]

#### 3. 성능 향상의 이유

**CPC와 Triplet Loss 대비 우수성:**[1]

1. **비정상성 명시적 처리**: ADF 검정으로 정상성 범위를 정확히 파악
2. **샘플링 편향 보정**: PU 학습의 가중치 조정으로 음성 샘플 오분류 완화
3. **적응적 이웃 범위**: 각 윈도우마다 신호 특성에 맞게 조정되는 η
4. **더 넓은 양성 샘플 정의**: Triplet Loss의 겹치는 윈도우만 사용하지 않고, 넓은 이웃 범위에서 비겹치는 유사 샘플도 포함

***

### 일반화 성능 향상 가능성

#### 1. 표현의 전이성(Transferability)

TNC가 학습한 표현은 **여러 다운스트림 작업에 일반화**됩니다:[1]

- **클러스터링**: 라벨 없이 잠재 상태 복구
- **분류**: 선형 분류기만으로도 높은 성능 달성
- **궤적 분석(Trajectory Analysis)**: 시간 경과에 따른 상태 변화 추적

특히 시뮬레이션 데이터에서 97.52%의 분류 정확도는 지도 학습(98.56%)과 거의 동등한 수준입니다.[1]

#### 2. 데이터 효율성

의료 데이터 실험에서 보듯이:**[1]
- 단 25명의 환자로부터 5백만개의 데이터 포인트를 활용
- **작은 샘플, 많은 시계열** 상황에서도 강건한 표현 학습
- 라벨 획득이 불가능한 상황에서도 유용한 표현 추출

#### 3. 신호 특성 적응성

**창 크기 선택에 따른 성능:**[1]

| 창 크기 | 시뮬레이션 AUPRC | 시뮬레이션 Accuracy |
|--------|-------------|------------------|
| 10 | 0.74±0.01 | 71.60±0.59 |
| 50 | 0.99±0.00 | 97.52±0.13 |
| 100 | 0.84±0.11 | 84.25±9.08 |

창 크기가 적절할 때(기저 상태를 충분히 포함하지만 다중 상태는 아닐 때) 최적 성능을 보입니다. 하지만 신호 특성에 맞는 창 크기 선택이 필요합니다.[1]

#### 4. 가중치 조정의 영향

**PU 학습 가중치 효과:**[1]

| 가중치 w | 시뮬레이션 | ECG | HAR |
|---------|----------|-----|-----|
| 0.2 | 71.60% | 60.44% | 85.75% |
| 0.1 | 75.41% | 63.67% | 88.21% |
| 0.05 | 75.73% | 66.04% | 87.33% |

가중치 조정은 특히 **불균형한 클래스 분포**를 가진 데이터셋(ECG)에서 성능 개선에 중요합니다.

***

### 모델의 한계

#### 1. 계산 복잡성

**ADF 검정의 성능 병목:**[1]
- 매 윈도우마다 ADF 검정 수행으로 학습 속도 저하
- ADF 구현이 GPU 계산을 지원하지 않음
- 저자들도 "최적화된 ADF 구현이 향후 과제"라 명시

#### 2. 초매개변수 민감성

**창 크기(δ) 선택:**[1]
- 신호 특성에 대한 사전 지식 필요
- 자동으로 결정할 수 있는 방법 부재
- 부적절한 선택 시 성능 급격히 저하 (100의 경우 97% → 84%)

**가중치(w) 선택:**[1]
- 기본값이나 도메인 지식으로 수동 설정 필요
- 하이퍼파라미터 튜닝 필요

#### 3. 신호의 장기 계절성 처리

**제한사항:**[1]
- 먼 시점이지만 같은 상태인 신호들을 완벽히 다루지 못함
- 예: 환자가 악화 후 다시 안정 상태로 돌아오는 경우
- 이를 부분적으로 가중치로 완화하지만 근본적 해결 아님

#### 4. 엔코더 아키텍처 의존성

**아키텍처 선택 부담:**[1]
- 프레임워크는 flexible하지만, 엔코더 선택은 결과에 큰 영향
- 다양한 신호 유형에 맞는 최적 아키텍처 제시 부족
- 단순 RNN, CNN만 실험 (고급 아키텍처 미테스트)

#### 5. 지도 학습과의 격차

특히 **의료 데이터(ECG)**에서:
- TNC: 77.79% (비지도)
- 지도: 94.81% (16% 차이)

라벨 부족 상황에서는 우수하지만, 라벨이 충분할 경우 지도 학습의 성능 격차를 극복하지 못합니다.

***

### 미래 연구에 미치는 영향 및 고려사항

#### 1. 연구 영향

**이 논문의 기여:**
- **시계열 표현 학습의 새로운 패러다임**: 비정상성을 명시적으로 다루는 첫 체계적 접근
- **PU 학습의 대조 학습 적용**: 표현 학습의 샘플링 편향 문제에 새로운 해결책 제시
- **의료 AI 기초 마련**: 라벨 부족 의료 데이터에서 임상 상태 추적의 기초 제공

#### 2. 향후 연구 방향

**자동 하이퍼파라미터 결정:**[1]
- 창 크기 자동 학습 메커니즘
- 적응적 가중치 w 결정 알고리즘
- ADF 임계값 데이터 기반 선택

**계산 효율 개선:**
- GPU 지원 ADF 구현
- 이웃 범위 계산 가속화

**고급 아키텍처 통합:**
- Transformer 기반 인코더 적용 가능성
- 다중 스케일 시간 표현

**시계열 특성 확장:**
- 더 심한 비정상성 신호 처리
- 강한 계절성/주기성 신호 개선

#### 3. 실제 응용 시 고려사항

**의료 분야 적용:**
- 신환자 모니터링에서 기저 상태 자동 학습
- 이상 탐지(anomaly detection) 작업 확대
- 다중 환자 집단의 임상 상태 자동 분류

**기술 선택 기준:**[1]
- 라벨 획득이 사실상 불가능한 고주파 시계열 → TNC 최적
- 예측 기반 접근이 유효한 순서형 데이터 → CPC 고려
- 명확한 시간적 계층 구조 데이터 → Triplet Loss 검토

**제약 조건:**
- 신호 특성에 대한 도메인 전문가 지식 필수
- 계산 자원(ADF 검정) 고려 필요
- 장기 계절성 있는 신호는 추가 전처리 고려

***

## 결론

**Temporal Neighborhood Coding**은 비정상 시계열의 비지도 표현 학습에서 **패러다임 전환**을 나타냅니다. ADF 검정을 통한 자동 이웃 정의와 PU 학습의 가중치 조정은 창의적인 기술적 해결책으로, 의료 데이터와 같이 라벨이 부족한 실제 상황에서의 신뢰성을 높입니다.[1]

다만 **계산 복잡성**, **초매개변수 민감성**, **장기 계절성 처리의 한계** 등은 실제 배포 시 고려해야 할 점입니다. 향후 연구에서는 이들 한계를 극복하고 더 복잡한 신호에 확대 적용하는 것이 중요합니다. 특히 의료 AI, 이상 탐지, 다중 도메인 시계열 분석에서 이 방법론의 발전이 임상적, 학술적 가치를 크게 높일 것으로 기대됩니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/0518075d-a97f-449c-b263-e94e4c7212ee/2106.00750v1.pdf)
