# Unsupervised Time-Series Representation Learning with Iterative Bilinear Temporal-Spectral Fusion

### 핵심 주장 및 주요 기여도

본 논문은 **Bilinear Temporal-Spectral Fusion (BTSF)**라는 비지도 시계열 표현 학습 프레임워크를 제안합니다. BTSF의 핵심 주장은 기존 시계열 표현 학습 방법들이 두 가지 중요한 문제를 해결하지 못한다는 점입니다. 첫째, 시간 슬라이싱 기반의 세그먼트 단위 증강은 전역 맥락의 손실로 인해 장기 의존성을 포착할 수 없으며 거짓 음성(false negatives)을 유발합니다. 둘째, 기존 방법들은 시간 영역의 정보만 활용하고 스펙트럼 정보 간의 관계를 무시하여 표현의 판별력을 제한합니다.[1]

BTSF의 주요 기여는 다음과 같습니다:[1]

1. **인스턴스 단위 증강 기법**: 전체 시계열을 입력으로 사용하고 단순 드롭아웃을 적용하여 전역 맥락을 최대한 보존합니다.
2. **반복적 쌍선형 시간-스펙트럼 융합**: 시간 및 스펙트럼 특성 간의 쌍방향 의존성을 명시적으로 모델링합니다.
3. **일반화 능력 평가**: 정렬(alignment)과 균일성(uniformity) 지표를 통해 학습된 표현의 일반화 능력을 평가합니다.

***

### 해결하고자 하는 문제 및 방법론

#### 문제 정의

시계열 데이터는 복잡한 동역학과 희소한 주석으로 인해 비지도 표현 학습이 도전적입니다. 기존의 대비 학습(contrastive learning) 기반 방법들(CPC, TS-TCC, TNC 등)은 세그먼트 단위 샘플링 정책에 의존하여 장기 의존성을 포착하지 못하고, 시간-스펙트럼 정보의 통합을 무시합니다.[1]

#### 제안하는 방법

**1. 인스턴스 단위 증강 기법**

기존의 시간 슬라이싱 방식 대신, 전체 시계열 $$x$$에 두 개의 독립적인 드롭아웃 마스크를 적용하여 양성 쌍을 생성합니다:[1]

$$
x_{anc} = \text{Dropout}(x), \quad x_{pos} = \text{Dropout}(x)
$$

드롭아웃 비율은 0.1로 설정되며, 다른 변수의 시계열을 음성 샘플로 사용합니다. 이 방식은 비정상(non-stationary)과 주기적(periodic) 시계열 모두에 적용 가능합니다.[1]

**2. 반복적 쌍선형 시간-스펙트럼 융합**

먼저 시계열을 시간 영역과 스펙트럼 영역으로 변환합니다:[1]

$$
F_t = \text{EncoderA}(x_t; \theta_t), \quad F_s = \text{EncoderB}(x_s; \theta_s)
$$

여기서 $$F_t \in \mathbb{R}^{m \times d}$$는 시간 특성, $$F_s \in \mathbb{R}^{n \times d}$$는 스펙트럼 특성입니다. 채널 간 상호작용을 통해 쌍선형 특성을 생성합니다:[1]

$$
F_{i,j} = F_t^i{}^T F_s^j
$$

모든 시간-주파수 쌍의 유사성을 합산하여 쌍선형 특성 벡터를 생성합니다:[1]

$$
F_{\text{bilinear}} = F_t^T F_s = \sum_{i=1}^{m} \sum_{j=1}^{n} F_t^i{}^T F_s^j
$$

**3. 교차 도메인 정제 루프**

스펙트럼-시간(S2T)과 시간-스펙트럼(T2S) 집계 모듈을 통해 시간 및 스펙트럼 특성을 반복적으로 정제합니다:[1]

$$
F_t' = \text{S2T}(F_{\text{bilinear}}), \quad F_s' = \text{T2S}(F_{\text{bilinear}})
$$

**4. 저차원 변환 및 메모리 최적화**

원래의 쌍선형 특성 $$F_{\text{bilinear}} \in \mathbb{R}^{d \times d}$$의 메모리 오버헤드를 해결하기 위해 상호작용 행렬 $$W \in \mathbb{R}^{m \times n}$$을 저차 인수분해합니다:[1]

$$
F_{\text{bilinear}} = F_t^T U V^T F_s
$$

여기서 $$U \in \mathbb{R}^{m \times l}$$, $$V \in \mathbb{R}^{n \times l}$$이고 $$l \ll d$$입니다. 이를 통해 메모리를 $$O(d^2)$$에서 $$O(ld)$$로 감소시킵니다.[1]

**5. 최종 표현 및 손실 함수**

최종 결합 표현은 원래 시간 및 스펙트럼 특성과 쌍선형 특성을 결합합니다:[1]

$$
f = \sigma(W_t^T F_t + W_s^T F_s + F_t^T W F_s)
$$

여기서 $$\sigma$$는 시그모이드 함수입니다. 대비 손실은 다음과 같이 정의됩니다:[1]

$$
L = \mathbb{E}_{X \sim P_{\text{data}}} \log \text{sim}(f_{anc}, f_{pos}) - \mathbb{E}_{x_{neg} \in X} \log \text{sim}(f_{anc}, f_{neg})
$$

***

### 모델 구조 및 설계 원리

**전체 아키텍처**[1]

BTSF 모델은 다음과 같은 구조를 가집니다:

1. **입력 처리**: 드롭아웃을 통한 데이터 증강
2. **인코더**: EncoderA (팽창 인과 컨볼루션)와 EncoderB (1D 컨볼루션 블록)
3. **쌍선형 융합**: 반복적 시간-스펙트럼 상호작용
4. **집계 모듈**: S2T와 T2S 모듈을 통한 교차 도메인 정보 교환

**그래디언트 흐름 분석**[1]

모델의 효율성을 증명하기 위해 손실 함수로부터 그래디언트 흐름을 분석합니다:

$$
\frac{\partial L}{\partial F_t} = \frac{\partial L}{\partial f} W_t - \frac{\partial L}{\partial f} W F_s
$$

$$
\frac{\partial L}{\partial F_s} = \frac{\partial L}{\partial f} W_s - \frac{\partial L}{\partial f} W^T F_t
$$

이는 시간 특성의 그래디언트 업데이트가 스펙트럼 특성과 밀접하게 관련되어 있음을 보여줍니다. 상호작용 행렬 $$W$$의 그래디언트는 교차 도메인 유사성 $$F_t F_s^T$$과 강하게 연결되어 있으며, 이는 시간-스펙트럼 특성의 더 나은 결합을 유도합니다.[1]

---

### 성능 향상 및 일반화 능력

#### 성능 개선 결과

**시계열 분류**[1]

| 데이터셋 | 방법 | 정확도 | AUPRC |
|---------|------|--------|--------|
| HAR | Supervised | 92.03% | 0.98 |
| HAR | TNC | 88.32% | 0.94 |
| HAR | **BTSF** | **94.63%** | **0.99** |
| Sleep-EDF | Supervised | 83.41% | 0.78 |
| Sleep-EDF | TNC | 82.97% | 0.76 |
| Sleep-EDF | **BTSF** | **87.45%** | **0.79** |
| ECG | Supervised | 84.81% | 0.67 |
| ECG | TNC | 77.79% | 0.55 |
| ECG | **BTSF** | **85.14%** | **0.68** |

BTSF는 모든 데이터셋에서 기존 방법들을 크게 능가하며, 심지어 지도 학습 방법보다 우수한 성능을 보입니다.[1]

**시계열 예측**[1]

장기 시계열 예측(LSTF) 작업에서 BTSF는 다양한 예측 길이에서 최소 예측 오차를 달성합니다. 특히 데이터셋의 길이가 증가할수록 전역 맥락을 더 잘 활용하여 장기 의존성을 포착하는 성능 향상을 보입니다.[1]

**시계열 이상 탐지**[1]

| 데이터셋 | Supervised | SRL | CPC | TS-TCC | TNC | **BTSF** |
|---------|-----------|-----|-----|--------|-----|---------|
| SWaT | 0.901 | 0.710 | 0.738 | 0.775 | 0.799 | **0.944** |
| WADI | 0.649 | 0.340 | 0.382 | 0.427 | 0.440 | **0.685** |
| SMD | 0.958 | 0.768 | 0.732 | 0.794 | 0.817 | **0.972** |

BTSF는 모든 이상 탐지 데이터셋에서 새로운 최고 성능(SOTA)을 달성합니다.[1]

#### 일반화 능력 평가

**정렬(Alignment) 및 균일성(Uniformity)**[1]

논문은 학습된 표현의 품질을 평가하기 위해 두 가지 중요한 특성을 분석합니다:

1. **정렬**: 긍정 쌍 간의 유사성을 측정하여 표현이 노이즈에 불변인지 평가합니다. BTSF는 긍정 쌍 간의 최고 평균 특성 거리를 달성하여 최고의 정렬을 보입니다.[1]

2. **균일성**: 학습된 특성이 인코딩 공간에 균등하게 분포하는지 측정합니다. BTSF의 특성은 다른 방법들보다 더 균등하게 분포하여 최대 정보를 보존합니다.[1]

**교차 도메인 상호작용 효과**[1]

반복적 쌍선형 융합의 영향을 조사한 결과, BTSF는 시간 및 스펙트럼 도메인 간에 96.60%의 높은 중복을 달성하는 반면, 기존 방법들은 약 30% 정도의 중복만 달성합니다. 이는 BTSF가 두 도메인 간의 효과적인 상호작용을 이루어낸다는 것을 입증합니다.[1]

**절제 연구(Ablation Study)**[1]

| 구성요소 | 정확도 |
|---------|--------|
| 기본선 (TNC) | 88.3% |
| + 드롭아웃 증강 | 89.4% |
| + 스펙트럼 특성 | 89.8% |
| + 합/연결 결합 | 90.7% |
| + 쌍선형 융합 | 92.4% |
| + 반복적 쌍선형 | **94.6%** |

각 구성요소가 단계적으로 성능을 향상시킴을 보여줍니다.[1]

***

### 모델의 한계

논문에서 명시적으로 언급되지는 않지만, 다음과 같은 잠재적 한계가 있습니다:[1]

1. **메모리 오버헤드**: 초기 쌍선형 특성의 이차 확장으로 인한 메모리 문제는 저차 인수분해로 완화되지만, 여전히 계산 비용이 존재합니다.[1]

2. **초매개변수 의존성**: 드롭아웃 비율(0.1), 온도 매개변수(0.05), 반복 루프 수(3)와 같은 여러 초매개변수가 성능에 영향을 미칩니다.[1]

3. **실시간 응용의 적응성**: 장기 시계열에 최적화되어 있어 단기 시계열이나 특정 도메인(예: 금융 시계열)에서의 성능 특성이 명확하지 않습니다.[1]

4. **스펙트럼 정보의 가정**: FFT 기반 스펙트럼 변환은 주기적 신호에 최적화되어 있어, 강한 비정상성을 가진 시계열에 대한 적용성이 제한될 수 있습니다.[1]

***

### 연구에 미치는 영향 및 향후 고려사항

#### 학술적 영향

1. **시간-스펙트럼 통합의 중요성 입증**: 본 논문은 시계열 표현 학습에서 시간 영역과 스펙트럼 영역의 통합이 얼마나 중요한지 명확히 보여줍니다. 기존 방법들의 약 30%의 도메인 간 중복도에서 BTSF의 96.60%로의 향상은 혁신적입니다.[1]

2. **인스턴스 단위 증강의 효과**: 세그먼트 단위 시간 슬라이싱에서 벗어나 전체 시계열을 활용하는 접근법은 향후 시계열 자기 지도 학습 연구에 새로운 방향을 제시합니다.[1]

3. **세 가지 주요 작업에 대한 동시 평가**: 분류, 예측, 이상 탐지 세 가지 작업에서 모두 우수한 성능을 보임으로써 표현 학습의 일반성을 입증합니다.[1]

#### 향후 연구 시 고려사항

1. **비균형 데이터 처리**: 실제 산업 환경에서는 클래스 불균형이 심하므로, BTSF가 이러한 상황에서 어떻게 작동하는지에 대한 연구가 필요합니다.[1]

2. **도메인 적응(Domain Adaptation)**: 서로 다른 도메인의 시계열 데이터 간 적응 학습 능력 강화는 BTSF의 실용성을 크게 향상시킬 수 있습니다.[1]

3. **계산 효율성**: 반복적 쌍선형 융합의 계산 복잡도를 더욱 감소시키는 연구로 모바일이나 엣지 장비에서의 적용을 가능하게 할 수 있습니다.[1]

4. **다중 스케일 시간 관계**: 다양한 시간 스케일에서의 의존성을 캡처하기 위한 멀티스케일 쌍선형 융합 확장이 고려될 수 있습니다.[1]

5. **비지도 학습 성능의 이론적 보장**: 학습된 표현이 왜 지도 학습을 능가하는지에 대한 이론적 분석은 표현 학습의 근본적 이해를 제공할 것입니다.[1]

6. **자체적응형 하이퍼파라미터 조정**: 다양한 시계열 특성에 맞춰 자동으로 드롭아웃 비율과 반복 루프 수를 조정하는 메커니즘의 개발은 모델의 적응성을 향상시킬 수 있습니다.[1]

본 논문의 BTSF는 시계열 표현 학습의 새로운 패러다임을 제시하며, 특히 시간-스펙트럼 정보의 명시적 통합과 인스턴스 단위 증강의 조합이 매우 효과적임을 증명함으로써 향후 시계열 자기 지도 학습 분야의 발전에 중요한 기여를 합니다.[1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/018a9266-acf4-4167-a7c6-d27fa674d9fc/2202.04770v3.pdf)
