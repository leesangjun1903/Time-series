<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" style="height:64px;margin-right:32px"/>

## 1. 핵심 주장과 주요 기여

"Towards Better Forecasting by Fusing Near and Distant Future Visions"는 다변량 시계열 예측(multivariate time series forecasting)에서 서로 다른 시간적 거리를 갖는 미래 예측 과제들 간의 상호작용을 활용하여 예측 정확도를 향상시키는 Multi-Level Construal Neural Network (MLCNN)을 제안합니다. 이 논문은 심리학의 해석 수준 이론(Construal Level Theory, CLT)에서 영감을 받아, 근거리 미래와 원거리 미래에 대한 서로 다른 수준의 추상적 표현을 융합하는 다중 과제 학습 프레임워크를 설계했습니다.[^1_1]

### 주요 기여

- **다중 수준 추상화 메커니즘**: CNN을 사용하여 서로 다른 깊이의 계층에서 추출된 다양한 추상화 수준의 특징을 각기 다른 예측 과제에 할당[^1_1]
- **미래 비전 융합 아키텍처**: Encoder-Decoder 구조를 수정하여 다중 예측 과제의 상호작용을 모델링하고 그들의 미래 비전을 융합[^1_1]
- **하이브리드 모델 설계**: 전통적인 자기회귀(AR) 모델과 신경망을 결합하여 스케일 변화에 민감하지 않은 강건한 예측 모델 구축[^1_1]
- **실증적 성과**: 세 가지 실제 데이터셋에서 RMSE 평균 4.59%, MAE 평균 6.87% 개선을 달성[^1_1]


## 2. 상세 분석

### 해결하고자 하는 문제

기존의 대부분의 시계열 예측 모델들은 단일 미래 시점 $X_{t+h}$ 또는 연속된 미래 구간 $\{X_{t+1}, ..., X_{t+h}\}$만을 예측하며, 서로 다른 시간적 거리를 갖는 예측들 간의 연관성을 무시합니다. 이러한 결핍은 모델이 미래에 대한 충분한 정보를 얻지 못하게 하여 일반화 능력을 제한할 수 있습니다.[^1_1]

기본 예측 문제는 다음과 같이 정의됩니다:

$E[X_{t+h}|X_t, ..., X_{t-p+1}] = f(X_t, ..., X_{t-p+1})$

여기서 $X_{t+h}$는 조건부 평균을 나타내며, $p$는 과거 관측 윈도우의 길이, $h$는 예측 수평선(horizon)입니다.[^1_1]

### 제안하는 방법

#### (1) 다중 과제 설정

논문은 미래 스팬(future span, $fsp$)과 미래 스트라이드(future stride, $fst$)를 정의하여 보조 예측 과제를 지정합니다. 기본 설정($fsp=2$, $fst=1$)에서는 다음 5개의 시점을 동시에 예측합니다:[^1_1]

$\{X_{t+h-2}, X_{t+h-1}, X_{t+h}, X_{t+h+1}, X_{t+h+2}\}$

여기서 $X_{t+h-2}$와 $X_{t+h-1}$은 근거리 미래 비전, $X_{t+h+1}$과 $X_{t+h+2}$는 원거리 미래 비전을 제공합니다.[^1_1]

#### (2) 합성곱 컴포넌트

다층 CNN을 사용하여 서로 다른 추상화 수준의 구성물(construals)을 생성합니다:

$C_{t+h-2} = f_1(X_t^{-p})$
$C_{t+h-1} = f_2(C_{t+h-2})$
$C_{t+h} = f_3(C_{t+h-1})$
$C_{t+h+1} = f_4(C_{t+h})$
$C_{t+h+2} = f_5(C_{t+h+1})$

여기서 $X_t^{-p} = [X_{t-p+1}; X_{t-p+2}; ...; X_t] \in \mathbb{R}^{p \times n}$는 입력 행렬이고, $f_i$는 Conv1D 레이어입니다. 각 필터의 출력은 다음과 같이 계산됩니다:[^1_1]

$c_k = \text{Act}(W_k * X + b_k)$

여기서 LeakyReLU 활성화 함수가 사용됩니다: $\text{LeakyReLU}(x) = \begin{cases} x & x \geq 0 \\ \alpha x & \text{otherwise} \end{cases}$ ($\alpha = 0.01$).[^1_1]

#### (3) 공유 순환 컴포넌트 (Fusion Encoder)

공유 LSTM은 모든 예측 과제에 대한 구성물을 순차적으로 처리하여 미래 비전을 융합합니다. 시간 $\tau$에서 $k$번째 구성물에 대한 LSTM의 상태는 다음과 같이 계산됩니다:

$i_k^{(\tau)} = \sigma(W_{ii}C_k^{(\tau)} + b_{ii} + W_{hi}h_k^{(\tau-1)} + b_{hi})$
$f_k^{(\tau)} = \sigma(W_{if}C_k^{(\tau)} + b_{if} + W_{hf}h_k^{(\tau-1)} + b_{hf})$
$g_k^{(\tau)} = \tanh(W_{ig}C_k^{(\tau)} + b_{ig} + W_{hg}h_k^{(\tau-1)} + b_{hg})$
$o_k^{(\tau)} = \sigma(W_{io}C_k^{(\tau)} + b_{io} + W_{ho}h_k^{(\tau-1)} + b_{ho})$
$c_k^{(\tau)} = f_k^{(\tau)} \odot c_k^{(\tau-1)} + i_k^{(\tau)} \odot g_k^{(\tau)}$
$h_k^{(\tau)} = o_k^{(\tau)} \odot \tanh(c_k^{(\tau)})$

여기서 $k \in \{t+h-2, t+h-1, ..., t+h+2\}$이고, $\odot$는 원소별 곱셈입니다.[^1_1]

#### (4) 주 순환 컴포넌트 (Main Decoder)

주 예측 과제 ($X_{t+h}$)에 대해서는 별도의 주 LSTM을 사용합니다:

$h_{t+h}^{\prime(p)} = \text{MainLSTM}(C_{t+h}, h_{t+h}^{(p)}, c_{t+h}^{(p)})$

여기서 초기 은닉 상태와 셀 상태가 공유 LSTM의 출력 $h_{t+h}^{(p)}$와 $c_{t+h}^{(p)}$로 설정됩니다.[^1_1]

#### (5) 자기회귀 컴포넌트

스케일 변화 문제를 해결하기 위해 선형 AR 모델을 추가합니다:

$r_k^L = \sum_{j=0}^{qsar} W_k^L X_{j,i}^{qar} + b_k^L$

여기서 $X^{qar} = [X_t; X_{t-1}; ...; X_{t-qsar+1}] \in \mathbb{R}^{qsar \times n}$이고, $sar$은 자기회귀 스트라이드입니다.[^1_1]

#### (6) 최종 예측

신경망 출력과 AR 출력을 결합합니다:

$\hat{Y}_k = r_k^D + r_k^L$

여기서 $r_k^D$는 Dense 레이어의 출력입니다.[^1_1]

#### (7) 손실 함수

L2 손실 또는 L1 손실을 사용합니다:

$L_2(Y, \hat{Y}) = \sum_{\Omega_{train}} \sum_{k=1}^l \sum_{j=1}^n (Y_{k,j} - \hat{Y}_{k,j})^2$

$L_1(Y, \hat{Y}) = \sum_{\Omega_{train}} \sum_{k=1}^l \sum_{j=1}^n |Y_{k,j} - \hat{Y}_{k,j}|$

Adam 최적화 알고리즘으로 최소화합니다.[^1_1]

### 모델 구조

MLCNN의 전체 아키텍처는 다음과 같이 구성됩니다:

1. **입력 레이어**: 과거 $p$ 시점의 다변량 시계열 데이터 $X_t^{-p} \in \mathbb{R}^{p \times n}$[^1_1]
2. **합성곱 특징 추출기**: 10개의 Conv1D 레이어로 5개의 다른 추상화 수준의 구성물 생성[^1_1]
3. **공유 LSTM 인코더**: 모든 과제의 구성물을 처리하여 융합 특징 생성[^1_1]
4. **주 LSTM 디코더**: 주 예측 과제를 위한 전용 디코더[^1_1]
5. **AR 컴포넌트**: 각 예측 과제에 대한 선형 자기회귀 모델[^1_1]
6. **출력 레이어**: Dense 레이어를 통한 최종 예측 생성[^1_1]

### 성능 향상

#### 실험 결과

세 가지 실제 데이터셋에서 평가했습니다:

- **Traffic**: 862개 변수, 17,544 샘플 (캘리포니아 도로 점유율)[^1_1]
- **Energy**: 26개 변수, 19,735 샘플 (가전제품 에너지 소비)[^1_1]
- **NASDAQ**: 82개 변수, 40,560 샘플 (주식 가격)[^1_1]

주요 성과:

- **Traffic 데이터셋 (t+3 예측)**: LSTNet 대비 RMSE 4.09% 개선, MAE 5.17% 개선[^1_1]
- **평균 개선**: 모든 baseline 대비 RMSE 평균 4.59%, MAE 평균 6.87% 감소[^1_1]
- **통계적 유의성**: Two-sample t-test (5% 유의수준)에서 LSTNet 대비 통계적으로 유의미한 개선 확인[^1_1]


### 한계

1. **하이퍼파라미터 선택**: $fsp$와 $fst$ 값을 고정값(기본값 2와 1)으로 설정하며, 동적으로 선택하는 메커니즘이 없음[^1_1]
2. **가중치 메커니즘 부재**: 서로 다른 미래 비전에 대한 적응적 가중치(예: Attention 메커니즘) 미구현[^1_1]
3. **모델 복잡도**: 다중 LSTM과 다층 CNN으로 인한 구조적 복잡성[^1_1]
4. **계산 비용**: 다중 과제 학습으로 인한 추가적인 계산 부담 (단, 파라미터 공유로 일부 완화)[^1_1]

## 3. 일반화 성능 향상 가능성

### 이론적 근거

MLCNN의 일반화 성능 향상은 다음 메커니즘을 통해 달성됩니다:

#### (1) 다중 과제 학습의 정규화 효과

다중 과제 학습은 암묵적 정규화(implicit regularization) 효과를 제공합니다. 서로 다른 시간적 거리의 예측 과제들이 공통의 표현을 학습하도록 강제함으로써, 모델이 개별 과제의 잡음에 과적합되는 것을 방지합니다.[^1_1]

#### (2) 미래 비전의 다양성

근거리 미래와 원거리 미래에 대한 서로 다른 관점을 통합함으로써, 모델은 단일 시간 스케일에만 의존하지 않고 다양한 시간적 패턴을 학습합니다. 이는 해석 수준 이론(CLT)의 심리학적 통찰을 반영한 것으로, 사람들이 근거리 사건에는 구체적 특징을, 원거리 사건에는 추상적 특징을 사용하는 방식을 모방합니다.[^1_1]

#### (3) 계층적 특징 추출

다층 CNN 구조는 서로 다른 추상화 수준의 특징을 자동으로 학습합니다:[^1_1]

- **낮은 레이어**: 지역적, 세밀한 패턴 (근거리 미래 예측용)
- **깊은 레이어**: 전역적, 추상적 패턴 (원거리 미래 예측용)

이러한 계층적 표현은 모델이 다양한 시간 스케일의 패턴을 효과적으로 포착하게 합니다.[^1_1]

### 실증적 증거

#### Ablation Study 결과

논문의 변형 비교 실험에서 각 구성요소의 기여를 확인했습니다:[^1_1]

- **MLCNN-nL** (동일 추상화 레벨 사용): 성능 저하 및 분산 증가 → 다중 수준 구성물의 중요성 입증[^1_1]
- **MLCNN-nS** (공유 LSTM 제거): 미래 비전 융합 부재로 인한 성능 저하 → 과제 간 상호작용의 중요성 입증[^1_1]
- **MLCNN-nM** (주 LSTM 제거): 단일 LSTM 사용 시 성능 하락 → Encoder-Decoder 구조의 효과 입증[^1_1]


#### 파라미터 민감도 분석

MLCNN은 다양한 하이퍼파라미터 설정에서 안정적인 성능을 보여, LSTNet 및 다른 변형들보다 파라미터 변화에 덜 민감함을 확인했습니다. 이는 모델의 강건성과 일반화 능력을 시사합니다.[^1_1]

#### 시간 복잡도 효율성

파라미터 공유 메커니즘 덕분에 MLCNN의 학습 및 예측 시간은 다른 baseline들과 유사한 수준을 유지하면서도, 고차원 시계열에서는 VAR 및 AECRNN보다 우수한 효율성을 보입니다.[^1_1]

## 4. 향후 연구에 미치는 영향과 고려사항

### 영향

#### (1) 다중 과제 학습 패러다임의 확장

MLCNN은 시계열 예측에서 다중 과제 학습의 새로운 적용 방식을 제시했습니다. 기존의 AECRNN과 달리, 동일한 변수의 서로 다른 시간적 거리 예측을 보조 과제로 활용하는 자연스러운 프레임워크를 제공합니다.[^1_1]

#### (2) 해석 수준 이론의 기계학습 적용

심리학 이론(CLT)을 딥러닝 아키텍처 설계에 적용한 선구적 사례로, 인지과학과 기계학습의 학제간 융합 가능성을 보여줍니다.[^1_1]

#### (3) 하이브리드 모델링 접근

신경망과 전통적 통계 모델(AR)의 결합이 스케일 변화 문제 해결에 효과적임을 재확인하여, 하이브리드 접근의 중요성을 강조했습니다.[^1_1]

### 향후 연구 고려사항

#### (1) 적응적 가중치 메커니즘

논문의 저자들이 제안한 대로, Attention 메커니즘을 통한 서로 다른 미래 비전의 동적 가중치 조정이 필요합니다. 이는 모델이 데이터의 특성에 따라 근거리/원거리 정보의 중요도를 자동으로 조절하게 할 것입니다.[^1_1]

#### (2) 동적 시간 범위 선택

$fsp$와 $fst$ 파라미터를 데이터 기반으로 자동 선택하는 메타 학습 또는 신경 아키텍처 탐색(NAS) 기법 적용이 필요합니다.[^1_1]

#### (3) 설명 가능성 향상

다중 과제 학습에서 각 보조 과제가 주 과제에 기여하는 정도를 정량화하고 시각화하는 해석 기법 개발이 요구됩니다.

#### (4) 확장성 문제

매우 긴 수평선이나 고차원 시계열에서의 확장성 연구가 필요하며, 특히 메모리 효율적인 구현이 중요합니다.

## 5. 2020년 이후 관련 최신 연구 비교 분석

### Attention 기반 다중 과제 학습

#### Multi-Task Time Series Forecasting With Shared Attention (2020)

이 연구는 병렬 Transformer 인코더와 외부 공유 multi-head attention을 사용하여 다중 과제 시계열 예측을 수행합니다. MLCNN과의 주요 차이점:[^1_2]

- **공통점**: 다중 과제 간 정보 공유 메커니즘 사용[^1_2]
- **차이점**: MLCNN은 CNN 기반 계층적 특징 추출을 사용하는 반면, 이 연구는 Transformer의 self-attention 메커니즘에 의존[^1_2]
- **장점**: Attention 메커니즘이 장기 의존성 포착에 더 효과적일 수 있음[^1_2]


#### Multiple Stock Time Series Jointly Forecasting (2020)

주식 간 상호 연관성을 활용한 다중 과제 학습을 제안하며, Shared-Private Attention 메커니즘을 도입했습니다.[^1_3]

- **차이점**: MLCNN은 동일 시계열의 다른 시간적 거리를 예측하는 반면, 이 연구는 서로 다른 주식(변수)을 별도 과제로 취급[^1_3]
- **통찰**: 공유-사적 정보 균형 메커니즘은 MLCNN의 미래 개선 방향 제시[^1_3]


### Foundation Models 및 대규모 사전학습

#### PatchFormer (2026)

Patch 기반 시계열 foundation model로, 계층적 masked reconstruction과 cross-domain transfer learning을 사용합니다.[^1_4]

- **혁신**: Zero-shot 다중 수평선 예측에서 27.3% MSE 감소 달성[^1_4]
- **MLCNN과의 관계**: MLCNN의 계층적 특징 추출 아이디어가 patch 기반 계층적 학습으로 발전[^1_4]
- **규모**: 1000억 데이터 포인트까지 확장 가능한 사전학습[^1_4]


#### UniTS (2024)

Task tokenization을 통해 예측과 생성 과제를 통합한 멀티태스크 모델입니다.[^1_5]

- **차별점**: MLCNN보다 더 일반적인 다중 과제 프레임워크 제공 (예측뿐만 아니라 생성, 분류 등)[^1_5]
- **한계**: 특정 예측 과제에서는 MLCNN과 같은 specialized 모델이 더 효과적일 수 있음[^1_5]


### Temporal Fusion Transformer (TFT)

#### GridFM (2026)

물리 정보 기반 foundation model로, FreqMixer 적응 레이어와 다중 과제 학습을 결합했습니다.[^1_6]

- **물리 제약**: 전력 균형 방정식과 그래프 신경망을 통한 도메인 지식 통합[^1_6]
- **MLCNN 대비 진전**: 도메인 특화 지식을 다중 과제 학습에 명시적으로 통합[^1_6]


#### TFT 기반 연구 (2021-2024)

Variable Selection Network(VSN)와 해석 가능한 multi-head attention을 통해 변수 및 시간별 중요도를 제공합니다.[^1_7][^1_8]

- **해석성**: MLCNN에 부족한 해석 가능성을 제공[^1_7]
- **적용**: 수천 개의 단변량/다변량 시계열 학습 가능[^1_8]


### 경량화 및 효율성

#### TSMixer (2023)

MLP 기반 경량 모델로, Transformer의 높은 계산 비용 문제를 해결합니다.[^1_9]

- **효율성**: MLCNN의 CNN+LSTM 구조보다 더 경량화된 MLP-only 아키텍처[^1_9]
- **성능**: 장기 예측에서 Transformer와 경쟁력 있는 성능[^1_9]


#### GLinear (2025)

데이터 효율적인 선형 기반 아키텍처로, Transformer의 복잡성을 줄입니다.[^1_10]

- **MLCNN의 AR 컴포넌트와 유사**: 선형 모델의 중요성 재확인[^1_10]
- **차이**: MLCNN은 하이브리드 접근인 반면, GLinear는 순수 선형 기반[^1_10]


### 최신 Attention 및 Decomposition 기법

#### SageFormer (2024)

Series-aware 프레임워크로 intra- 및 inter-series 의존성을 명시적으로 모델링합니다.[^1_11]

- **MLCNN의 한계 극복**: Inter-series 의존성을 더 체계적으로 처리[^1_11]


#### Autoformer \& FEDformer (2021-2022)

Spectral analysis와 decomposition을 결합하여 장기 의존성과 다중 스케일 구조를 처리합니다.[^1_12]

- **기술적 진전**: MLCNN의 CNN 기반 다중 스케일 추출을 주파수 도메인으로 확장[^1_12]


#### DisenTS (2024)

Disentangled channel evolving patterns을 모델링하는 Forecaster Aware Gate(FAG) 도입.[^1_13]

- **차별점**: 채널별 패턴을 명시적으로 분리하여 MLCNN보다 더 세밀한 제어 제공[^1_13]


### 종합 비교

| 측면 | MLCNN (2019) | 최신 연구 (2020-2026) |
| :-- | :-- | :-- |
| **다중 과제 전략** | 동일 변수의 다른 시간 거리 예측[^1_1] | 이종 과제 통합, task tokenization[^1_5] |
| **특징 추출** | CNN 기반 계층적 추상화[^1_1] | Patch 기반[^1_4], Spectral[^1_12], Attention[^1_2] |
| **사전학습** | 없음 | Foundation models with 100B+ points[^1_4] |
| **해석성** | 제한적[^1_1] | Variable/Temporal importance[^1_7][^1_8] |
| **효율성** | 중간 수준[^1_1] | 경량 MLP[^1_9], 선형 모델[^1_10] |
| **Zero-shot** | 불가능 | 가능[^1_4][^1_14] |
| **도메인 지식** | 없음 | 물리 제약 통합[^1_6] |

### 핵심 발전 방향

1. **Foundation Models로의 전환**: MLCNN의 task-specific 학습에서 대규모 사전학습 기반 전이 학습으로 패러다임 이동[^1_14][^1_4]
2. **해석 가능성 강화**: Variable Selection과 Attention visualization을 통한 투명성 향상[^1_8][^1_7]
3. **효율성 개선**: MLP, 선형 모델 등 경량 아키텍처가 복잡한 Transformer와 경쟁[^1_9][^1_10]
4. **도메인 특화**: 물리 법칙, 그래프 구조 등 도메인 지식의 명시적 통합[^1_6]
5. **다중 모달 융합**: LLM과 시계열 모델의 결합으로 semantic pattern 활용[^1_15][^1_16]

MLCNN은 다중 과제 학습의 기초를 마련했으며, 이후 연구들은 이를 확장하여 더 일반적이고 효율적이며 해석 가능한 모델로 발전시켰습니다. 특히 2023년 이후 foundation model 접근법이 주류가 되면서, MLCNN의 핵심 아이디어인 "다양한 시간적 관점의 융합"은 대규모 사전학습과 zero-shot 예측의 맥락에서 재해석되고 있습니다.[^1_14][^1_4]
<span style="display:none">[^1_17][^1_18][^1_19][^1_20][^1_21][^1_22][^1_23][^1_24][^1_25][^1_26][^1_27][^1_28][^1_29][^1_30][^1_31][^1_32][^1_33][^1_34][^1_35][^1_36][^1_37][^1_38]</span>

<div align="center">⁂</div>

[^1_1]: 1912.05122v1.pdf

[^1_2]: https://ieeexplore.ieee.org/document/9346331/

[^1_3]: https://ieeexplore.ieee.org/document/9207543/

[^1_4]: https://www.semanticscholar.org/paper/3abce6e2b1f3905acce518f039fb0f1aca36699f

[^1_5]: https://arxiv.org/pdf/2403.00131v3.pdf

[^1_6]: https://www.mdpi.com/1996-1073/19/2/357

[^1_7]: https://www.mathworks.com/help/deeplearning/ug/time-series-forecasting-using-temporal-fusion-transformer.html

[^1_8]: https://aihorizonforecast.substack.com/p/temporal-fusion-transformer-time

[^1_9]: https://arxiv.org/pdf/2306.09364.pdf

[^1_10]: http://arxiv.org/pdf/2501.01087.pdf

[^1_11]: https://arxiv.org/pdf/2307.01616.pdf

[^1_12]: https://www.ewadirect.com/proceedings/ace/article/view/31299

[^1_13]: http://arxiv.org/pdf/2410.22981.pdf

[^1_14]: https://www.semanticscholar.org/paper/83a0afa70fb75488078a696d762f0b8b34d6f96b

[^1_15]: https://arxiv.org/html/2503.22747v1

[^1_16]: https://arxiv.org/html/2507.10098v1

[^1_17]: https://ieeexplore.ieee.org/document/11230677/

[^1_18]: https://www.semanticscholar.org/paper/4307c388907e607b9b06ef5384f8df6929210b6e

[^1_19]: https://www.mdpi.com/1996-1073/13/18/4722

[^1_20]: https://hdl.handle.net/2117/328183

[^1_21]: https://arxiv.org/pdf/2209.14413.pdf

[^1_22]: https://arxiv.org/pdf/2109.01657.pdf

[^1_23]: https://arxiv.org/pdf/2307.09543.pdf

[^1_24]: https://www.biorxiv.org/content/10.64898/2026.01.07.698166v1.full.pdf

[^1_25]: https://pdfs.semanticscholar.org/fb76/33dcdeb50f0abdd840d44e23e4afa44a2fde.pdf

[^1_26]: https://pdfs.semanticscholar.org/ae0a/6a2b344e2e11b0d3ea50e05c51a755d4036e.pdf

[^1_27]: https://arxiv.org/html/2407.17877v1

[^1_28]: https://arxiv.org/html/2406.02486v2

[^1_29]: https://arxiv.org/html/2511.19497v1

[^1_30]: https://www.biorxiv.org/content/10.64898/2025.12.13.694121v1.full.pdf

[^1_31]: https://arxiv.org/html/2410.03159v1

[^1_32]: https://www.sciencedirect.com/science/article/abs/pii/S0952197625036565

[^1_33]: https://arxiv.org/html/2511.08622v2

[^1_34]: https://openreview.net/profile?id=~Binqing_Wu1

[^1_35]: https://par.nsf.gov/servlets/purl/10212862

[^1_36]: https://milvus.io/ai-quick-reference/how-do-attention-mechanisms-enhance-time-series-forecasting-models

[^1_37]: https://helios2.mi.parisdescartes.fr/~themisp/publications/tsalm24-forecasting.pdf

[^1_38]: https://arxiv.org/html/2402.05370v1

