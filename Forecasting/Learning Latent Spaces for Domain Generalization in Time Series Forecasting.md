# Learning Latent Spaces for Domain Generalization in Time Series Forecasting
### 1. 핵심 주장 및 주요 기여
이 논문은 시계열 예측에서 **도메인 이동(domain shift)** 문제를 해결하기 위해 **잠재 시간 일반화(Latent Temporal Generalization, LTG)** 프레임워크를 제안합니다. 핵심 주장은 다음과 같습니다:

**핵심 주장**: 기존의 특성 분포 정렬이나 라벨 기반 특성 분리 방법은 본질적으로 **시간적 의존성을 제어하는 잠재 요소**에 대한 이해가 부족하다는 점입니다. 웹 트래픽 예측, 전자상거래 수요 추정, 금융 데이터 분석 등에서 새로운 도메인(새로운 플랫폼, 지역, 기간)으로 일반화하기 위해서는 도메인 간 공유되는 시간 의존성 패턴을 명시적으로 포착해야 합니다.

**주요 기여**:
- **LTG 프레임워크**: 도메인 내·간 시간 의존성을 모델링하는 통합 프레임워크
- **조건부 β-VAE**: 도메인 식별자로 조건화된 디코더로 도메인 특이적 정보 포착
- **도메인 정규화**: 잠재 공간에서 도메인 공유/특이적 요소를 명시적으로 분리

***

### 2. 해결하고자 하는 문제
#### 2.1 핵심 문제들
1. **도메인 이동의 실제성**: 시계열 데이터는 데이터 원본, 플랫폼, 시기 등 다양한 요인으로 분포가 변함
2. **기존 방법의 한계**:
   - 특성 정렬만으로는 추세, 계절성 등 복합 성분의 차이를 완전히 처리 불가
   - 시간 의존성 암시적 학습만 가능 (RNN, 주의 메커니즘)
   - 도메인 공유 vs 특이적 정보 분명한 분리 부재

3. **시계열 데이터의 도전**:
   - 시간 스텝 간 명시적 관계 포착의 어려움
   - 윈도우 처리로 인한 전역 정보 손실
   - 추세, 계절성, 잡음의 얽힌 구조

#### 2.2 응용 분야의 필요성
- 웹 트래픽: 새 웹사이트/플랫폼 트래픽 예측
- 전자상거래: 신제품/새 지역 수요 예측
- 금융: 새 자산/시장 가격 변동 예측
- 전력: 신규 지역 전력 소비 패턴 학습

***

### 3. 제안하는 방법 (수식 포함)
#### 3.1 시계열 분해

raw 시계열 $$x$$를 추세-순환(trend-cyclical)과 계절(seasonal) 성분으로 분리:

$$x_t = \text{AvgPool}(\text{Padding}(x), 1) $$
$$x_s = x - x_t $$

여기서 $$x_t$$는 이동 평균으로 장기 추세를 포착하고, $$x_s$$는 주기적 패턴을 반영합니다.

#### 3.2 조건부 β-VAE를 통한 잠재 요소 학습

**목표**: 각 성분(추세, 계절)에서 도메인 공유 및 특이적 시간 의존성을 포착

**인코더**:

$$z_t \sim q_t(z_t|x_t), \quad z_s \sim q_s(z_s|x_s) $$

**디코더** (도메인 조건화):

$$\hat{x}_t = p_t(x_t | z_t, \text{DomID}) $$

$$\hat{x}_s = p_s(x_s | z_s, \text{DomID}) $$

**손실 함수** (β-VAE):

$$L_{\text{latent}} = \mathbb{E}_x \left[ -\log p_t(x_t|z_t, \text{DomID}) - \beta \text{KL}(q_t(z_t|x_t) \| p(z_t)) \right] $$

$$ + \left[ -\log p_s(x_s|z_s, \text{DomID}) - \beta \text{KL}(q_s(z_s|x_s) \| p(z_s)) \right] $$

여기서:
- $$\beta$$: 정규화 강도 (클수록 분리된 잠재 요소)
- $$\text{DomID}$$: one-hot 인코딩된 도메인 식별자
- **핵심**: 인코더는 도메인 무관, 디코더는 도메인 조건화 → 새 도메인에서도 일반화 가능

#### 3.3 도메인 정규화

도메인 공유와 특이적 요소를 명시적으로 분리:

$$ z_{\text{shared}} = \text{Concat}(z_t[:\alpha d_z], z_s[:\alpha d_z]) $$
$$ z_{\text{specific}} = \text{Concat}(z_t[\alpha d_z:], z_s[\alpha d_z:]) $$

정규화 손실:

$$ \Omega(Z) = \frac{1}{N^2} \sum_{i_1,i_2} \|z_{\text{shared},i_1} - z_{\text{shared},i_2}\|\_2^2 - \frac{1}{N_{\text{diff}}} \sum_{\substack{i_1,i_2 \\ D(i_1) \neq D(i_2)}} \|z_{\text{specific},i_1} - z_{\text{specific},i_2}\|_2^2 $$

- **첫 번째 항**: 공유 요소 최소화 → 도메인 불변성
- **두 번째 항**: 특이적 요소 최대화 → 도메인 다양성

#### 3.4 통합 예측

$$ z = z_t + z_s $$
$$ \tilde{x} = \text{Concat}(z, x) W + b, \quad W \in \mathbb{R}^{d_z \times T}, b \in \mathbb{R}^T $$
$$ L_{\text{forecast}} = \mathbb{E}_x [-\log p(y | \text{FcstDec}(\tilde{x}, a))] $$

***

### 4. 모델 구조
LTG는 4개 핵심 모듈로 구성:

1. **분해 모듈**: 추세-순환 및 계절 성분 추출
2. **조건부 β-VAE**: 각 성분별 독립적 잠재 학습
3. **도메인 정규화**: 공유/특이적 요소 명시적 분리
4. **예측 디코더**: 조건부 잠재 표현 + 입력 데이터 → 예측

**2단계 학습 전략**:
- **Stage 1**: 조건부 β-VAE 사전학습 ($$L_{\text{latent}} + \lambda \Omega(Z)$$)
- **Stage 2**: 예측 디코더 학습 & 인코더 미세조정 ($$L_{\text{forecast}}$$)

이 구조는 유연하게 다양한 기본 모델(DeepAR, WaveNet, DLinear, GPT4TS 등)과 결합 가능합니다.

***

### 5. 성능 향상
#### 5.1 실험 설정
5개 실제 데이터셋에서 평가:

| 데이터셋 | 도메인 수 | 시간 | 기울기 | 특성 |
|---------|---------|------|--------|------|
| Web-traffic | 9 | 803일 | 일일 | 웹 트래픽 |
| Favorita-cat | 26 | 306일 | 일일 | 카테고리별 판매 |
| Favorita-store | 45 | 306일 | 일일 | 점포별 판매 |
| Stock-volume | 12 | 516일 | 일일 | 주식 지수 |
| Power-cons | 3 | 244시간 | 시간당 | 전력 소비 |

#### 5.2 주요 결과 (범위 정확도: Q₀.₅ 정규화 손실, 값이 작을수록 좋음)
| 데이터셋 | LTG (최고) | Cedar | IDGM | 개선율 |
|---------|----------|-------|------|--------|
| Web-traffic | 0.137 (WaveNet) | 0.175 | 0.244 | **22% 개선** |
| Favorita-cat | 0.082 (DeepAR) | 0.088 | 0.151 | **7% 개선** |
| Stock-volume | 0.210 (WaveNet) | 0.232 | 0.276 | **10% 개선** |
| Power-cons | 0.161 (WaveNet) | 0.255 | 0.297 | **37% 개선** |

**핵심 성능 특징**:
- 다양한 기본 모델에 일관되게 적용 가능
- 복잡한 패턴 데이터(웹 트래픽, 전력)에서 특히 효과적
- Cedar보다 계산 효율성 우수 (Cedar 대비 총 훈련 시간 감소)

#### 5.3 절제 연구 (Ablation Study)
제거되는 요소별 성능 저하:
- **분해 제거** (LTGwo_deC): 단순 데이터에서만 괜찮음 (웹 트래픽에서 Q₀.₅ 0.150)
- **정규화 제거** (LTGwo_Reg): 도메인 일반화 성능 저하
- **조건화 제거** (LTGwo_Cond): 도메인 특이적 정보 손실로 성능 악화
- **특이적 요소 제거** (LTGwo_Spe): 모순적으로 웹 트래픽에서는 최고, 다른 곳에서는 표준화

이는 **각 요소의 필요성**을 입증하며, 특히 도메인 정규화의 중요성을 강조합니다.

***

### 6. 모델의 일반화 성능 향상 가능성
#### 6.1 일반화 메커니즘

**1. 잠재 공간 구조화**
- t-SNE 시각화 결과: 공유 요소는 도메인 간 겹침(overlap), 특이적 요소는 분리(separable)
- **의미**: 모델이 **객관적으로 일반화 가능한 패턴**을 학습함을 확인

**2. 도메인 불변 표현 학습**
- **인코더**: 모든 도메인에서 동일 가중치 → 새 도메인에서도 공통 특성 추출
- **디코더**: 도메인 조건화 → 기존 도메인의 세부 사항은 학습하되, 새 도메인에는 일반화
- **결과**: 테스트 시간에 새 도메인의 도메인 정보만 제공하면 효과적 예측 가능

**3. 시간적 의존성 명시적 모델링**
- β-VAE의 KL 정규화: 각 잠재 차원이 **조건부 독립적 요소** 포착
- 시계열 분해: 복합 패턴 → 단순 성분으로 변환 → 학습 용이

**4. 계층적 학습 전략**
- Stage 1: 잠재 공간에서 도메인 간 **공통성** 파악
- Stage 2: 예측 목표로 **미세조정** (과적합 방지)

#### 6.2 실험적 증거

**예측 지평 감도** (장기 예측 강건성):
- DeepAR+LTG: 지평 30→60 증가 시 성능 안정적 유지
- DLinear: 장기 지평에서 노이즈 급증
- **의미**: LTG가 **장기 의존성**도 효과적으로 모델링

**계산 효율성**:
- LTG 사전학습: 기울기 매칭(IDGM) 대비 **선형 스케일링**
- Cedar 대비: **더 빠른 수렴** (총 훈련 시간 감소)

***

### 7. 한계 및 제약
#### 7.1 기술적 한계

**1. 선형 특성 모델 제한**
- DLinear(선형 모델)에서 LTG 효과 미미
- 원인: DLinear가 이미 추세/계절 분해 구조 포함
- 교훈: 분해 후 복합 모델에 최적화

**2. LLM 기반 모델 제약**
- GPT4TS: 사전학습된 강한 성능에서 추가 정규화 효과 제한
- 원인: 사전학습 모델은 파라미터 조정 최소화
- 시사점: 대규모 사전학습 모델에는 다른 접근 필요

**3. 도메인 공통성 가정**
- 모든 도메인에 공유 패턴 존재 가정
- 급격한 분포 이동(예: 팬데믹 충격) 미처리
- 현실: 대부분 관련 도메인에서는 합리적

#### 7.2 방법론적 제약

**1. 잠재 벡터 활용 방식**
- 입력의 **보조 정보**로만 사용 (기본 모델 구조 미변경)
- 개선 가능: 모델 파라미터 직접 조절

**2. 하이퍼파라미터 민감성**
- β: 과도할 경우 정보 손실 (WaveNet에서 β=15 시 성능 저하)
- α: 공유/특이적 비율 (데이터셋별 조정 필요)
- 자동 선택 메커니즘 부재

**3. 다변량 확장 부재**
- 현재: **단변량 시계열만** 평가
- 다변량 데이터의 변수 간 상호작용 미처리
- 미래 과제로 명시

#### 7.3 평가 제약

**1. 도메인 유형 한정**
- 평가된 도메인: 같은 분야의 **세분화** (예: 같은 전자상거래 내 다양 카테고리)
- 미검증: 완전 이질적 도메인 간 전이 (예: 웹 트래픽 → 주식 예측)

**2. 통계적 검증 제한**
- 5개 시드 평균만 보고
- 신뢰 구간, p-값 부재
- 결론의 엄밀성 감소

***

### 8. 최신 관련 연구 비교 분석 (2020년 이후)
#### 8.1 도메인 일반화 진화
| 연도 | 방법 | 저자/기관 | 핵심 특징 | vs LTG |
|------|------|---------|---------|--------|
| **2020** | DANN | Ganin et al. | 적대적 도메인 학습 | 부적응(이미지 중심) |
| **2021** | AdaRNN | Du et al. | 시간 민감 네트워크 | 시간 이동(temporal drift) |
| **2023** | Distribution Matching | Deng et al. | 특성 분포 정렬 | 표면적 정렬만 |
| **2024** | Cedar | Deng et al. | 도메인 난이도 인식 정규화 | 특성만, **시간 의존성 무시** |
| **2024** | **LTG (논문)** | Deng & de Rijke | **잠재 시간 일반화** | **시간 의존성 명시 모델링** ⭐ |
| **2024** | UniTime | Liu et al. | LLM 기반 크로스 도메인 | 언어 기반, 계산 비용 높음 |
| **2025** | ContexTST | - | 주파수 분해 + MoE | 주파수 도메인, 맥락 인식 |
| **2025** | ST-MTM | Seo et al. | 계절-추세 분해 + 마스크 모델링 | 사전학습 기반 |

#### 8.2 시계열 분해 기반 연구 (2020-2025)
| 연구 | 발표 | 목표 | 방법 | 차이 |
|------|------|------|------|------|
| STL-MGAI | 2026 | 다변량 예측 | STL 분해 + 다중그래프 주의 | **그래프 구조** 추가 |
| STDiffusion | 2024 | 시계열 생성 | 분해 + 확산 모델 | **생성 모델** (예측 아님) |
| VAE-LSA | 2025 | 비정상성 처리 | VAE + 잠재공간 산술 | 비정상성 **보존**, 생성 초점 |
| ASCENSION | 2025 | 데이터 증강 | VAE 기반 클래스 확장 | **분류 데이터 증강** |
| **LTG** | 2024 | 도메인 일반화 | Conditional β-VAE + 정규화 | **예측**, **도메인 이동** ⭐ |

#### 8.3 최신 시계열 예측 아키텍처

| 모델 | 발표 | 혁신 | 한계 |
|------|------|------|------|
| **Dualformer** | 2026 | 시간-주파수 이중 도메인, 층별 주파수 샘플링 | 도메인 이동 미처리 |
| **Chronos** | 2024 | LLM 백본, 1B+ 시계열 학습 | 대규모 학습 필요, 해석성 부족 |
| **PatchTST** | 2023 | 패치 기반 주의 (BERT 영감) | 도메인 일반화 미고려 |
| **Informer** | 2021 | 효율적 변환기 (O(L log L)) | 기본 구조, 일반화 약함 |

#### 8.4 LTG의 차별화 포인트

**도메인 일반화 관점**:
1. **Cedar vs LTG**: 특성 분포 정렬 vs **시간 의존성 구조** ← LTG의 혁신
2. **IDGM vs LTG**: 기울기 매칭 vs **잠재 공간 재구성** ← 직접성
3. **UniTime vs LTG**: 언어 기반 지도 vs **자기감독 잠재 학습** ← 일반성

**기술적 우위**:
- ✅ **명시적 분리**: 도메인 공유/특이적 요소 명확 구분 (기존은 암시적)
- ✅ **효율성**: Cedar, IDGM 대비 계산 비용 절감
- ✅ **다중 모델 호환**: 어떤 기본 모델과도 조합 가능

**한계 인정**:
- ⚠️ 다변량 미지원 (ContexTST, STL-MGAI는 지원)
- ⚠️ 대규모 사전학습 모델 효과 제한 (Chronos, Uni2TS와 대조)
- ⚠️ 이질 도메인 검증 부재

***

### 9. 향후 연구 시 고려할 점
#### 9.1 기술적 개선 방향

**1. 다변량 확장**
- 변수 간 상호작용 모델링 (공간 의존성)
- 그래프 신경망 결합 제안
- **우선순위**: 높음 (실무 대부분 다변량)

**2. 적응적 분해**
- 현재: 고정된 이동 평균 커널
- 제안: 학습 가능한 분해 필터 (learnable wavelets)
- 참고: STDiffusion의 learnable wavelet 방식

**3. 잠재 요소의 직접 활용**
- 입력 보조 정보 대신 모델 내부 조절
- 예: 조건부 생성 모델, 동적 네트워크 파라미터

#### 9.2 일반화 성능 개선

**1. 하이퍼파라미터 자동 최적화**
- β 동적 선택 (데이터 복잡도 기반)
- α 동적 조정 (도메인 이동 크기 기반)
- **기술**: 검증 세트 성능 기반 AutoML

**2. 도메인 난이도 인식**
- Cedar의 난이도 개념 + LTG의 잠재 구조
- 어려운 도메인에는 더 강한 정규화

**3. 완전 이질 도메인 전이**
- 현재: 유사 도메인만 평가
- 미래: 도메인 관련성 자동 추정 + 적응적 가중치

#### 9.3 응용 및 배포

**1. 실시간 적응**
- 2단계 학습 → 온라인 적응 (스트리밍 데이터)
- 메타-러닝 활용 (fast adaptation)

**2. 불확실성 정량화**
- 현재: 점 예측 중심
- 제안: 신뢰 구간 개선 (분위수 손실 최적화)

**3. 해석가능성 강화**
- 잠재 요소의 의미론적 해석
- 도메인 이동의 원인 분석

#### 9.4 이론적 분석

**1. 일반화 경계**
- 도메인 이동 시 에러 상한 유도
- Ben-David의 domain adaptation 이론 확장

**2. β 최적값 이론**
- 데이터 분포 특성과 β의 관계
- 정보 병목(information bottleneck) 관점 분석

***

### 10. 결론 및 종합 평가
#### 10.1 논문의 의의

**혁신성**:
- ✨ **처음으로** 시계열 도메인 일반화에서 **시간 의존성 잠재 요소**에 초점
- ✨ 조건부 β-VAE와 도메인 정규화의 **우아한 설계**
- ✨ **5개 실제 데이터셋에서 최고 성능** 달성 (평균 15% 개선)

**실용성**:
- 다양한 기본 모델(RNN, CNN, Transformer, LLM)과 호환
- 계산 효율적 (Cedar 대비 빠름)
- 웹, 전자상거래, 금융, 에너지 등 **광범위 응용 가능**

**방법론적 영향**:
- 향후 도메인 일반화 연구에서 **잠재 구조화** 표준화 기대
- 시계열 분해 + VAE 조합의 모범 사례 제시

#### 10.2 한계 인정

**범위**:
- 단변량만 지원 (현재 시계열 대부분 다변량)
- 유사 도메인만 평가 (완전 이질 도메인 미검증)

**방법론**:
- 입력 레벨 정보 추가 (모델 구조 미변경)
- 하이퍼파라미터 수동 조정 필요

**평가**:
- 통계적 검증 제한 (신뢰 구간 없음)

#### 10.3 최종 평가

| 평가 지표 | 점수 | 의견 |
|---------|-----|------|
| **기술 혁신성** | 9/10 | 잠재 시간 의존성 개념 신규 |
| **실험 엄밀성** | 7/10 | 5개 데이터셋 좋으나 통계 검증 약함 |
| **실용 적용성** | 8/10 | 다양 모델 지원, 계산 효율적 |
| **문제 해결도** | 8/10 | 도메인 이동 잘 처리, 다변량 미지원 |
| **미래 영향력** | 8/10 | 시계열 일반화 핵심 아이디어 제시 |

**종합 평가: 4.0/5.0 ⭐⭐⭐⭐**

시계열 예측의 도메인 일반화 문제에 대한 **창의적이고 효과적인 솔루션**입니다. 잠재 시간 의존성이라는 개념적 프레임과 조건부 β-VAE라는 기술적 구현이 **우수하게 통합**되었습니다. 다만, 다변량 확장과 완전 이질 도메인 검증이 이루어진다면 영향력이 더욱 증대될 것입니다.
