# Modeling Irregular Time Series with Continuous Recurrent Units

### 1. 핵심 주장과 주요 기여[1]

**Continuous Recurrent Units (CRU)**는 불규칙한 시간 간격의 시계열 데이터를 모델링하기 위한 신경망 아키텍처입니다. 이 논문의 핵심 주장은 기존 RNN(LSTM, GRU)들이 일정한 시간 간격을 가정하고 있다는 문제를 해결하기 위해, **선형 확률 미분방정식(SDE)으로 표현된 숨겨진 상태**와 **연속-이산 칼만 필터**를 결합한 아키텍처를 제안하는 것입니다.[1]

주요 기여는 다음과 같습니다:[1]

- **CRU 개발**: 신경망 인코더-디코더 프레임워크와 확률적 상태 공간 모델을 결합하여 불규칙한 관찰 시간을 자연스럽게 처리할 수 있는 아키텍처 개발
- **f-CRU 도입**: 고유분해(eigendecomposition)를 통한 매개변수화로 행렬 지수 계산을 O(n³)에서 요소별 연산으로 단순화하여 훈련 속도 대폭 개선
- **경험적 검증**: 여러 도전적인 데이터셋에서 신경 ODE 기반 방법보다 우수한 보간 성능과 더 빠른 훈련 시간 입증

***

### 2. 해결하고자 하는 문제와 제안 방법[1]

#### **문제의 정의**

기존 RNN 아키텍처는 다음의 제약이 있습니다:[1]

- 일정한 시간 간격을 가정함
- 의료 기록, 기후 데이터 등 실제 데이터셋의 불규칙한 관찰 시간을 처리하지 못함
- 관찰 시간 간격 자체가 가지는 정보적 가치 무시 (예: 의료 기록에서 오랫동안 검사가 없었다는 것은 환자가 건강했음을 시사)

#### **제안 방법: CRU의 수학적 기초**

**연속 잠재 상태 동역학**[1]

CRU의 핵심은 다음의 선형 확률 미분방정식(SDE)으로 모델링된 숨겨진 상태입니다:

$$
dz = Azdt + Gd\beta
$$

여기서:
- $$z \in \mathbb{R}^M$$: 잠재 상태
- $$A \in \mathbb{R}^{M \times M}$$: 시간 불변 전이 행렬
- $$G \in \mathbb{R}^{M \times B}$$: 확산 계수
- $$\beta \in \mathbb{R}^B$$: 표준 브라운 운동 (Brownian motion)
- $$Q \in \mathbb{R}^{B \times B}$$: 확산 행렬

**가우시안 관찰 모델**[1]

$$
y_t \sim \mathcal{N}(Hz_t, (\sigma^{obs}_t)^2 I)
$$

여기서 $$H \in \mathbb{R}^{D \times M}$$은 관찰 모델이고, $$\sigma^{obs}_t$$는 관찰 소음입니다.

**인코더와 디코더**[1]

- 인코더: $$[y_t, \sigma^{obs}_t] = f\_\theta(x_t)$$ - 관찰을 잠재 공간으로 매핑
- 디코더: $$[o_t, \sigma^{out}_t] = g\_\phi(\mu^+_t, \Sigma^+_t)$$ - 잠재 상태를 출력으로 매핑

***

### 3. 모델 구조: 연속-이산 칼만 필터

#### **예측 단계 (Prediction Step)**[1]

이전 관찰 시점 $$\tau(t)$$에서 현재 시점 $$t$$까지 상태가 진화하는 방식:

$$
\mu^-_t = \exp(A(t - \tau(t)))\mu^+_{\tau(t)}
$$

$$
\Sigma^-_t = \exp(A(t - \tau(t)))\Sigma^+_{\tau(t)}\exp(A(t - \tau(t)))^T + \int_{\tau(t)}^{t} \exp(A(t - s))GQG^T\exp(A(t - s))^T ds
$$

여기서 $$\mu^-_t$$와 $$\Sigma^-_t$$는 사전(prior) 분포의 평균과 공분산입니다.

#### **업데이트 단계 (Update Step)**[1]

새로운 관찰이 들어올 때 베이즈 정리를 적용:

$$
\mu^+_t = \mu^-_t + K_t(y_t - H\mu^-_t)
$$

$$
\Sigma^+_t = (I - K_t H)\Sigma^-_t
$$

**칼만 이득(Kalman Gain)**:[1]

$$
K_t = \Sigma^-_t H^T (H\Sigma^-_t H^T + \Sigma^{obs}_t)^{-1}
$$

칼만 이득은 관찰 소음과 사전 불확실성을 비교하는 **게이팅 메커니즘(gating mechanism)**의 역할을 합니다. 관찰 소음이 낮을 때 높은 값을 가져 새로운 관찰을 더 신뢰합니다.

#### **알고리즘 1: CRU 셀의 재귀 구조**[1]

```
입력: 데이터 포인트와 타임스탐프 {(x_t, t)}_{t∈T}
초기화: μ⁺_{t0} = 0, Σ⁺_{t0} = 10·I

각 관찰 시점 t > t₀에 대해:
  1. y_t, σ^obs_t = f_θ(x_t)  [인코딩]
  2. μ⁻_t, Σ⁻_t = predict(μ⁺_{τ(t)}, Σ⁺_{τ(t)}, t - τ(t))  [예측]
  3. μ⁺_t, Σ⁺_t = update(μ⁻_t, Σ⁻_t, y_t, σ^obs_t)  [업데이트]
  4. o_t, σ^out_t = g_φ(μ⁺_t, Σ⁺_t)  [디코딩]

반환: {o_t, σ^out_t}_{t∈T}
```

***

### 4. 모델의 일반화 성능 향상: f-CRU

#### **일반화 성능 향상 메커니즘**[1]

CRU의 성능을 향상시키기 위해 두 가지 주요 전략이 사용되었습니다:

**1. 국소 선형 상태 전이 (Locally Linear State Transitions)**[1]

표현력을 유지하면서 계산 복잡성을 관리하기 위해 K개의 기저 행렬의 가중 평균을 사용:

$$
A_t = \sum_{k=1}^{K} \alpha^{(k)}_t A^{(k)}, \quad \text{where } \alpha_t = w_\psi(\mu^+_t)
$$

이는 신경망 $$w_\psi$$가 현재 상태에 따라 동역학을 적응적으로 조절할 수 있게 합니다.

**2. Fast CRU (f-CRU): 고효율 매개변수화**[1]

f-CRU는 기저 행렬을 고유분해 형태로 직접 매개변수화합니다. 모든 $$k \in \{1...K\}$$에 대해 $$A^{(k)} = ED^{(k)}E^T$$ 형태로 표현:

$$
\mu^-_t = E \exp\left((t - \tau(t))\sum_{k=1}^{K} \alpha^{(k)}D^{(k)}\right) E^T \mu^+_{\tau(t)}
$$

여기서 $$\exp(\cdot)$$는 **요소별 지수 함수**입니다. 이렇게 하면:
- 행렬 지수 계산이 O(n³)에서 O(n)으로 단순화
- 모든 기저 행렬이 같은 고유벡터를 공유하도록 보장
- 훈련 시간이 최대 50% 감소[1]

***

### 5. 성능 평가 및 한계[1]

#### **평가 결과**

| 데이터셋 | 과제 | CRU 성능 | 주요 비교 대상 |
|---------|------|---------|----------------|
| 펜듈럼 이미지 | 보간 | MSE: 0.996±0.052 | ODE-RNN: 2.830±0.137 |
| USHCN (기후) | 보간 | MSE: 0.016±0.006 | ODE-RNN: 0.831±0.008 |
| Physionet (의료) | 보간 | MSE: 0.182±0.091 | ODE-RNN: 0.236±0.009 |
| 펜듈럼 | 회귀 | MSE: 4.626±1.072 | RKN: 8.433±0.610 |

**훈련 시간 비교**[1]
- CRU: 122초/에포크 (USHCN)
- f-CRU: 61초/에포크 (약 50% 감소)
- ODE-RNN: 81초/에포크
- Latent ODE: 110초/에포크

#### **불확실성 기반 게이팅의 효과**[1]

Figure 4에서 보여지듯이, CRU의 칼만 이득은 관찰의 신뢰도에 따라 적응적으로 조절됩니다:
- **높은 소음**: 칼만 이득 감소 → 과거 정보 의존 증가
- **낮은 소음**: 칼만 이득 증가 → 새로운 관찰 신뢰 증가

부분 관찰(Partial Observability) 실험에서 CRU는 희소한 관찰에 대해 자동으로 낮은 가중치를 부여합니다.[1]

#### **모델의 한계**[1]

1. **선형 가정**: 숨겨진 상태가 선형 SDE를 따른다고 가정하여, 고도의 비선형 동역학을 표현하기 어려울 수 있음
2. **상태 공간 크기**: 행렬 연산으로 인한 계산 복잡성 때문에 매우 높은 차원의 상태 공간을 사용하기 어려움
3. **외삽 성능**: 긴 미래 예측(extrapolation)에서는 mTAND 같은 주의(attention) 기반 방법에 비해 약간의 성능 저하 관찰 (Physionet 외삽: CRU 0.629 vs mTAND 0.340)
4. **부분 관찰의 한계**: 결측치가 매우 많은 상황에서는 성능이 저하될 수 있음

---

### 6. 일반화 성능 향상 가능성[1]

#### **현재까지의 성과**

- **폐쇄형 해**: 수치 ODE 솔버를 필요로 하지 않아 신경 ODE 방법보다 안정적인 훈련과 빠른 수렴[1]
- **최적 칼만 필터링**: 선형 필터링 문제에 대한 최적해를 제공하여 이론적 건전성 확보
- **소음 강건성**: 불확실성 인식 게이팅이 노이지한 데이터에 자동으로 대응

#### **향후 개선 가능성**

1. **비선형 확장**: 상태 전이 함수에 신경망 요소를 추가하여 비선형 동역학 학습
2. **다중 스케일 모델링**: 계층적 상태 구조로 다양한 시간 스케일 포착
3. **전이 학습**: 대규모 의료 데이터로 사전훈련된 모델을 다른 도메인에 적용
4. **앙상블 방법**: CRU의 확률적 특성을 활용한 앙상블 기법 개발

***

### 7. 논문의 연구 영향과 향후 고려사항[1]

#### **학문적 영향**

- **불규칙 시계열 처리의 새로운 패러다임**: 신경 ODE와 다른 이론적 기초(칼만 필터)를 제시하여 연구 방향 다양화
- **확률론적 해석**: 신경망 게이팅 메커니즘의 확률론적 근거 제공
- **폐쇄형 해의 중요성**: 수치 근사가 아닌 해석해의 장점 재강조

#### **실무적 응용**

- **의료 정보학**: 불규칙한 환자 모니터링 데이터 처리
- **기후 모델링**: 센서 고장으로 인한 결측 데이터 처리
- **IoT 및 센서 네트워크**: 비동기 센서 데이터 통합

#### **향후 연구 시 고려할 점**[1]

1. **다중 시계열 의존성**: 변수 간 상호작용을 더 잘 모델링하는 다변량 확장
2. **동적 인코더-디코더**: 고정된 인코더-디코더가 아닌 적응형 설계
3. **계산 효율성**: f-CRU보다 더 효율적인 매개변수화 기법 탐색
4. **장기 의존성 학습**: 매우 긴 시계열에서의 성능 개선 필요
5. **도메인 적응**: 데이터 부족 분야에서의 전이 학습 전략 수립
6. **불확실성 정량화**: 예측 불확실성의 정확한 추정 검증
7. **해석 가능성**: 칼만 이득과 상태 전이의 물리적 의미 분석

이 논문은 확률론적 상태 공간 모델과 심층 학습의 결합이 가지는 가능성을 보여주며, 불규칙한 시계열 데이터를 다루는 실무적 문제에 대한 이론적으로 견고한 해결책을 제시합니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/62f9e86f-3ebf-4501-b498-74dbb5cf48f7/2111.11344v3.pdf)
