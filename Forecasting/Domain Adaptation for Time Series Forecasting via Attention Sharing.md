# Domain Adaptation for Time Series Forecasting via Attention Sharing

### 1. 핵심 주장과 주요 기여

**Domain Adaptation Forecaster (DAF)** 논문은 시계열 예측에서 **데이터 부족** 문제를 해결하기 위해 도메인 적응 기법을 제안합니다. 핵심 주장은 다음과 같습니다:[1]

- **주요 문제**: 깊은 신경망을 사용한 시계열 예측 모델은 충분한 데이터가 있을 때만 효과적이지만, 실제 응용에서는 데이터가 제한적입니다.

- **핵심 통찰**: 데이터가 풍부한 **원본 도메인(Source Domain)** 의 통계적 강점을 활용하여 데이터가 부족한 **타겟 도메인(Target Domain)** 의 성능을 향상시킬 수 있습니다.

- **주요 기여**:
  1. 시간 시리즈 예측을 위한 **최초의 엔드-투-엔드 도메인 적응 솔루션** 제시
  2. 어텐션 메커니즘을 활용한 독창적인 도메인 적응 전략
  3. 광범위한 실험과 절제 연구(Ablation Study)를 통한 설계 선택의 효과성 입증[1]

### 2. 해결하고자 하는 문제와 제안하는 방법

#### 2.1 핵심 문제점

논문은 기존 도메인 적응 방법을 시계열 예측에 직접 적용할 수 없는 두 가지 주요 도전 과제를 식별합니다:[1]

1. **시간적 특성**: 시계열의 진화하는 패턴은 전체 이력 표현으로는 포착되기 어렵습니다. 미래 예측은 서로 다른 시기의 국소 패턴에 의존할 수 있으므로, 순차적인 국소 표현이 더 적절합니다.

2. **출력 공간의 가변성**: 일반적인 분류 문제와 달리, 예측의 출력 공간은 고정되어 있지 않습니다(예: 전력 데이터의 kW vs. 재고 데이터의 단위 수).

#### 2.2 제안하는 방법론

**Minimax 최적화 문제** 공식화:[1]

$$ \min_{G_S, G_T} \max_D L_{seq}(D_S, G_S) + L_{seq}(D_T, G_T) + \lambda L_{dom}(D_S, D_T, D, G_S, G_T) $$

여기서:
- $$L_{seq}$$: 예측 손실(추정 오류)
- $$L_{dom}$$: 도메인 분류 손실
- $$\lambda$$: 균형 계수 (실험에서 1로 설정)
- $$G_S, G_T$$: 원본/타겟 시퀀스 생성기
- $$D$$: 도메인 판별기[1]

**순차 손실(Sequence Loss)** 정의:[1]

$$ L_{seq}(D, G) = \sum_{i=1}^N \left[\frac{1}{T}\sum_{t=1}^T l(\hat{z}_{i,t}, z_{i,t}) + \frac{1}{\tau}\sum_{t=T+1}^{T+\tau} l(\hat{z}_{i,t}, z_{i,t})\right] $$

**도메인 분류 손실(Domain Classification Loss)**:[1]

$$ L_{dom} = \sum_{h_i \in H_S} \log D(h_i) + \sum_{h_i \in H_T} \log(1-D(h_i)) $$

### 3. 모델 구조(Architecture)

DAF의 아키텍처는 다음과 같은 주요 구성 요소로 이루어져 있습니다:[1]

#### 3.1 개인 인코더(Private Encoders)

각 도메인의 원본 입력 $$X = \{z_t\}_{t=1}^T$$ 를 두 가지 임베딩으로 변환:

- **패턴 임베딩**: $$P = \{p_t\}_{t=1}^T$$, $$p_j = \text{Conv}(X; \theta_p^j)$$ (M개의 다양한 커널 크기를 가진 시간적 합성곱)
- **값 임베딩**: $$V = \{v_t\}_{t=1}^T$$, $$v_t = \text{MLP}(z_t; \theta_v)$$[1]

#### 3.2 공유 어텐션 모듈(Shared Attention Module)

**도메인-불변 특성 생성**:

$$ q_t, k_t = \text{MLP}(p_t; \theta_s) $$

**어텐션 점수 계산**:[1]

$$ \alpha_t = \frac{\kappa(q_t, k_t)}{\sum_{t' \in N_t} \kappa(q_t, k_{t'})} $$

여기서 $$\kappa(q, k)$$는 양의 반정치 커널 (예: 지수 축소 내적)

**어텐션 가중 평균**:[1]

$$ o_t = \text{MLP}\left(\sum_{t' \in N_t} \alpha_t(q_t, k_{t'}) v_{t'}, \theta_o\right) $$

#### 3.3 보간(Interpolation)과 외삽(Extrapolation)

**재구성을 위한 보간**: $$N_t = \{1, 2, ..., t-1, t+1, ..., T\}$$에서 $$z_t$$를 재구성

**예측을 위한 외삽**: 마지막 로컬 윈도우 $$z_{T-s+1}, ..., z_T$$의 패턴을 따라 $$z_{T+1}$$을 예측

윈도우 크기 $$s = \lceil\frac{\text{kernel size}}{2}\rceil$$[1]

#### 3.4 개인 디코더(Private Decoders)

각 도메인별로 고유의 디코더:

$$ \hat{z}_t = \text{MLP}(o_t; \theta_d) $$

이는 도메인-특정 예측을 생성하고, 예측값은 다음 시계열 예측을 위해 피드백됩니다.[1]

#### 3.5 도메인 판별기(Domain Discriminator)

이진 분류기로 쿼리와 키가 도메인-불변인지 확인:

$$ D(q_t) = \text{MLP}(q_t; \theta_D), \quad D(k_t) = \text{MLP}(k_t; \theta_D) $$

### 4. 성능 향상(Performance Improvements)

#### 4.1 합성 데이터 실험

**Cold-Start 예측** (짧은 시계열):[1]

| 역사 길이 | DAR | AttF | DATSING | DAF |
|----------|-----|------|---------|-----|
| T=36 | 0.053 | 0.042 | 0.039 | **0.035** |
| T=45 | 0.037 | 0.041 | 0.039 | **0.030** |
| T=54 | 0.031 | 0.038 | 0.037 | **0.029** |

**Few-Shot 예측** (부족한 시계열):[1]

| 시계열 수 | DAR | AttF | DATSING | DAF |
|---------|-----|------|---------|-----|
| N=20 | 0.062 | 0.095 | 0.078 | **0.057** |
| N=50 | 0.059 | 0.074 | 0.076 | **0.055** |
| N=100 | 0.059 | 0.071 | 0.058 | **0.051** |

#### 4.2 실제 데이터 실험

4개의 벤치마크 데이터셋(전력 소비-elec, 교통-traf, 판매-sales, 웹 트래픽-wiki)에서의 성능:[1]

**Cross-Domain 적응 결과**:

- **elec → traf**: DAF (0.169) vs. AttF (0.182) - **7.1% 개선**
- **traf → elec**: DAF (0.125) vs. AttF (0.137) - **8.8% 개선**  
- **wiki → sales**: DAF (0.042) vs. AttF (0.050) - **16% 개선**
- **sales → wiki**: DAF (0.280) vs. AttF (0.305) - **8.2% 개선**

#### 4.3 주요 성능 관찰

1. **데이터 부족 상황에서 더 큰 개선**: Figure 5에 따르면, 타겟 데이터셋 크기가 작아질수록 DAF의 성능 향상이 더 뚜렷합니다.[1]

2. **엔드-투-엔드 학습의 우수성**: 공동 학습 기반 DA 방법(RDA, DAF)이 2단계 기반 방법(DATSING)보다 우수합니다.[1]

3. **도메인 빈도 무관성**: 다른 빈도의 도메인 간 이전에도 효과적입니다(시간당 데이터 ↔ 일일 데이터).[1]

### 5. 일반화 성능 향상(Generalization Performance)

#### 5.1 도메인 불변 특성 학습

**핵심 설계**: 쿼리(Query)와 키(Key)는 도메인-불변이지만, 값(Value)은 도메인-특정적입니다.[1]

이 전략의 효과:

- **쿼리-키 정렬의 역할**: 도메인 간 상황 매칭(Context Matching)을 가능하게 합니다
- **값의 도메인-특정성**: 각 도메인의 고유 특성을 보존하면서도 패턴 인식을 공유합니다

**시각화 증거** (Figure 7): 비적응 모델(no-adv)은 쿼리와 키의 분포가 정렬되지 않지만, DAF는 원본과 타겟 도메인의 쿼리/키 분포가 명확히 정렬됩니다.[1]

#### 5.2 절제 연구(Ablation Studies) 결과

**핵심 설계 요소의 중요도**:[1]

| 변형 | traf-elec | elec-traf | wiki-sales | sales-wiki |
|------|-----------|-----------|-----------|-----------|
| no-adv (판별기 없음) | 0.172 | 0.121 | 0.042 | 0.294 |
| no-q-share (쿼리 미공유) | 0.171 | 0.122 | 0.042 | 0.283 |
| no-k-share (키 미공유) | 0.172 | 0.120 | 0.044 | 0.282 |
| v-share (값 공유) | 0.176 | 0.127 | 0.049 | 0.291 |
| **DAF** | **0.168** | **0.119** | **0.041** | **0.280** |

**결론**: 값을 도메인-특정적으로 유지하는 설계가 가장 큰 긍정적 영향을 미칩니다.[1]

#### 5.3 일반화 메커니즘

1. **패턴 공유**: 원본 도메인의 시간적 패턴 인식이 타겟 도메인으로 전이됩니다
2. **적응적 가중치**: 각 도메인의 국소 윈도우 특성을 유지하면서도 전역적 패턴 일치를 수행합니다
3. **다중 스케일 특성**: 다양한 커널 크기의 합성곱을 통해 여러 시간 스케일의 패턴을 포착합니다.[1]

### 6. 한계 및 제약사항

#### 6.1 방법론적 한계

1. **이론적 정당성 부재**: 논문 저자들도 인정하듯이, 어텐션 모델 내에서 도메인-불변 특성을 갖는 것에 대한 이론적 정당화가 아직 개방된 문제입니다.[1]

2. **다변량 시계열 확장**: 현재 구현은 주로 단변량 시계열에 초점을 맞추고 있으며, 다변량 시계열로의 확장이 향후 과제입니다.[1]

3. **공통 원본 데이터 발견의 어려움**: 실제 응용에서 적절한 원본 도메인 찾기가 도전적일 수 있습니다.

#### 6.2 실험적 제약

1. **타겟 데이터셋 크기**: 실제 데이터셋을 부분적으로 추출하여 데이터 부족 상황을 시뮬레이션했습니다(마지막 30-60일). 이는 실제 콜드 스타트 문제를 완벽히 대표하지 못할 수 있습니다.[1]

2. **고정된 λ 값**: 모든 실험에서 도메인 적응 손실의 가중치를 λ=1로 고정했는데, 다양한 도메인 쌍에 대해 최적 값이 다를 수 있습니다.[1]

3. **제한된 도메인 수**: 4개 벤치마크 데이터셋으로만 평가되었으며, 더 다양한 도메인(예: 센서 데이터, 금융 데이터)에서의 성능 미검증.[1]

### 7. 모델의 일반화 성능에 대한 심층 분석

#### 7.1 일반화 성능 향상 메커니즘

**도메인 간 특성 전이의 핵심**:[1]

1. **쿼리-키 정렬(Query-Key Alignment)**: 
   - 원본 도메인의 시간적 패턴 인식이 타겟 도메인의 유사한 패턴을 인식하도록 도와줍니다
   - 예: 24시간 주기성, 주간 패턴 등이 서로 다른 도메인 간에 공유될 수 있습니다

2. **도메인-특정 값(Domain-Specific Values)**:
   - 각 도메인의 절대값 범위와 스케일을 보존하여 과도한 일반화를 방지합니다
   - 예: 전력 소비(kW)와 교통량(점유율)의 완전히 다른 스케일을 각각 유지합니다

#### 7.2 데이터 부족 상황에서의 성능

**Few-Shot 학습에서의 우수성** (Figure 5):[1]
- 타겟 데이터 N=20일 때: DAF는 AttF 대비 40% 성능 향상
- 타겟 데이터 N=50일 때: 약 26% 성능 향상
- 데이터가 충분해질수록 성능 격차 감소 (N=100에서 약 26% 향상)

이는 DAF가 **특히 데이터 부족 상황에 최적화**되어 있음을 보여줍니다.[1]

#### 7.3 도메인 시프트에 대한 강건성

**이질적인 도메인 간 전이 성공**:[1]

실험에서 wiki(불규칙한 패턴) → sales(다양한 패턴) 같은 도메인 쌍에서도 효과적이었으며, 이는 DAF의 유연한 어텐션 메커니즘이 광범위한 도메인 변수에 대응할 수 있음을 시사합니다.

### 8. 향후 연구에 미치는 영향 및 고려 사항

#### 8.1 연구 영향

1. **도메인 적응 패러다임의 확장**: 시계열 예측 분야에서 도메인 적응의 가능성을 입증하여, 다른 시계열 작업(분류, 이상 탐지 등)으로의 확장을 시사합니다.[1]

2. **어텐션 기반 설계의 효과성**: 어텐션 메커니즘을 통해 도메인-불변과 도메인-특정 특성을 선택적으로 분리할 수 있음을 보여줍니다. 이는 다른 도메인 적응 문제에 적용될 수 있습니다.[1]

3. **엔드-투-엔드 학습의 중요성**: 기존의 2단계(pre-training + fine-tuning) 접근보다 엔드-투-엔드 공동 학습이 더 효과적임을 입증합니다.[1]

#### 8.2 향후 연구 시 고려할 점

1. **이론적 분석**:
   - 도메인-불변 표현의 조건에 대한 수렴성 보장
   - 도메인 적응 손실의 최적 가중치 선택에 대한 이론적 프레임워크

2. **기술적 확장**:
   - **다변량 시계열**: 변수 간 상관관계를 모델링하는 확장
   - **비정상 시계열**: 추세나 계절성이 변하는 데이터에 대한 적응
   - **다중 원본 도메인**: 여러 원본 도메인을 동시에 활용

3. **실용적 개선**:
   - **적응적 가중치 조정**: 도메인 특성에 따라 λ를 동적으로 조정
   - **메타-학습 통합**: 새로운 도메인에 빠르게 적응하기 위한 메타-학습 프레임워크
   - **불확실성 정량화**: 예측의 신뢰도 평가

4. **적용 영역**:
   - **산업 센서 데이터**: 새로운 공장/설비로의 빠른 적응
   - **의료 시계열**: 환자별 생체신호 예측
   - **금융**: 새로운 자산 또는 시장으로의 모델 전이
   - **기후/에너지**: 새로운 지역의 날씨 또는 전력 수요 예측

5. **평가 체계**:
   - 더 많은 실제 데이터셋에서의 광범위한 평가
   - 도메인 복잡도를 고려한 벤치마크 개발
   - 계산 효율성 분석

#### 8.3 다른 연구와의 연계

논문의 기여는 다음 방향으로 발전할 수 있습니다:[1]

- **Transformer 기반 모델**: 최신 Transformer 예측 모델(Informer, Autoformer)과의 통합
- **자가지도학습(Self-Supervised Learning)**: 도메인-불변 특성 학습을 위한 대조 학습 활용
- **인과추론(Causal Inference)**: 도메인 간 진정한 인과 관계의 이전

### 결론

**Domain Adaptation for Time Series Forecasting via Attention Sharing**은 시계열 예측의 데이터 부족 문제를 해결하기 위한 혁신적인 솔루션을 제시합니다.[1]

핵심적으로:
- **쿼리와 키의 도메인-불변 정렬**을 통해 패턴 인식을 공유
- **값의 도메인-특정 유지**로 각 도메인의 고유성 보존
- **엔드-투-엔드 적대적 학습**으로 강력한 도메인 적응 실현

이 논문은 특히 **데이터 부족 상황에서 40% 이상의 성능 향상**을 보여주며, 향후 시계열 분석 및 도메인 적응 연구에 중요한 기초를 제공합니다. 다만 이론적 정당화의 부재와 다변량 시계열로의 확장 필요성은 향후 해결해야 할 과제로 남아있습니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/6183b547-78e3-4f28-9c5b-8157fcb6849e/2102.06828v9.pdf)
