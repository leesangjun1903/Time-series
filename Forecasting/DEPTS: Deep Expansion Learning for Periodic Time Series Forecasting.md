# DEPTS: Deep Expansion Learning for Periodic Time Series Forecasting

## 1. 핵심 주장과 주요 기여

DEPTS(Deep Expansion Learning for Periodic Time Series Forecasting)는 주기성이 있는 시계열(Periodic Time Series, PTS) 예측을 위한 딥러닝 프레임워크입니다.[1]

**핵심 주장:**
- 기존 시계열 예측 모델들이 복잡한 주기적 의존성을 제대로 모델링하지 못함[1]
- 실제 시계열의 주기성은 다양한 진폭과 주파수를 가진 여러 주기의 복합적 구성으로 이루어짐[1]

**주요 기여:**
1. **새로운 분리된 수식화(Decoupled Formulation)**: 주기적 상태를 숨겨진 변수로 도입한 새로운 공식화[1]
2. **확장 모듈(Expansion Module)**: 잔차 학습을 기반으로 한 계층별 의존성 확장[1]
3. **주기성 모듈(Periodicity Module)**: 다양한 주기를 포착할 수 있는 매개변수화된 주기 함수[1]
4. **해석 가능성**: 예측 결과를 지역적 모멘텀과 전역적 주기성으로 분리 해석 가능[1]

## 2. 문제 및 방법론 상세 분석

### 해결하고자 하는 문제

**문제 1: 복잡한 주기적 의존성**
기존 방법들은 가법적(additive) 또는 승법적(multiplicative) 계절성 같은 단순한 가정에만 의존하여 복잡한 주기적 의존성을 모델링하지 못함.[1]

**문제 2: 다양한 주기 구성**
실제 시계열은 여러 다른 진폭과 주파수를 가진 주기들의 복합적 구성이지만, 기존 방법들은 사전에 주기적 주파수를 지정해야 함.[1]

### 제안하는 방법

#### 분리된 수식화(Decoupled Formulation)

기존의 자기회귀 수식:

$$x_{t:t+H} = F'_{\Theta}(x_{t-L:t}, t) + \epsilon_{t:t+H}$$

제안된 분리 수식:

$$x_{t:t+H} = f_{\theta}(x_{t-L:t}, z_{t-L:t+H}) + \epsilon_{t:t+H}$$

$$z_t = g_{\phi}(t)$$

여기서 $$z_t$$는 시점 t에서의 주기적 상태를 나타내는 숨겨진 변수.[1]

#### 확장 모듈(Expansion Module)

삼중 잔차 확장을 통한 계층별 분해:

$$z_{t-L:t+H} = z_{t-L:t+H}^{(0)} = \sum_{\ell=1}^{N} v_{t-L:t+H}^{(\ell)} + z_{t-L:t+H}^{(N)}$$

$$x_{t-L:t} = x_{t-L:t}^{(0)} = \sum_{\ell=1}^{N} (u_{t-L:t}^{(\ell)} + v_{t-L:t}^{(\ell)}) + x_{t-L:t}^{(N)}$$

$$\hat{x}_{t:t+H} = \hat{x}_{t:t+H}^{(N)} = \sum_{\ell=1}^{N} (u_{t:t+H}^{(\ell)} + v_{t:t+H}^{(\ell)})$$

#### 주기성 모듈(Periodicity Module)

코사인 함수 급수로 주기 함수 표현:

$$g_{\phi}(t) = A_0 + \sum_{k=1}^{K} A_k \cos(2\pi F_k t + P_k)$$

여기서 $$A_k$$, $$F_k$$, $$P_k$$는 각각 k번째 코사인 함수의 진폭, 주파수, 위상.[1]

**매개변수 초기화**: 이산 코사인 변환(DCT)과 2단계 최적화를 통한 데이터 기반 초기화.[1]

### 모델 구조

**확장 모듈**: N개 계층으로 구성되며, 각 계층은 로컬 블록과 주기적 블록으로 구성[1]
- **로컬 블록**: 4개 완전연결 계층으로 구성된 N-BEATS와 유사한 구조
- **주기적 블록**: 1개 완전연결 계층과 2개 선형 투영으로 구성된 단순한 구조

**주기성 모듈**: K개의 코사인 기저 함수로 다양한 주기 패턴 표현[1]

## 3. 성능 향상 및 한계

### 성능 향상

**합성 데이터 실험**: 
- 선형, 이차, 삼차 주기적 의존성에서 N-BEATS 대비 각각 7%, 9%, 11%의 오차 감소[1]
- 주기적 의존성이 복잡해질수록 성능 향상 폭이 증가[1]

**실제 데이터 실험**:
- ELECTRICITY, TRAFFIC, M4(HOURLY), CAISO, NP 데이터셋에서 평균 12.5%, 3.5%, 8.7%, 13.3%, 9.9%의 오차 감소[1]
- 일부 케이스에서 최대 20%까지 오차 감소[1]

### 일반화 성능 향상

**주요 설계 원칙**:
1. **잔차 학습**: 과적합을 방지하면서 높은 모델 용량 확보[1]
2. **데이터 기반 초기화**: DCT 기반 주기 계수 초기화로 지역 최적점 회피[1]
3. **2단계 최적화**: 훈련/검증 데이터를 통한 일반화 가능한 주기 선택[1]
4. **앙상블**: 다양한 lookback 길이와 초기화로 훈련된 모델들의 앙상블[1]

**아블레이션 연구**:
- 각 구성 요소(주기 효과 제거, 주기적 예측 포함, 잔차 연결)의 중요성 검증[1]
- 하이퍼파라미터 J(선택할 주기 수)의 민감도 분석으로 과적합 방지 확인[1]

### 한계점

1. **단변량 시계열 제한**: 현재는 단변량 시계열에만 적용[1]
2. **코사인 함수 가정**: 주기성을 코사인 함수로만 표현하는 제약[1]
3. **하이퍼파라미터 민감도**: J값에 따른 성능 변화가 크므로 신중한 튜닝 필요[1]
4. **계산 복잡도**: DCT 기반 초기화와 2단계 최적화로 인한 추가 계산 비용[1]

### 해석 가능성

**예측 분해**:
- 전역적 주기성($$\sum_{\ell=1}^{N} v_{t:t+H}^{(\ell)}$$)과 지역적 모멘텀($$\sum_{\ell=1}^{N} u_{t:t+H}^{(\ell)}$$)으로 예측 분해[1]

**주기 계수 해석**:
- 진폭, 주파수, 위상 등 물리적 의미를 가진 매개변수[1]
- 실제 도메인과 일치하는 의미 있는 주기 발견 (예: 일별, 주별, 연별 주기)[1]

## 4. 향후 연구에 미치는 영향 및 고려사항

### 향후 연구 영향

**딥러닝 기반 시계열 분야 발전**:
- 전통적 시계열 분석에서 중요했던 주기성 모델링을 딥러닝 프레임워크로 성공적으로 통합[1]
- 명시적 주기성 모델링의 중요성을 입증하여 향후 연구 방향 제시[1]

**벤치마크 데이터셋 기여**:
- CAISO, NP 등 충분히 긴 주기성 시계열 데이터셋 제공으로 연구 촉진[1]

**해석 가능 AI 발전**:
- 예측 결과의 물리적 해석 가능성 제공으로 실무 적용성 향상[1]

### 향후 연구 고려사항

**확장 방향**:
1. **다변량 시계열**: 다변량 주기성 시계열로의 확장 연구 필요[1]
2. **주기 함수 일반화**: 코사인 함수 외 다양한 주기 함수 표현 방법 탐구
3. **적응적 주기성**: 시간에 따라 변하는 주기성 패턴 모델링
4. **계산 효율성**: DCT 초기화와 2단계 최적화의 계산 비용 최적화

**실무 적용 고려사항**:
1. **하이퍼파라미터 자동화**: J값 등 핵심 하이퍼파라미터의 자동 선택 방법 개발
2. **실시간 학습**: 온라인 환경에서의 주기성 적응 학습 방법
3. **도메인 특화**: 특정 산업 분야의 주기성 특성에 맞춘 모델 변형
4. **불확실성 정량화**: 주기성 예측의 불확실성 정량화 방법 개발

**이론적 발전**:
1. **수렴성 분석**: 2단계 최적화의 이론적 수렴 보장
2. **일반화 경계**: 주기성 모델링이 일반화 성능에 미치는 이론적 분석
3. **최적성**: 주기 함수 표현의 최적성과 근사 오차 분석

이 논문은 딥러닝 기반 시계열 예측에서 주기성의 명시적 모델링이 중요함을 보여주며, 향후 복잡한 주기성을 가진 시계열 분야의 연구 발전에 중요한 기여를 할 것으로 예상됩니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/5de9a2b7-cbf6-4512-9c41-535d0821aeeb/2203.07681v1.pdf)
