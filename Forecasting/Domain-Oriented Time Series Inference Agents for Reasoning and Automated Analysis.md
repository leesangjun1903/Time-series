# Domain-Oriented Time Series Inference Agents for Reasoning and Automated Analysis

## 1. 핵심 주장과 주요 기여

TS-Reasoner는 실세계 시계열 분석이 단순 예측을 넘어 **다단계 추론, 제약 조건 처리, 도메인 지식 통합, 작업별 워크플로우 조합**을 요구한다는 점을 해결하기 위해 개발된 도메인 특화 에이전트입니다. 이 논문의 핵심 기여는 다음과 같습니다:[^1_1]

- **다단계 시계열 추론의 공식화**: 기존 시계열 foundation 모델들이 단일 작업(예: 96 스텝 예측)에 국한된 반면, 실무에서는 공변량 검색, 예측 모델 적용, 운영 제약 검증, 예측 개선 등의 복합적 단계가 필요함을 제시[^1_1]
- **하이브리드 아키텍처**: LLM의 추론 능력과 특화된 수치 연산 모듈을 결합하여 자연어 이해와 정밀한 수치 계산을 동시에 달성[^1_1]
- **자기 개선 메커니즘**: 실행 피드백을 통한 오류 감지 및 수정, 적응적 모델 선택 기능 구현[^1_1]


## 2. 해결하고자 하는 문제

### 기존 시스템의 한계

**시계열 Foundation 모델의 문제점**:[^1_1]

- 사전 정의된 단일 작업만 수행 (예: 정확히 336개 과거 관측값으로 96 스텝 예측)
- 명령어 수행, 제약 추론, 교차 도메인 지식 통합 능력 부재
- 다단계 추론 작업에 대한 유연성 결여

**LLM의 시계열 처리 한계**:[^1_1]

- 연속 데이터의 이산화가 시간적 정밀도를 손상
- 다음 토큰 예측에 최적화되어 수치 추정에 부적합
- Figure 1에서 보듯 명확한 주기 패턴도 감지하지 못함


## 3. 제안하는 방법

### 3.1 전체 아키텍처

시스템은 다음과 같이 공식화됩니다:[^1_1]

$$
y = g(R, x, C)
$$

여기서:

- $y$: 최종 출력
- $R = [f_1, f_2, ..., f_n]$: 특화된 연산자로 구성된 추론 트레이스
- $x$: 자연어로 표현된 입력 작업
- $C$: 사용 가능한 데이터와 도메인 제약을 포함한 컨텍스트


### 3.2 Task Decomposer (작업 분해기)

LLM 기반의 Task Decomposer는 복잡한 자연어 명령을 구조화된 연산자 절차로 변환합니다:[^1_1]

$$
f_i \sim p_\theta(f_1, f_2, ..., f_{i-1}, x, C)
$$

여기서 $p_\theta$는 파라미터 $\theta$를 가진 작업 분해기이며, $f_i$는 실행 파이프라인의 $i$번째 연산입니다. In-context learning을 활용하여 예제 작업-솔루션 쌍 $(x_1, R_1), (x_2, R_2), ..., (x_n, R_n)$로부터 새로운 작업을 적절한 분해 시퀀스로 매핑하는 방법을 학습합니다.[^1_1]

### 3.3 특화 연산자 (Specialized Operators)

4가지 카테고리로 구성됩니다:[^1_1]

#### (1) 시계열 모델 연산자

$$
f_{TS}(X, \theta) \rightarrow Y
$$

여기서 $X \in \mathbb{R}^{n \times d}$는 $n$개 타임스탬프와 $d$차원을 가진 입력 시계열입니다. Chronos, Lag-Llama, TimeGPT, MOMENT, TimesNet 등의 모델을 포함하며, zero-shot 추론과 훈련 절차를 모두 지원합니다.[^1_1]

#### (2) 수치 연산자

$$
f_{NUM}(X, \phi) \rightarrow Z
$$

통계 분석, 분포 검정, 분해, 연결 등의 정밀한 수학적 계산을 수행합니다.[^1_1]

#### (3) 외부 데이터 검색 연산자

$$
f_{EXT}(q) \rightarrow D
$$

쿼리 파라미터 $q$(위치, 시간 범위)를 받아 외부 데이터셋 $D$를 검색합니다. Task decomposer가 세계 지식을 활용하여 관련 공변량을 식별합니다.[^1_1]

#### (4) LLM 생성 커스텀 연산자

$$
f_{CUSTOM}(des) \rightarrow h
$$

자연어 설명 $des$로 표현된 제약이나 도메인 지식을 커스텀 함수 $h$로 합성합니다.[^1_1]

### 3.4 피드백 메커니즘 및 자기 개선

실행 프로세스는 다음과 같이 공식화됩니다:[^1_1]

$$
E(R, x, C) = \begin{cases} 
y & \text{성공 시} \\
\epsilon & \text{실패 시}
\end{cases}
$$

실행 오류 발생 시 피드백 루프가 활성화됩니다:

$$
R_{t+1} = p_\theta(R_t, \epsilon_t, x, C)
$$

적응적 모델 선택을 위해 품질 메트릭 $Q$를 사용합니다:

$$
\hat{m}_i = \arg\max_{m \in M_i} Q(m(x, C))
$$

여기서 $M_i = \{m_1, m_2, ..., m_k\}$는 후보 모델 집합입니다. 버퍼 메모리 $B$에 이전 시도를 저장하여 효율적인 모델 선택과 구조화된 실패 처리를 촉진합니다:[^1_1]

$$
B = \{(R_j, E(R_j, x, C), Q(y_j)) | j = 1, 2, ..., t-1\}
$$

## 4. 모델 구조

TS-Reasoner의 파이프라인은 Figure 2에 설명되어 있으며 다음 단계로 구성됩니다:[^1_1]

1. **입력 단계**: 질문과 시계열 데이터 수신
2. **작업 분해**: LLM이 연산자 정의와 in-context 예제를 학습하여 작업 인스턴스를 연산자 시퀀스로 분해
3. **프로그램 실행**: 프로그램 실행기가 솔루션 계획을 실행하고 Task Decomposer와 피드백 루프 형성
4. **중간 피드백**: 모델 성능 평가 및 최적 모델 선택
5. **오류 피드백**: 실행 오류 감지 시 계획 수정
6. **최종 결과**: 검증된 출력 반환

## 5. 성능 향상

### 5.1 기본 시계열 이해 (TimeSeriesExam)

TS-Reasoner는 모든 차원에서 베이스라인 모델을 일관되게 능가했습니다:[^1_1]

- **인과 분석**: 최고 성능 베이스라인 대비 87% 향상
- **패턴 인식, 노이즈 이해, 이상 감지, 유사성 분석**에서 모두 우수


### 5.2 복잡한 시계열 추론

**예측 작업** (Table 1):[^1_1]

- 공변량 포함 예측: 성공률 98.61%, MAPE 0.0620
- 공변량 없는 예측: 성공률 92.50%, MAPE 0.1031 (GPT-4o 대비 73.8% 성공률, MAPE 0.2220)
- 다중 그리드 예측: 성공률 95.00%, MAPE 0.1535

**진단 작업** (Figure 4):[^1_1]

- 참조 데이터를 이용한 극한 기상 감지: 성공률 78%, F1 점수 0.9214
- 이상률 정보를 이용한 감지: 성공률 100%, F1 점수 0.7569
- 인과 발견: 성공률 100%, 정확도 0.7915


### 5.3 오류 분석

Figure 5의 오류 분포 분석에서 TS-Reasoner는:[^1_1]

- 성공률 92.5%, 실행 오류 0%
- 제약 위반만 6.2-7.5%로 제한
- 반면 ReAct는 성공률 58.7%, 실행 오류 33.8%


## 6. 한계점

### 6.1 논문에서 명시한 한계

1. **시계열 신호의 완전한 이해 부족**: TS-Reasoner는 시계열 데이터를 직접 처리하지 않고 작업 분해와 구조화된 실행에 의존합니다.[^1_1]
2. **멀티모달 기초 모델과의 차이**: 시계열 토큰과 자연어 토큰 간의 의미 공간 정렬, 시계열 토큰으로 인한 자연어 흐름 방해, 두 모달리티 간 고품질 정렬 데이터셋 부족 등의 문제가 해결되지 않았습니다.[^1_1]
3. **제한된 도메인 범위**: 현재 벤치마크는 에너지, 기후 과학, 인과 발견에 집중되어 있으며, 의료 및 기타 도메인으로의 확장이 필요합니다.[^1_1]
4. **계산 비용**: 적응적 모델 선택과 반복적 개선은 계산 비용을 증가시킵니다.

## 7. 모델의 일반화 성능 향상 가능성

### 7.1 In-Context Learning을 통한 일반화

TS-Reasoner는 **재훈련 없이** in-context learning을 활용하여 다양한 시계열 문제에 일반화합니다. 예제 작업-솔루션 쌍을 통해 시계열 분석 워크플로우의 구조적 패턴을 인식하고 새로운 도메인과 제약에 적응합니다.[^1_1]

### 7.2 정성적 제약 및 새로운 도메인으로의 일반화

Table 2의 실험 결과:[^1_1]

**인과 지식 작업**:

- 단일 in-context 예제만으로 정성적 제약을 처리
- 성공률 100%, 정확도 0.7393 (베이스라인 대비 최고)

**주식 가격 미래 변동성 작업**:

- 명시적 in-context 예제 없이도 미관찰 도메인과 명령어에 적응
- 성공률 98%, MAPE 0.6203 (GPT-4o의 28% 성공률, MAPE 0.8366 대비 크게 우수)


### 7.3 모듈식 아키텍처의 확장성

모듈식 설계로 인해:[^1_1]

- 새로운 연산자를 쉽게 추가 가능
- 특정 도메인에 대한 foundation 모델 통합 가능
- 커스텀 제약 및 도메인 지식을 동적으로 생성


### 7.4 기본 LLM에 대한 강건성

Table 4에서 LLaMA 3.1 70B로 GPT-4o를 대체했을 때도 비슷한 성능을 유지하여, 구조화된 실행 파이프라인이 기본 LLM의 능력보다 더 중요함을 입증했습니다.[^1_1]

## 8. 2020년 이후 관련 최신 연구 비교 분석

### 8.1 시계열 Foundation 모델

**Chronos (2024)**:[^1_2]

- 시계열을 언어로 취급하여 스케일링과 양자화 기법 사용
- 단일 작업(예측)에 최적화, 다단계 추론 불가

**Sundial (2025)**:[^1_2]

- TimeFlow Loss 기반 flow-matching으로 1조 시점 데이터 사전 훈련
- Zero-shot 예측에서 SOTA 달성하지만 제약 처리 및 추론 능력 제한

**Lag-Llama (2024)**:[^1_3]

- 디코더 전용 트랜스포머로 lag를 공변량으로 사용
- 확률적 예측에 강점이지만 복합 워크플로우 조합 불가

**MOMENT (2024)**:[^1_4]

- Time series Pile에서 사전 훈련된 범용 모델
- 제한된 감독 설정에서 효과적이나 도메인 지식 통합 부족

**TimeGPT, Moirai-MoE (2023-2024)**:[^1_5][^1_6]

- 대규모 예측 벤치마크에서 우수하지만 명령어 수행 및 제약 추론 불가

**TS-Reasoner와의 차이점**: 이들 모델은 모두 사전 정의된 작업 정의 하에서 작동하며, TS-Reasoner가 제공하는 **다단계 추론, 동적 워크플로우 조합, 제약 처리** 능력이 부족합니다.[^1_1]

### 8.2 LLM 기반 시계열 에이전트

**LLMTime (2024)**:[^1_1]

- 시계열을 문자열로 인코딩
- 수치 정밀도 손실 문제

**TimeLLM, TimeMoE (2023-2025)**:[^1_1]

- 시계열을 언어 표현으로 변환하여 정렬
- 여전히 단일 작업 패러다임에 제한

**TEMPO (2023)**:[^1_1]

- 분해 기법과 프롬프트 설계 통합
- 미관찰 데이터와 멀티모달 시나리오로 일반화하지만 복합 추론 부족

**DCATS (LLM-agent for forecasting, 2025)**:[^1_7]

- 메타데이터 추론을 통한 데이터셋 확장
- 데이터 선택에 집중, TS-Reasoner의 종단 간 추론 파이프라인과 다름

**TS-RAG (2025)**:[^1_8]

- 검색 증강 생성으로 TSFM 강화
- Zero-shot 예측 6.84% 향상, 해석 가능성 제공
- 그러나 제약 처리 및 다단계 실행은 다루지 않음

**TS-Reasoner (다른 논문, 2025)**:[^1_9]

- TSFM의 잠재 표현을 LLM의 텍스트 입력과 정렬
- 이해/추론 작업에 집중, TS-Reasoner(본 논문)의 프로그램 지원 실행과 다름

**차별점**: TS-Reasoner는 LLM의 추론을 **프로그램 지원 실행**과 결합하여 수치 정밀도를 보장하고, 자기 개선 메커니즘으로 실행 오류를 처리합니다.[^1_1]

### 8.3 시계열 추론 연구

**"What Can LLMs Tell Us about Time Series Analysis" (2024)**:[^1_10]

- LLM이 데이터/모델 증강자, 예측자, 에이전트로서 시계열 분석을 혁신할 잠재력 제시
- 그러나 복잡한 시계열 데이터 이해에 제약, 환각 출력 생성

**"Towards Interpretable Time Series Reasoning" (2025)**:[^1_11]

- 포괄적인 시간적 이해, 구조화된 다단계 추론, 충실한 평가 프레임워크 제시
- 멀티에이전트 협업, 멀티모달 컨텍스트, 검색 증강 접근법 강조

**TS-Reasoner의 기여**: 실무 중심의 벤치마크와 작업별 성공 기준으로 **다단계 시계열 추론을 공식화**하고, 제약 인식 예측, 임계값 보정을 통한 이상 감지, 도메인 지식 기반 인과 발견 등을 포함합니다.[^1_1]

### 8.4 벤치마크 및 평가

**FoundTS (2024)**:[^1_12]

- TSF foundation 모델의 철저하고 공정한 평가 가능
- Zero-shot, few-shot, full-shot 전략 지원
- 그러나 다단계 추론 작업은 다루지 않음

**TSFM Benchmarking Challenges (2025)**:[^1_13]

- 데이터 누출, 전역 패턴 암기, 시공간 평가 부족 등의 문제 지적
- 미래 데이터에 대한 진정한 out-of-sample 평가 필요성 강조

**TS-Reasoner의 기여**: 390개 질문으로 구성된 새로운 다단계 추론 데이터셋을 구축하고, 작업별 성공 기준을 가진 통합 평가 프레임워크를 도입했습니다.[^1_1]

## 9. 향후 연구에 미치는 영향 및 고려사항

### 9.1 새로운 연구 패러다임 제시

**다단계 시계열 추론**을 새로운 작업 패러다임으로 공식화하여, 단일 작업 중심에서 **복합적 워크플로우 조합**으로의 전환을 촉진합니다. 이는 실무 응용에 더 가까운 평가를 가능하게 합니다.[^1_1]

### 9.2 하이브리드 접근법의 중요성 입증

LLM 단독으로는 복잡한 시계열 추론에 불충분하며, **도메인 특화 연산자와의 하이브리드 접근**이 필수적임을 실험적으로 증명했습니다. 이는 향후 연구가 순수 end-to-end 학습보다 모듈식 설계를 고려해야 함을 시사합니다.[^1_1]

### 9.3 향후 연구 방향

#### (1) 멀티모달 통합

논문은 이미지 등 멀티모달 입력을 컨텍스트 단서나 외부 지식 소스로 통합할 계획을 밝혔습니다. 이는 최신 연구 트렌드(Multi-Domain Multimodal Dataset)와 일치합니다.[^1_14][^1_1]

#### (2) 시계열 토큰의 의미 정렬

현재 TS-Reasoner는 원시 시계열 데이터를 직접 처리하지 않습니다. 향후 연구는:[^1_1]

- 시계열 토큰과 자연어 토큰 간 의미 공간 정렬
- 고품질 정렬 데이터셋 구축
- 시계열 표현으로 파인튜닝 시 추론 능력 보존

이는 TS-Reasoner (2025, 다른 논문)이 시도한 TSFM-LLM 정렬 연구와 보완적입니다.[^1_9]

#### (3) 도메인 확장

의료, 금융(DeXposure-FM) 등 추가 도메인으로 벤치마크를 확장하여 일반화 능력을 검증해야 합니다.[^1_15][^1_16][^1_1]

#### (4) 스케일링 법칙 탐구

Time-MoE (2025)가 24억 파라미터까지 스케일링하여 스케일링 법칙을 검증한 것처럼, TS-Reasoner도 모델 크기와 토큰 수에 따른 추론 능력 변화를 연구할 수 있습니다.[^1_17]

#### (5) 합성 데이터 사전 훈련

CauKer (2025)가 합성 데이터만으로 분류 TSFM을 사전 훈련할 수 있음을 보인 것처럼, TS-Reasoner의 연산자도 다양한 합성 시나리오에서 훈련될 수 있습니다.[^1_18]

#### (6) 조합적 추론 능력 개선

최근 연구는 TSFM의 조합적 추론 능력을 조사했습니다. Patch 기반 트랜스포머가 최고 추론 성능을 보였으며, TS-Reasoner는 이러한 아키텍처를 통합하여 성능을 더욱 향상시킬 수 있습니다.[^1_6]

### 9.4 실무 응용 시 고려사항

1. **계산 비용**: 적응적 모델 선택과 피드백 루프는 추론 시간을 증가시킵니다. 실시간 응용에서는 효율성과 정확성 간 균형이 필요합니다.
2. **도메인 전문가와의 협업**: 커스텀 연산자와 제약 조건 설계에는 도메인 지식이 필요하며, 인간-AI 협업 워크플로우가 중요합니다.
3. **신뢰성과 해석 가능성**: 프로그램 지원 실행은 해석 가능성을 제공하지만, LLM의 작업 분해 단계는 여전히 블랙박스입니다. 설명 가능한 AI 기법 통합이 필요합니다.
4. **평가 방법론**: TSFM 벤치마킹의 도전 과제(데이터 누출, 정보 암기)를 고려하여, 진정한 out-of-sample 평가와 원칙적 평가 설계가 필요합니다.[^1_13]
5. **Few-shot 학습**: 최근 연구는 TSFM의 few-shot 학습 능력을 탐구했습니다. TS-Reasoner는 in-context fine-tuning을 통합하여 제한된 데이터에서도 성능을 향상시킬 수 있습니다.[^1_19][^1_20]

## 결론

TS-Reasoner는 LLM의 추론 능력과 도메인 특화 시계열 도구를 결합하여 **다단계 시계열 추론**이라는 새로운 패러다임을 제시했습니다. 2020년 이후 시계열 foundation 모델들이 단일 작업 예측에서 우수한 성능을 보인 반면, TS-Reasoner는 실무의 복잡성(제약 조건, 도메인 지식, 워크플로우 조합)을 직접 다룹니다. 하이브리드 접근법의 효과를 입증하고 강건한 일반화 능력을 보였지만, 원시 시계열 데이터 처리와 멀티모달 통합은 향후 과제로 남아 있습니다. 이 연구는 시계열 AI 에이전트의 발전 방향을 제시하며, 에너지, 의료, 금융 등 중요한 도메인의 의사결정 개선에 광범위한 잠재력을 가지고 있습니다.[^1_1]
<span style="display:none">[^1_21][^1_22][^1_23][^1_24][^1_25][^1_26][^1_27][^1_28][^1_29][^1_30][^1_31][^1_32][^1_33][^1_34][^1_35][^1_36][^1_37]</span>

<div align="center">⁂</div>

[^1_1]: 2410.04047v4.pdf

[^1_2]: https://arxiv.org/abs/2502.00816

[^1_3]: https://arxiv.org/pdf/2310.08278.pdf

[^1_4]: https://arxiv.org/pdf/2402.03885.pdf

[^1_5]: https://www.semanticscholar.org/paper/3f8f68f87b04306b45e7a56687e0d6361d2fbb65

[^1_6]: https://arxiv.org/abs/2502.06037

[^1_7]: https://arxiv.org/html/2508.04231v1

[^1_8]: https://arxiv.org/abs/2503.07649

[^1_9]: https://arxiv.org/abs/2510.03519

[^1_10]: https://arxiv.org/html/2402.02713v2

[^1_11]: https://arxiv.org/abs/2510.16980

[^1_12]: http://arxiv.org/pdf/2410.11802.pdf

[^1_13]: https://arxiv.org/abs/2510.13654

[^1_14]: https://arxiv.org/pdf/2406.08627.pdf

[^1_15]: https://www.arxiv.org/pdf/2602.03981.pdf

[^1_16]: https://arxiv.org/html/2602.03981v1

[^1_17]: https://openreview.net/forum?id=e1wDDFmlVu

[^1_18]: https://arxiv.org/abs/2508.02879

[^1_19]: https://research.google/blog/time-series-foundation-models-can-be-few-shot-learners/

[^1_20]: https://icml.cc/virtual/2025/poster/43707

[^1_21]: https://arxiv.org/abs/2505.14766

[^1_22]: https://arxiv.org/abs/2502.12944

[^1_23]: https://ieeexplore.ieee.org/document/11180477/

[^1_24]: https://arxiv.org/html/2502.00816v1

[^1_25]: https://arxiv.org/pdf/2403.14735.pdf

[^1_26]: http://arxiv.org/pdf/2310.20496.pdf

[^1_27]: https://arxiv.org/pdf/2502.15637.pdf

[^1_28]: https://arxiv.org/html/2504.04011v1

[^1_29]: https://arxiv.org/html/2601.15170v1

[^1_30]: https://arxiv.org/html/2511.03799v1

[^1_31]: https://arxiv.org/html/2410.04047v3

[^1_32]: https://arxiv.org/html/2508.11004v1

[^1_33]: https://arxiv.org/abs/2504.04011

[^1_34]: https://arxiv.org/html/2510.13654v1

[^1_35]: https://www.reddit.com/r/MachineLearning/comments/1d3h5fs/d_benchmarking_foundation_models_for_time_series/

[^1_36]: https://datasciencedojo.com/blog/langchain-agents-for-time-series-analysis/

[^1_37]: https://arxiv.org/abs/2410.04047v3

