# TLNets: Transformation Learning Networks for long-range time-series prediction

## 1. 핵심 주장과 주요 기여

TLNets는 장기 시계열 예측을 위한 새로운 신경망 아키텍처로, **수용 영역 학습(Receptive Field Learning, RFL)**이라는 개념을 통해 전역(global)과 지역(local) 정보를 균형있게 학습합니다. 이 논문은 네 가지 변형 모델(FT-Matrix, FT-SVD, FT-Conv, Conv-SVD)을 제시하며, 푸리에 변환(FT), 특이값 분해(SVD), 희소 행렬 곱셈, 합성곱을 결합하여 다양한 스케일의 특징을 융합합니다.[^1_1]

주요 기여는 다음과 같습니다:

- RFL의 일반적인 정의를 도입하고, 변환된 특징 도메인에서의 학습이 더 나은 성능을 달성함을 입증[^1_1]
- 합성곱, 푸리에 변환, 행렬 곱셈 간의 관계와 각각의 수용 영역 정보를 수학적으로 증명[^1_1]
- 여러 실제 데이터셋에서 기존 최첨단 방법들을 능가하는 성능 달성[^1_1]


## 2. 상세 분석

### 해결하고자 하는 문제

기존 딥러닝 방법들은 **예측 범위가 극적으로 증가할 때 설명력이 부족하거나 성능이 만족스럽지 못한** 문제를 갖고 있습니다. 전통적인 CNN 기반 방법은 작은 커널로 큰 수용 영역을 얻기 위해 깊은 층이 필요하며, Transformer 모델은 계산 복잡도가 높고 하이퍼파라미터 설정에 민감합니다.[^1_1]

### 제안하는 방법 (수식 포함)

TLNets는 특징을 적절히 정의된 도메인(푸리에 도메인, 직교 정규 도메인)으로 변환하여 자연스럽게 큰 수용 영역을 획득하는 방식을 제안합니다.[^1_1]

**일반적인 신경 연산자 패러다임:**

$$
v_{t+1}(x) = W_S v_t(x) + H^{-1}[W_H H[v_t(x)]] + \sigma(K^{-1}[W_K K[v_t(x)]] + G^{-1}[W_G \odot G[v_t(x)]], ...)
$$

여기서 $K, G, H$는 수학적 변환(푸리에, SVD 등)이고, $K^{-1}, G^{-1}, H^{-1}$은 역변환, $W_K, W_G, W_H$는 학습 가능한 잠재 매개변수, $W_S$는 희소 행렬입니다.[^1_1]

**FT-SVD 모델의 특징 학습:**

$$
x_{l+1} = F_l^{-1} W_l F_l x_l + \sigma((U_{\Phi} \odot U_x)(S_{\Phi} \odot S_x)(V_{\Phi} \odot V_x))
$$

여기서 $F_l$과 $F_l^{-1}$은 순방향 및 역 푸리에 변환 행렬, $W_l$과 $\Phi_l$은 각각 푸리에 도메인과 SVD 도메인의 매개변수입니다. 손실 함수는 다음과 같이 정의됩니다:[^1_1]

$$
L(W, \Phi) = \frac{1}{BM} \sum_{i}^{B} \|\hat{y}_i(W, \Phi) - y_i\|
$$

여기서 $B$는 배치 크기, $M$은 시계열 길이입니다.[^1_1]

**합성곱과 행렬 곱셈의 관계:**

1D 합성곱은 희소 행렬 곱셈으로 표현될 수 있습니다:

$$
y = \sigma\{h_n...\sigma[h_1\sigma(h_1X)]\}
$$

여기서 $h_1...h_n$은 네트워크의 합성곱 행렬입니다.[^1_1]

**합성곱과 푸리에 변환의 관계:**

합성곱 정리에 의해:

$$
x \ast h = F^{-1}(Fx \odot Fh)
$$

따라서 푸리에 도메인에서 학습하면:

$$
x \ast h = F^{-1}WFx
$$

이를 통해 전역 수용 영역을 달성할 수 있습니다.[^1_1]

### 모델 구조

TLNets는 네 가지 빌딩 블록을 기반으로 합니다:[^1_1]

1. **푸리에 변환(FT) 블록**: 전역 정보를 학습하며, 주파수 도메인에서 특징을 학습합니다. 각 점이 원본 도메인의 모든 정보를 수집할 수 있습니다.[^1_1]
2. **SVD 블록**: 직교 매개변수는 더 나은 모델 수렴을 달성하는 데 도움이 됩니다. SVD 분해는 다음과 같이 표현됩니다:

$$
SVD(x) = \sum_{i=0}^{m} U_{[:,i]}S_{[i,i]}V_{[i,:]}
$$

여기서 $U_{[:,i]}$와 $V_{[i,:]}$는 고유값 $S_{[i,i]}$에 대응하는 시간 및 특징 방향의 고유벡터입니다.[^1_1]

3. **희소 행렬 블록**: 전역 및 지역 정보를 동시에 학습하도록 희소하게 설계되었습니다.[^1_1]
4. **합성곱 블록**: 지역 정보 학습에 집중합니다.[^1_1]

**FT-SVD 아키텍처**는 중간 층에서 FT 및 SVD 블록이 잠재 공간에서 해당 매개변수를 학습하며, 출력은 예측된 시퀀스 $X_{t+1:t+\tau}$입니다.[^1_1]

### 성능 향상

실험 결과는 9개 데이터셋(ETTh1, ETTh2, ETTm1, ETTm2, Traffic, Electricity, Exchange-Rate, Weather, ILI)에서 TLNets가 대부분의 경우 최고 성능을 달성함을 보여줍니다:[^1_1]

- **Electricity 데이터셋**: 720-step 예측에서 FT-Conv의 MSE는 0.194로 Autoformer(0.254)와 FEDformer(0.246)를 크게 능가합니다.[^1_1]
- **Traffic 데이터셋**: 96-step 예측에서 FT-SVD의 MSE는 0.403으로 모든 baseline 모델을 능가합니다.[^1_1]
- **ETTm1 데이터셋**: FT-Matrix와 FT-SVD는 상관계수(CORR)에서 다른 모델들보다 월등히 높은 성능을 보입니다.[^1_1]


### 한계

논문은 다음과 같은 한계를 인정합니다:[^1_1]

1. **효과적인 변환 설계의 어려움**: 일반적인 작업에 적합한 효과적이고 효율적인 변환을 설계하는 것은 여전히 도전적이며, 현재는 주로 사전 지식에 의존합니다.[^1_1]
2. **계산 요구사항**: FT-Matrix의 계산 요구사항은 입력 길이와 특징 수 모두에 영향을 받으며, 특징 수가 증가하면 더 많은 계산 자원이 필요합니다. 복잡도 분석:[^1_1]
    - SVD: $O(nk^2 + k^3)$
    - FFT: $O(nk \log n)$
    - 행렬 곱셈: $O(onk)$[^1_1]
3. **소규모 데이터셋에서의 제한**: ILI 데이터셋과 같은 작은 규모의 데이터셋에서는 모델의 효과를 충분히 측정하기 어렵습니다.[^1_1]

## 3. 일반화 성능 향상 가능성

TLNets는 **변환 기반 학습을 통해 모델의 일반화 성능을 향상**시킬 수 있는 여러 메커니즘을 갖추고 있습니다:

### 직교 매개변수와 수렴성

SVD 블록은 매개변수의 직교성을 엄격하게 유지하여 더 나은 모델 수렴을 달성합니다. 역전파 기반 모델 학습 과정에서 매개변수 직교성을 유지하는 것은 어렵지만, SVD의 엄격한 직교 특성으로 인해 분해된 가중치($U_{\Phi}, S_{\Phi}, V_{\Phi}$)가 항상 직교성을 유지합니다.[^1_1]

### 다중 스케일 특징 융합

TLNets는 **전역 및 지역 수용 영역의 균형**을 통해 더 나은 표현 학습을 가능하게 합니다. 예를 들어:[^1_1]

- FT와 SVD 블록은 전역 정보를 학습[^1_1]
- Conv 블록은 지역 정보에 집중[^1_1]
- 희소 행렬 블록은 전역 및 지역 정보를 동시에 학습[^1_1]


### Ablation Study를 통한 검증

ETTh1 데이터셋에 대한 ablation study는 각 블록을 개별적으로 사용할 때보다 **블록들을 하나의 네트워크에서 결합할 때 더 나은 성능**을 산출함을 보여줍니다:[^1_1]


| 예측 범위 | TLNets best (MSE) | Matrix 단독 (MSE) | FT 단독 (MSE) | SVD 단독 (MSE) | Conv 단독 (MSE) |
| :-- | :-- | :-- | :-- | :-- | :-- |
| 96 | 0.366 | 0.686 | 0.374 | 0.892 | 0.388 |
| 720 | 0.423 | 0.719 | 0.459 | 0.923 | 0.507 |

이는 다중 변환 메커니즘의 결합이 **과적합을 방지하고 일반화 능력을 향상**시킴을 시사합니다.[^1_1]

### 주파수 도메인 학습의 장점

논문은 단일 층 합성곱이 커널 크기에 의해 결정되는 제한된 주파수만 학습할 수 있음을 증명합니다. 커널 크기가 3인 경우, 행렬 $H$는 대부분의 값이 0이므로 저주파 정보만 포함합니다:[^1_1]

$$
H = Fh
$$

반면, 푸리에 도메인에서 직접 학습하면 **모든 주파수 성분에 접근**할 수 있어, 다양한 시계열 패턴에 대한 일반화 능력이 향상됩니다.[^1_1]

## 4. 연구의 영향과 향후 고려사항

### 앞으로의 연구에 미치는 영향

**1. 수용 영역 학습(RFL) 프레임워크의 새로운 패러다임**

TLNets는 딥러닝 모델을 이해하고 설계하는 데 있어 **더 해석 가능한 프레임워크**를 제공합니다. RFL 정의는 합성곱, 어텐션, 변환 등 다양한 연산을 통합된 관점에서 이해할 수 있게 합니다.[^1_1]

**2. 하이브리드 모델 설계 지침**

논문은 전역과 지역 정보의 균형이 중요함을 강조하며, 이는 향후 시계열 예측 모델 설계에 중요한 지침이 됩니다. 단일 메커니즘보다는 **다중 변환 메커니즘의 결합**이 더 효과적임을 입증했습니다.[^1_1]

**3. 고전적 신호 처리와 딥러닝의 융합**

TLNets는 고전적인 신호 처리 기법(푸리에 변환, SVD)을 딥러닝과 결합하여 성공적인 결과를 달성했습니다. 이는 도메인 지식과 데이터 기반 학습의 융합이 강력함을 보여줍니다.[^1_1]

### 향후 연구 시 고려할 점

**1. 대규모 데이터셋과 사전 학습**

현재 시계열 예측 분야는 **대규모 공개 데이터셋의 부족**으로 인해 사전 학습 모델의 개발이 제한되고 있습니다. ImageNet과 같은 대규모 범용 시계열 데이터셋의 개발이 필수적입니다.[^1_2]

**2. 변환 메커니즘의 자동 선택**

논문의 한계에서 언급했듯이, 현재는 사전 지식에 기반하여 변환을 선택합니다. 향후 연구는 **데이터에 기반하여 자동으로 변환을 생성하거나 선택**하는 메커니즘을 개발해야 합니다.[^1_1]

**3. 계산 효율성 개선**

FT-Matrix의 계산 복잡도는 특징 수가 증가하면 높아집니다. **더 효과적인 희소 행렬 설계**나 유사한 특성을 가진 다른 변환으로의 대체가 필요합니다.[^1_1]

**4. 분포 변화와 개념 이동**

시계열 데이터의 **분포 변화(distribution shift)**는 여전히 중요한 과제입니다. 적응적 학습 메커니즘과 메타 학습 접근법이 필요합니다.[^1_3][^1_4]

**5. 인과성과 해석 가능성**

시계열 예측에서 **인과성 파악과 모델 해석 가능성**은 실제 응용에서 중요합니다. TLNets의 변환 기반 접근은 해석 가능성을 높일 수 있는 잠재력이 있지만, 더 많은 연구가 필요합니다.[^1_4]

## 5. 2020년 이후 관련 최신 연구 비교 분석

### Transformer 기반 모델들

**Autoformer (2021)**는 자기 상관(auto-correlation) 메커니즘과 분해 레이어를 도입했습니다. TLNets는 ETTm1 720-step 예측에서 MSE 0.401로 Autoformer의 0.671을 크게 능가합니다.[^1_2][^1_1]

**FEDformer (2022)**는 주파수 향상 분해 변환을 사용합니다. TLNets는 대부분의 데이터셋에서 FEDformer를 능가하며, 특히 Electricity 720-step 예측에서 FT-Conv의 MSE 0.194가 FEDformer의 0.246보다 우수합니다.[^1_1]

**CATS (2024)**는 자기 어텐션을 제거하고 교차 어텐션만 사용하여 효율성을 개선했습니다. **VARMAformer (2025)**는 VARMA 원리를 통합하여 지역 시간적 종속성을 포착합니다.[^1_5]

### Linear 모델의 부상

**DLinear (2022)**는 단순 선형 레이어가 Transformer를 능가할 수 있다고 주장했습니다. TLNets 실험 결과는 적절히 구성된 Transformer 기반 모델이 여전히 경쟁력이 있음을 보여줍니다. ETTm1 96-step에서 FT-SVD의 MSE 0.295는 DLinear의 0.299와 비슷하지만, 720-step에서는 FT-Matrix의 0.401이 DLinear의 0.425보다 우수합니다.[^1_1]

**RLinear**과 **AverageTime (2024)**는 채널 임베딩과 평균화를 통해 채널 간 상관관계를 포착합니다. 이는 TLNets의 다중 블록 결합 접근과 유사한 철학을 공유합니다.[^1_6]

### Foundation Models와 LLM 기반 접근

**TEMPO (2024)**는 프롬프트 기반 생성 사전 학습 Transformer로 제로샷 시계열 예측을 수행합니다. **TimesFM, Time-GPT, LagLlama (2023-2024)**와 같은 Foundation 모델들이 등장했습니다.[^1_7][^1_8][^1_3]

TLNets와 비교하면, Foundation 모델들은 **대규모 사전 학습**에 의존하는 반면, TLNets는 **명시적인 변환 메커니즘**을 통해 효율적으로 학습합니다. 소규모 데이터셋에서는 TLNets의 접근이 더 실용적일 수 있습니다.[^1_1]

### 하이브리드 및 특수 아키텍처

**SCINet (2021)**은 샘플 합성곱과 상호작용을 사용하며, TLNets 논문에서 효과적인 Conv 기반 모델로 언급됩니다.[^1_1]

**CNN-LSTM 하이브리드 (2024)**는 특징 추출을 위해 CNN을, 시간적 종속성을 위해 LSTM을 결합합니다. TLNets의 FT-Conv와 Conv-SVD는 유사하게 다른 메커니즘을 결합하지만, **명시적인 주파수 도메인 학습**과 **직교 분해**를 추가합니다.[^1_9][^1_1]

**MFF-FTNet (2024)**는 주파수와 시간 도메인에서 다중 스케일 특징 융합을 수행합니다. 이는 TLNets의 다중 변환 접근과 개념적으로 유사하지만, TLNets는 **SVD를 통한 채널 간 상관관계 포착**이라는 추가적인 강점이 있습니다.[^1_10][^1_1]

### 새로운 트렌드

**Mamba와 Diffusion 모델 (2024)**이 시계열 예측에 적용되기 시작했습니다. **DisenTS (2024)**는 다변량 시계열의 다양한 패턴을 분리하여 모델링합니다.[^1_11][^1_4]

**Future-Guided Learning (2025)**은 예측 피드백 메커니즘을 통해 데이터 드리프트에 적응합니다. TLNets의 향후 발전은 이러한 적응적 학습 메커니즘을 통합할 수 있습니다.[^1_12]

### 종합 비교

TLNets (2023)는 2020년대 초반 연구로서 다음과 같은 차별점을 갖습니다:


| 특징 | TLNets | Transformer 기반 | Linear 모델 | Foundation 모델 |
| :-- | :-- | :-- | :-- | :-- |
| 전역 수용 영역 | ✓ (FT, SVD) | ✓ (Attention) | ✗ | ✓ |
| 지역 패턴 포착 | ✓ (Conv, Matrix) | 제한적 | ✓ | 제한적 |
| 계산 효율성 | 중간 | 낮음 | 높음 | 낮음 |
| 해석 가능성 | 높음 | 낮음 | 높음 | 매우 낮음 |
| 사전 학습 필요 | ✗ | ✗ | ✗ | ✓ |

TLNets는 **명시적인 수학적 변환**을 통해 해석 가능성과 성능의 균형을 달성하며, 이는 최근의 블랙박스 Foundation 모델들과 구별되는 강점입니다.[^1_3][^1_1]

**결론적으로**, TLNets는 시계열 예측에서 변환 기반 학습의 효과를 입증했으며, 향후 연구는 적응적 변환 선택, 대규모 사전 학습, 계산 효율성 개선, 그리고 최신 Foundation 모델 기법과의 융합을 고려해야 합니다.[^1_13][^1_4][^1_3][^1_1]
<span style="display:none">[^1_14][^1_15][^1_16][^1_17][^1_18][^1_19][^1_20][^1_21][^1_22][^1_23][^1_24][^1_25][^1_26][^1_27][^1_28][^1_29][^1_30][^1_31][^1_32][^1_33][^1_34][^1_35][^1_36][^1_37][^1_38]</span>

<div align="center">⁂</div>

[^1_1]: 2305.15770v1.pdf

[^1_2]: https://huggingface.co/blog/autoformer

[^1_3]: https://arxiv.org/abs/2401.13912

[^1_4]: https://www.semanticscholar.org/paper/41742e4ae0f3c4afcf5a90eefbd685d63134d911

[^1_5]: https://arxiv.org/abs/2509.04782

[^1_6]: https://arxiv.org/html/2412.20727v3

[^1_7]: http://arxiv.org/pdf/2310.04948.pdf

[^1_8]: https://arxiv.org/html/2410.11773v5

[^1_9]: https://dl.acm.org/doi/10.1145/3677779.3677827

[^1_10]: http://arxiv.org/pdf/2411.17382.pdf

[^1_11]: http://arxiv.org/pdf/2410.22981.pdf

[^1_12]: http://arxiv.org/pdf/2410.15217.pdf

[^1_13]: https://royalsocietypublishing.org/doi/10.1098/rsta.2020.0209

[^1_14]: https://ieeexplore.ieee.org/document/11079452/

[^1_15]: https://onlinelibrary.wiley.com/doi/10.1002/for.3082

[^1_16]: https://www.mdpi.com/2071-1050/16/18/8227

[^1_17]: https://ieeexplore.ieee.org/document/10873159/

[^1_18]: https://link.springer.com/10.1007/s00521-024-09558-5

[^1_19]: https://ieeexplore.ieee.org/document/10583885/

[^1_20]: https://journalofcloudcomputing.springeropen.com/articles/10.1186/s13677-023-00576-7

[^1_21]: https://arxiv.org/pdf/2312.17100.pdf

[^1_22]: https://arxiv.org/pdf/2002.09695.pdf

[^1_23]: https://arxiv.org/pdf/2401.13968.pdf

[^1_24]: https://arxiv.org/abs/2004.13408

[^1_25]: https://arxiv.org/abs/2301.10874

[^1_26]: https://arxiv.org/pdf/2509.26468.pdf

[^1_27]: https://arxiv.org/html/2602.02567v1

[^1_28]: https://arxiv.org/html/2511.01468v1

[^1_29]: https://arxiv.org/html/2512.18661v1

[^1_30]: https://arxiv.org/html/2509.04782v1

[^1_31]: https://arxiv.org/html/2506.06005v1

[^1_32]: https://peerj.com/articles/cs-2312/

[^1_33]: https://peerj.com/articles/cs-3001/

[^1_34]: https://arxiv.org/abs/2411.05793

[^1_35]: https://arxiv.org/abs/2503.10198

[^1_36]: https://www.cbs.nl/-/media/_pdf/2024/40/deep-learning-for-time-series-forecasting-and-nowcasting.pdf

[^1_37]: https://journal.hep.com.cn/fcs/EN/10.1007/s11704-025-50947-3

[^1_38]: https://www.emergentmind.com/topics/time-series-forecasting-models

