# STONE: A Spatio-temporal OOD Learning Framework Kills Both Spatial and Temporal Shifts

### 1. 핵심 주장 및 기여 요약

STONE(Spatio-Temporal OOD Graph Learning Networks with Fréchet Embedding)은 KDD 2024에 발표된 획기적인 연구로, 공간 구조 변화(노드 추가/제거)와 시간적 분포 변화를 동시에 처리하는 첫 번째 종합적 프레임워크입니다. 기존 연구들이 시간적 시프트만 고려한 반면, STONE은 양쪽 시프트를 모두 다룹니다.

**주요 기여:**
- 공간-시간적 OOD(Out-of-Distribution) 학습의 종합적 정의
- Fréchet 임베딩 기반 구조적 변화에 강건한 노드 표현 학습
- 그래프 개입 메커니즘을 통한 다양한 환경 시뮬레이션
- Explore-to-Extrapolate 손실함수를 통한 환경 다양성 증강

### 2. 해결하고자 하는 문제

#### 문제 정의

기존 공간-시간 그래프 신경망은 다음과 같은 가정에 기초합니다:

$$\min_F E_{(x,y) \sim P(x,y|e)} [L(F(x), y)]$$

여기서 훈련 환경 $e$와 테스트 환경이 동일한 분포에서 샘플링됨을 가정합니다. 그러나 실제 트래픽 시스템에서는:

1. **시간적 시프트(Temporal Shift)**: 트래픽 데이터의 평균과 분산이 시간에 따라 변화
   - $P(X^{te}) \neq P(X^{tr})$ (테스트 데이터의 시간 분포가 훈련 분포와 다름)

2. **공간적 시프트(Spatial Shift)**: 도로 네트워크 구조 진화
   - 새로운 센서 추가 (노드 추가)
   - 기존 센서 제거 (노드 제거)
   - 간선 구조 변화

**OOD 학습 목표:**

$$\min_F \max_{e^* \in E} E_{(x,y) \sim P(x,y|e^*)} [L(F(x), y)]$$

### 3. 제안하는 방법 (상세 설명)

#### 3.1 Fréchet 임베딩

기존 Node2Vec 같은 임베딩 방법은 로컬 부분 구조에 민감하여 공간적 시프트에 취약합니다. STONE은 Fréchet 임베딩을 도입:

**정의 1**: 메트릭 공간 $(V, d)$에서 함수 $\phi$는 다음을 만족하면 Fréchet 임베딩:

$$\phi_i(v) = \alpha \cdot \min_{u \in V_i} d(v, u) \quad v \in V, i=1,...,k$$

여기서:
- $V_i$: $i$번째 앵커 세트 (무작위 샘플링된 노드들)
- $d$: K-order Manhattan 거리 메트릭
- $\alpha$: 학습 가능한 파라미터

**성질**: Fréchet 임베딩은 그래프 구조의 상대적 위치 정보를 보존하면서도 신규 노드에 대해 탄력적입니다.

**정리 1 (Bourgain 정리)**: 무작위 샘플링 알고리즘으로 구성된 매핑 함수는 다음 왜곡(distortion)을 만족:

$$E[d(v,u)] \leq (1+\epsilon) d(\phi(v), \phi(u)) \leq (1+\epsilon)^2 d(v,u)$$

왜곡도는 $O(\log n)$입니다.

#### 3.2 의미론적 그래프 학습

**공간 의미 그래프** ($A_S$):

$$\phi^{(l)} = \text{ReLU}(\theta_1 \phi + \theta_2)$$
$$\phi'^{(l)} = \phi^{(l)} \odot \text{Sigmoid}(\theta_3 \phi + \theta_4)$$
$$A_S^{(l)} = \text{SA}(\phi'^{(l)}) = \text{Softmax}(\phi'^{(l)}(\phi'^{(l)})^T/\sqrt{d_h})$$

공간 시멘틱 그래프는 시간 변화 특성의 노드 간 유사도를 인코딩합니다.

**시간 의미 그래프** ($A_T$):

$$h^{(l)} = \text{ReLU} \odot \text{TCN}(x^{(l-1)})$$
$$\tilde{h} = \text{Concat}(h^{(1)}, h^{(2)}, ..., h^{(n)}) \in \mathbb{R}^{T \times N \times d}$$
$$A_T = \text{SA}(\tilde{h}) = \text{Softmax}(\tilde{h}(\tilde{h})^T/\sqrt{d})$$

TCN(Temporal Convolutional Network)을 사용하여 다중 스케일 시간 의존성을 캡처합니다.

#### 3.3 그래프 개입 메커니즘

**노이즈 추가**:

$$\xi \sim N(0,1)$$
공간 시프트를 시뮬레이션하기 위해 Fréchet 임베딩 출력에 가우시안 노이즈를 추가합니다.

**마스킹 전략**:

$$M_{i,j}^{(m)} \sim \text{Bernoulli}(1, p_m)$$

개입 행렬을 생성하여 엣지를 선택적으로 마스킹:

$$A_S^{(m)} = M_S^{(m)} \odot A_S$$
$$A_T^{(m)} = M_T^{(m)} \odot A_T$$

여기서 각 행은 동일한 이항분포에서 샘플링되어 계산 효율성을 높입니다.

**확산 그래프 컨볼루션**:

$$Z_T = D^{-1}(I - \alpha L_D) \cdot H_T \cdot W_T$$
$$Z_S = D^{-1}(I - \alpha L_D) \cdot H_S \cdot W_S$$

확산 단계를 통해 정보가 그래프 전체에 자연스럽게 전파됩니다.

#### 3.4 최적화 손실함수

**예측 손실**:

$$L_{pred}(M_1,...,M_k) = \frac{1}{k}\sum_{m=1}^k L_{MSE}(\hat{y}_m, y)$$

**불변 위험 최소화 (IRM)**:

$$L_{IRM} = \sum_{m=1}^k \text{Var}_m(L_{pred}(M_1,...,M_k))$$

다양한 개입 환경에서 손실의 분산을 최소화합니다.

**Explore-to-Extrapolate 손실**:

$$L_{E2E} = -\max_{M_1,...,M_k} \text{Var}_{loss}(L_{pred}(M_1,...,M_k))$$

환경의 다양성을 극대화하여 모델의 일반화 능력을 강화합니다.

**최종 목적함수**:

$$\min_\theta \text{Var}(L_{pred}(M_1,...,M_k)) + \lambda L_{IRM} - \beta \underbrace{\max_{M_1,...,M_k} \text{Var}(L_{pred})}_{\text{Explore-to-Extrapolate}}$$

### 4. 모델 구조

STONE의 전체 아키텍처는 다음 세 가지 핵심 모듈로 구성:

1. **의미 그래프 학습 모듈**: Fréchet 임베딩 + 게이트 트랜스포머
2. **공간-시간 그래프 컨볼루션 모듈**: 확산 GCN을 통한 정보 집계
3. **그래프 개입 메커니즘**: 다양한 환경 생성을 통한 강건성 학습

### 5. 성능 향상 및 실험 결과

| Dataset | STONE MAE | 최고 기준선 MAE | 개선율 |
|---------|-----------|----------------|--------|
| STSD-10 | 18.17 | 24.23 | **25.1%** |
| STSD-15 | 19.36 | 24.05 | **19.5%** |
| STSD-20 | 19.32 | 23.89 | **19.1%** |
| STGBA-10 | 17.67 | 26.86 | **34.2%** |
| STGBA-15 | 18.73 | 26.78 | **30.1%** |
| STGBA-20 | 18.83 | 26.82 | **29.7%** |

**평균 개선율: 26.3%**

### 6. 일반화 성능 향상 가능성

#### 6.1 일반화 능력 분석

STONE의 일반화 성능은 세 가지 메커니즘에서 비롯됩니다:

**1) 불변 특성 학습**

개입된 다양한 환경에서 공통적으로 나타나는 불변 노드 의존성을 학습함으로써:
- 특정 그래프 구조에 과적합되는 것을 방지
- 신규 환경에서의 강건한 예측 가능

**2) Fréchet 임베딩의 탄력성**

- 신규 노드: 앵커 세트까지의 거리 계산으로 즉시 임베딩 가능
- 제거된 노드: 다른 노드의 의존성 경로로 정보 손실 최소화
- 구조 변화: 상대적 위치 정보 보존으로 강건함

**3) 환경 다양성 극대화**

Explore-to-Extrapolate 손실이 훈련 데이터의 분포를 넘어서는 환경도 탐색하여:
- 미지의 분포에 대한 외삽(Extrapolation) 능력 강화
- 예측 불확실성 감소

#### 6.2 확장성(Scalability) 성능

새로운 노드(unseen nodes)에 대한 예측 성능:

- **GCN 기반 모델**: 새 노드에 대해 이웃 정보가 부족하여 성능 저하
- **STONE**: 의미론적 이웃 정보를 통해 새 노드의 임베딩을 정확히 추론
  - STSD-10에서 새 노드 MAE 17.22 (대비 GWNet 19.58)

#### 6.3 환경 변화에 대한 강건성

| 시프트 유형 | STONE | CaST | CauSTG | 개선도 |
|----------|--------|------|---------|---------|
| 시간만 | 18.26 | 22.83 | 24.97 | **20.2%** |
| 시간+공간 | 18.17 | 24.23 | 26.42 | **25.1%** |

### 7. 한계(Limitations) 및 도전과제

#### 기술적 한계

1. **계산 복잡도**: 다중 개입 행렬 $M_1, ..., M_k$의 생성 및 마스킹으로 인한 훈련 비용 지수적 증가

2. **수렴 속도**: 많은 마스킹 연산자로 인해 최적화 어려움

3. **하이퍼파라미터 민감도**: 앵커 세트 개수, 마스킹 확률 등의 튜닝 필요

#### 적용 범위 한계

1. **데이터셋 제한**: 교통 데이터셋(PeMS)에만 실험
   - 다른 공간-시간 도메인(기후, 에너지, 보건) 검증 부족

2. **시계열 길이**: 단기 예측(3, 6, 12 시간)에 집중
   - 장기 예측의 성능 미지수

3. **그래프 크기**: 최대 2,352개 노드 실험
   - 수십만 개 이상의 대규모 그래프에 대한 성능 미검증

### 8. 2020년 이후 관련 최신 연구 비교 분석

#### 시간대별 연구 진화

| 연구 | 출판년 | 주요 특징 | 시간 시프트 | 공간 시프트 | 인과성 | 개입 메커니즘 |
|------|--------|---------|-----------|-----------|--------|------------|
| **AdaRNN** | 2021 | 동적 매칭 | ✓ | ✗ | ✗ | 없음 |
| **STEVE** | 2023 | 분해된 표현 | ✓ | ✗ | ✓ | 자가감독 |
| **CaST** | 2023 | 인과 SCM | ✓ | ✗ | ✓ | 백도어 조정 |
| **CauSTG** | 2024 | 지역-전역 관계 | ✓ | ✓ | ✓ | 그래프 학습 |
| **STONE** | 2024 | **Fréchet 임베딩** | ✓ | ✓ | ✓ | **엣지 마스킹** |
| **STOP** | 2025 | 중앙화 메시징 | ✓ | ✓ | ✓ | 메시지 섭동 |
| **CAN-ST** | 2025 | 클러스터 정규화 | ✓ | ✓ | ✗ | 정규화 |
| **UniSTD** | 2025 | 통합 다중과제 | ✓ | ✓ | ✗ | 혼합 전문가 |

#### 기술적 혁신 추이

**1단계 (2020-2022): OOD 인식의 출현**
- 기존 시공간 GNN의 일반화 문제 지적
- 시간적 시프트만 다루는 초기 접근

**2단계 (2023): 인과 학습 통합**
- 구조적 인과 모델(SCM) 도입
- 환경 분해(environment decomposition) 시작

**3단계 (2024-2025): 공간-시간 동시 처리 및 메커니즘 혁신**
- **STONE의 획기적 기여**: 공간 시프트의 체계적 처리
- Fréchet 임베딩의 이론적 근거 제시
- 그래프 개입을 통한 명시적 환경 생성

#### STONE vs. 경쟁 방법

**vs. CaST (2023):**
- CaST는 시간적 시프트만 고려
- STONE은 공간 시프트까지 포괄 (새 노드 추가/제거)
- MAPE에서 최대 18.13% 우수

**vs. CauSTG (2024):**
- 둘 다 공간-시간 시프트 다룸
- STONE: 의미 그래프 기반 접근 (구조 보존성)
- CauSTG: 인과 관계 추출 (해석성)
- STONE이 확장성에서 우위 (새 노드 처리)

**vs. STOP (2025):**
- STOP: 중앙화된 메시징으로 노드-노드 상호작용 차단
- STONE: 개입된 의미 그래프를 통한 불변 학습
- 두 방법 모두 강력하지만 철학적 차이 있음
- STOP은 메시지 기반, STONE은 임베딩 기반

### 9. 향후 연구에 미치는 영향

#### 9.1 이론적 기여

1. **공간-시간 OOD 문제의 정식화**
   - 처음으로 시간과 공간 시프트를 동시에 다루는 프레임워크 제시
   - 향후 연구의 벤치마크 정의

2. **Fréchet 임베딩의 이론화**
   - 그래프에 적용된 최초의 체계적 분석
   - 왜곡도 상한의 수학적 증명
   - 새로운 구조 학습 방법의 아이디어 제공

3. **인과학과 기계학습의 교점**
   - 개입(intervention) 개념을 그래프 신경망에 적용
   - IRM과 그래프 학습의 결합

#### 9.2 실무적 영향

1. **교통 시스템 실배포**
   - 동적으로 변화하는 도시 도로망의 예측 가능성 향상
   - 신규 센서 설치 시 빠른 적응

2. **새로운 도메인 확장**
   - 기후 모델링 (기상 관측소 추가)
   - 에너지 그리드 (신규 전력선 추가)
   - 전염병 모니터링 (감염자 추적점 변화)

#### 9.3 연구 방향

**단기 (1-2년)**
1. STONE의 다중 도메인 검증
2. 계산 효율성 개선 (앵커 세트 최적화)
3. 적응형 개입 메커니즘 개발

**중기 (2-3년)**
1. 매우 큰 그래프 ($10^6$ 이상의 노드)에 대한 확장성
2. 실시간 동적 그래프 처리
3. 개인화된 예측 모델 개발

**장기 (3-5년)**
1. 그래프 시프트와 노드 피처 시프트의 동시 처리
2. 메타-러닝을 통한 신규 환경의 빠른 적응
3. 기초 모델(Foundation Model) 개발

### 10. 연구 수행 시 고려사항

#### 10.1 방법론적 고려사항

1. **환경 생성의 현실성**
   - 마스킹을 통한 개입이 실제 공간 시프트를 충분히 반영하는가?
   - 다양한 시프트 시나리오를 모두 포괄하는가?

2. **하이퍼파라미터 선택**
   - 앵커 세트 개수 $k$: 데이터셋 크기에 따라 $10 \sim 30$
   - 마스킹 확률: 각 행렬에 대해 학습 가능하게 설정
   - $\lambda$, $\beta$ 트레이드오프 조정

3. **일반화 측정**
   - 단순히 MAE, RMSE뿐만 아니라 분포 거리(Wasserstein, MMD) 측정
   - OOD 감지 성능도 평가

#### 10.2 실험 설계

1. **데이터셋 구성**
   - 명확한 시간-공간 시프트 경계 정의
   - 새 노드와 제거된 노드의 위치가 무작위 vs. 체계적일 때의 차이

2. **기준선 선택**
   - 최신 방법론 포함: CauSTG, STEVE, CaST 모두 비교
   - 간단한 방법론: 이동평균, ARIMA 등과도 비교

3. **통계적 검증**
   - 다중 실행의 평균과 표준편차 보고
   - 신뢰 구간 제시

#### 10.3 해석 및 분석

1. **Fréchet 임베딩의 시각화**
   - t-SNE/UMAP으로 임베딩 공간 가시화
   - 신규 노드의 위치가 의미론적으로 올바른지 확인

2. **의미 그래프 분석**
   - 공간/시간 의미 그래프의 엣지 가중치 분포 비교
   - 의미 그래프가 지리적 인접성을 넘어서는 관계를 포착하는지 확인

3. **환경 다양성**
   - 생성된 개입 환경들의 손실 분산이 충분한지 검증
   - 환경 간 거리(분포 거리)의 증가 추이

### 결론

STONE은 공간-시간적 OOD 학습의 새로운 지평을 열었습니다. Fréchet 임베딩의 도입은 구조적 변화에 강건한 표현 학습의 이론적 근거를 제공하고, 그래프 개입 메커니즘은 인과학의 개입 개념을 실무에 체화했습니다. 

평균 26.3%의 성능 향상과 우수한 확장성을 통해 동적 시공간 시스템에 대한 모델의 실용성을 증명했으나, 계산 효율성 개선과 다중 도메인 검증이라는 과제가 남아있습니다. 향후 연구는 STONE의 이론적 기초 위에서 더욱 효율적이고 해석 가능한 방법론 개발로 나아갈 것으로 예상됩니다.

<span style="display:none">[^1_1][^1_10][^1_11][^1_12][^1_13][^1_14][^1_15][^1_16][^1_17][^1_18][^1_19][^1_2][^1_20][^1_21][^1_22][^1_23][^1_24][^1_25][^1_26][^1_27][^1_28][^1_29][^1_3][^1_30][^1_31][^1_32][^1_33][^1_34][^1_35][^1_36][^1_37][^1_38][^1_39][^1_4][^1_40][^1_41][^1_42][^1_43][^1_44][^1_45][^1_46][^1_5][^1_6][^1_7][^1_8][^1_9]</span>

<div align="center">⁂</div>

[^1_1]: 3637528.3671680.pdf

[^1_2]: https://link.springer.com/10.1007/s00477-025-03123-9

[^1_3]: https://www.semanticscholar.org/paper/e5f7eb4403743c68a20b89a5c25c00739ca752e0

[^1_4]: https://www.mdpi.com/2076-3417/10/12/4254

[^1_5]: https://www.semanticscholar.org/paper/5f6f7b20b25fcc84bf9447764ecdec868d0ad7cb

[^1_6]: https://www.mdpi.com/2072-4292/12/7/1203

[^1_7]: https://www.europeanproceedings.com/article/10.15405/epsbs.2020.05.5

[^1_8]: https://link.springer.com/10.1007/s11042-020-09048-5

[^1_9]: https://essd.copernicus.org/articles/12/2043/2020/essd-12-2043-2020-discussion.html

[^1_10]: https://www.mdpi.com/2072-4292/12/11/1741

[^1_11]: https://onlinelibrary.wiley.com/doi/10.1111/tbed.13902

[^1_12]: https://arxiv.org/pdf/2503.20748.pdf

[^1_13]: https://arxiv.org/pdf/2411.10198.pdf

[^1_14]: https://arxiv.org/pdf/2205.03212.pdf

[^1_15]: http://arxiv.org/pdf/2411.12164.pdf

[^1_16]: https://arxiv.org/html/2410.10524v1

[^1_17]: https://arxiv.org/pdf/2206.12126.pdf

[^1_18]: https://arxiv.org/pdf/2501.09045.pdf

[^1_19]: https://arxiv.org/html/2406.12709v1

[^1_20]: https://pdfs.semanticscholar.org/5139/937fb0ed52e6b30dcec3c46822ba4390ada4.pdf

[^1_21]: https://arxiv.org/html/2511.13785v1

[^1_22]: https://arxiv.org/abs/2407.09378

[^1_23]: https://peerj.com/articles/15913/

[^1_24]: https://arxiv.org/html/2305.17965v3

[^1_25]: https://arxiv.org/abs/2411.13821

[^1_26]: https://arxiv.org/pdf/2304.11213.pdf

[^1_27]: https://arxiv.org/html/2410.00373v1

[^1_28]: https://arxiv.org/abs/2401.15444

[^1_29]: http://arxiv.org/list/physics/2023-10?skip=680\&show=2000

[^1_30]: https://arxiv.org/pdf/2509.15291.pdf

[^1_31]: https://arxiv.org/abs/2312.12477

[^1_32]: https://journals.plos.org/plosone/article?id=10.1371%2Fjournal.pone.0146101

[^1_33]: https://arxiv.org/html/2509.15291v1

[^1_34]: https://arxiv.org/abs/2409.08544

[^1_35]: https://proceedings.mlr.press/v267/ma25s.html

[^1_36]: https://www.alphaxiv.org/overview/2504.13111v2

[^1_37]: https://eccv.ecva.net/virtual/2024/poster/472

[^1_38]: https://openreview.net/forum?id=q6ba0bZfpl

[^1_39]: https://openreview.net/forum?id=X52pu7VKVK

[^1_40]: https://www.ijcai.org/proceedings/2025/0394.pdf

[^1_41]: https://www.nature.com/articles/s41598-025-92859-z

[^1_42]: https://dl.acm.org/doi/10.1145/3637528.3671680

[^1_43]: https://arxiv.org/abs/2311.14994

[^1_44]: https://www.sciencedirect.com/science/article/abs/pii/S1383762125001973

[^1_45]: https://ieeexplore.ieee.org/document/10733567/

[^1_46]: https://arxiv.org/abs/2404.12238
