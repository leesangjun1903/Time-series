# Time-Series Representation Learning via Temporal and Contextual Contrasting

## 1. 핵심 주장과 주요 기여[1]

**TS-TCC(Time-Series representation learning framework via Temporal and Contextual Contrasting)**는 레이블이 없는 시계열 데이터에서 **견고하고 판별력 있는 표현(representation)을 학습**하기 위한 자기 지도 학습(self-supervised learning) 프레임워크이다.[1]

본 논문의 핵심 주장은 컴퓨터 비전에서 성공한 대조 학습(contrastive learning) 방법들이 **시계열 데이터의 시간적 의존성(temporal dependency)을 충분히 반영하지 못한다**는 것이다. 이를 해결하기 위해 시계열 데이터에 특화된 두 가지 대조 모듈을 제안한다.[1]

**주요 기여는 다음과 같다:**[1]

- 시계열 데이터를 위한 새로운 대조 학습 프레임워크 개발
- 약한 증강(weak augmentation)과 강한 증강(strong augmentation)을 활용한 효율적인 데이터 증강 전략
- **시간 대조(temporal contrasting) 모듈**: 교차 뷰 예측 작업을 통해 견고한 시간적 표현 학습
- **문맥 대조(contextual contrasting) 모듈**: 동일 샘플의 문맥 간 유사성은 최대화하고 다른 샘플 간의 유사성은 최소화하여 판별력 있는 표현 학습

***

## 2. 해결 문제, 방법론, 모델 구조, 성능[1]

### 2.1 해결하고자 하는 문제[1]

시계열 데이터는 다음과 같은 어려움이 있다:[1]

- IoT 및 웨어러블 기기에서 생성되는 데이터가 많지만 **레이블 데이터가 부족**함
- 사람이 인식 가능한 패턴이 명확하지 않아 **전문가 주석이 필요**
- 기존 대조 학습 방법들(이미지 기반)은 **시계열의 시간적 의존성을 반영하지 못함**
- 색상 왜곡(color distortion) 등 이미지 증강 기법을 시계열에 직접 적용할 수 없음

### 2.2 제안 방법론[1]

#### **2.2.1 데이터 증강(Time-Series Data Augmentation)**[1]

약한 증강과 강한 증강을 구분 적용:

**약한 증강(Weak Augmentation):** Jitter-scale 전략
- 신호에 임의의 변동을 추가
- 신호 크기를 스케일업

**강한 증강(Strong Augmentation):** Permutation-jitter 전략
- 신호를 $$M$$개 이하의 세그먼트로 분할하여 임의로 재배열
- 재배열된 신호에 무작위 지터 추가

주어진 입력 샘플 $$x$$에 대해:[1]

- 강한 증강 뷰: $$x^s \sim T_s$$
- 약한 증강 뷰: $$x^w \sim T_w$$

#### **2.2.2 시간 대조 모듈(Temporal Contrasting Module)**[1]

**핵심 아이디어:** 교차 뷰 예측 작업을 통해 증강에 의한 섭동에 강건한 표현 학습

인코더는 입력을 고차원 잠재 표현으로 매핑:[1]

$$z = f_{enc}(x) = [z_1, z_2, \ldots, z_T], \quad z_i \in \mathbb{R}^d$$

자회귀 모델(Transformer)이 시간 $$t$$까지의 모든 $$z_t$$를 문맥 벡터로 요약:[1]

$$c_t = f_{ar}(z_{\leq t}), \quad c_t \in \mathbb{R}^h$$

여기서 $$h$$는 숨겨진 차원(hidden dimension)이다.

**로그-쌍선형 모델(log-bilinear model)**을 사용하여 미래 시간 단계 예측:[1]

$$f_k(x_{t+k}, c_t) = \exp(W_k c_t^T z_{t+k})$$

여기서 $$W_k \in \mathbb{R}^{h \times d}$$는 선형 함수이고, $$k \in \{1, \ldots, K\}$$이다.

**교차 뷰 예측 손실:** 강한 증강의 문맥으로 약한 증강의 미래를 예측하고 그 반대도 수행[1]

$$L_t^{TC}(s) = -\frac{1}{K} \sum_{k=1}^{K} \log \frac{\exp(W_k c_t^s{}^T z_{t+k}^w)}{\sum_{n \in \mathcal{N}_{t,k}} \exp(W_k c_t^s{}^T z_{t+k}^n)}$$

$$L_t^{TC}(w) = -\frac{1}{K} \sum_{k=1}^{K} \log \frac{\exp(W_k c_t^w{}^T z_{t+k}^s)}{\sum_{n \in \mathcal{N}_{t,k}} \exp(W_k c_t^w{}^T z_{t+k}^n)}$$

#### **2.2.3 문맥 대조 모듈(Contextual Contrasting Module)**[1]

각 샘플에서 두 개의 증강 뷰로부터 얻은 두 개의 문맥을 활용하여 더 판별력 있는 표현 학습[1]

배치 크기 $$N$$에 대해 총 $$2N$$개의 문맥 생성:
- 긍정 쌍(positive pair): 동일 샘플의 다른 증강에서 온 문맥 $$(c_t^i, \tilde{c}_t^i)$$
- 부정 쌍(negative pair): 다른 샘플의 문맥 $$2N-2$$개

**문맥 대조 손실(Contextual Contrasting Loss):**[1]

$$L_{CC} = -\sum_{i=1}^{N} \log \frac{\exp(\text{sim}(c_t^i, \tilde{c}_t^i) / \tau)}{\sum_{m=1}^{2N} \mathbb{1}_{m \neq i} \exp(\text{sim}(c_t^i, c_t^m) / \tau)}$$

여기서 $$\text{sim}(u, v) = \frac{u^T v}{\|u\|\|v\|}$$는 코사인 유사성이고, $$\tau$$는 온도 매개변수이다.

#### **2.2.4 전체 손실 함수**[1]

$$L = \lambda_1(L_t^{TC}(s) + L_t^{TC}(w)) + \lambda_2 L_{CC}$$

여기서 $$\lambda_1 = 1$$, $$\lambda_2 = 0.7$$로 설정된다.

### 2.3 모델 구조[1]

**전체 아키텍처:**[1]

1. **입력 처리**: 약한 증강과 강한 증강으로 두 개의 뷰 생성
2. **인코더**: 3-블록 합성곱(CNN) 아키텍처로 고차원 특징 추출
3. **시간 대조 모듈**: Transformer 기반 자회귀 모델
   - $$L=4$$ 스택
   - 4개의 헤드를 가진 다중 헤드 주의(Multi-Head Attention)
   - 각 헤드는 선형 투영, MLP, 드롭아웃으로 구성
   - BERT 스타일의 특수 토큰 $$c$$를 컨텍스트 벡터로 사용
4. **비선형 투영 헤드**: 문맥 대조를 위해 문맥을 추가 변환

**Transformer 계산 과정:**[1]

$$\mathbf{z} = W_{Tran} z_t, \quad \mathbf{z} \in \mathbb{R}^h$$

$$\hat{\mathbf{z}}^{(0)} = [\mathbf{c}, \mathbf{z}]$$

$$\text{MHA}: \hat{\mathbf{z}}^{(\ell)} = \text{MultiHeadAtt}(\text{Norm}(\hat{\mathbf{z}}^{(\ell-1)})), \quad \ell = 1, \ldots, L$$

$$\text{MLP}: \hat{\mathbf{z}}^{(\ell)} = \text{MLP}(\text{Norm}(\hat{\mathbf{z}}^{(\ell)}))$$

$$c_t = \hat{\mathbf{z}}^{(L)}_{\text{token}}$$

### 2.4 성능 향상[1]

#### **2.4.1 선형 평가(Linear Evaluation)**[1]

냉동된 인코더 위에 단일 MLP 레이어로 구성된 선형 분류기 훈련:

| 데이터셋 | HAR | Sleep-EDF | Epilepsy |
|---------|-----|-----------|----------|
| 랜덤 초기화 | 57.89% | 35.61% | 90.26% |
| **지도 학습** | **90.14%** | **83.41%** | **96.66%** |
| CPC | 83.85% | 82.82% | 96.61% |
| SimCLR | 80.97% | 78.91% | 96.05% |
| **TS-TCC** | **90.37%** | **83.00%** | **97.23%** |

TS-TCC는 HAR과 Epilepsy에서 **지도 학습과 동등하거나 초과**하며, 모든 기존 방법을 능가한다.[1]

#### **2.4.2 반지도 학습(Semi-supervised Learning)**[1]

레이블된 데이터 1%, 5%, 10%, 50%, 75% 시나리오에서 평가:

- TS-TCC는 **1% 레이블로도 약 70%(HAR), 90%(Epilepsy) 성능 달성**
- **10% 레이블**로 **100% 레이블 지도 학습과 동등한 성능** 달성
- 레이블이 부족한 환경에서 지도 학습 대비 **현저한 우위**

#### **2.4.3 전이 학습(Transfer Learning)**[1]

결함 진단 데이터셋에서 12개 교차 도메인 시나리오 평가:

- TS-TCC는 **12개 중 8개 시나리오에서 우수한 성능**
- 평균적으로 지도 학습 대비 **약 4% 정확도 향상**
- 일부 도메인에서는 **7% 이상 성능 개선**

#### **2.4.4 절제 연구(Ablation Study)**[1]

| 구성 | HAR | Sleep-EDF | Epilepsy |
|------|-----|-----------|----------|
| 시간 대조만 (TC only) | 82.76% | 80.55% | 94.39% |
| TC + 교차 증강 | 87.86% | 81.58% | 95.56% |
| **TS-TCC** | **90.37%** | **83.00%** | **97.23%** |
| 약한 증강만 | 76.55% | 80.90% | 97.18% |
| 강한 증강만 | 60.23% | 78.55% | 97.14% |

- **교차 뷰 예측 작업**: HAR에서 **5% 이상**, 다른 데이터셋에서 **1% 성능 향상**
- **문맥 대조 모듈**: 추가적인 판별력으로 전체 성능 **최적화**
- **이중 증강 전략**: HAR, Sleep-EDF에서 중요하나 Epilepsy에서는 단일 증강도 **적절한 성능**

### 2.5 한계[1]

1. **데이터셋 의존성**: 증강 하이퍼파라미터($$M$$, 지터 비율)가 **시계열 데이터의 특성에 따라 신중하게 조정 필요**

2. **계산 복잡도**: Transformer 기반 자회귀 모델로 인한 **상대적으로 높은 계산 비용**

3. **제한된 평가 범위**: 
   - 3개의 시계열 분류 데이터셋만 평가
   - 시계열 예측(forecasting), 이상 탐지(anomaly detection) 등 다른 작업에 대한 평가 부재

4. **예측 단계 선택**: 예측할 미래 시간 단계 개수 $$K$$의 선택이 **성능에 영향**을 미치며, 감도 분석에서 $$K = d/40$$일 때 최적(여기서 $$d$$는 특징 길이)

5. **강건성 평가 부족**: 
   - 노이즈, 이상치, 분포 변화(domain shift)에 대한 명시적 강건성 분석 미비
   - 이상 탐지 시나리오에서의 성능 미평가

***

## 3. 일반화 성능 향상 가능성[1]

### 3.1 현재 일반화 성능[1]

**전이 학습 성능:**[1]

교차 도메인 전이 학습에서 TS-TCC는 지도 학습 대비 **평균 4% 정확도 향상**, 일부 도메인에서는 **7% 이상 개선**을 달성했다. 이는 TS-TCC가 **도메인 간 일반화 능력이 우수**함을 시사한다.

**반지도 학습 성능:**[1]

제한된 레이블 환경에서 TS-TCC는 다음을 달성:
- 1%의 레이블만으로도 상당한 성능 유지
- 10% 레이블로 100% 레이블 지도 학습과 동등한 성능

이는 **자기 지도 학습을 통해 충분한 일반화 가능한 표현을 사전 학습**할 수 있음을 의미한다.

### 3.2 일반화 성능 향상 메커니즘[1]

#### **3.2.1 견고한 시간적 표현 학습**[1]

교차 뷰 예측 작업이 모델을 강제:
- 약한 증강과 강한 증강의 차이를 극복하도록 함
- 증강에 **불변인(invariant) 시간적 특징** 추출
- 이는 **다양한 도메인의 시계열에 더 잘 일반화**되는 표현을 생성

#### **3.2.2 판별력 있는 특징**[1]

문맥 대조 모듈이:
- 동일 샘플의 서로 다른 증강 문맥 간의 유사성 최대화
- 다른 샘플 간의 유사성 최소화
- 결과적으로 **클래스 내 결집력과 클래스 간 분리**를 동시에 달성

#### **3.2.3 효율적인 레이블 활용**[1]

자기 지도 사전 학습 후 미세 조정 시:
- 초기 특징이 이미 **판별력 있고 도메인 불변**이므로
- **소량의 레이블 데이터로도 빠른 수렴** 가능
- 이는 전이 학습 성능 향상으로 이어짐

### 3.3 향후 일반화 성능 향상 방안[1]

1. **다양한 시계열 작업 평가**: 분류뿐만 아니라 예측, 이상 탐지 등에 확장

2. **도메인 적응(Domain Adaptation)**: 다중 도메인 설정에서 TS-TCC를 적용하여 **도메인 간 적응력 강화**

3. **데이터 증강 개선**: 시계열 특성에 따라 **적응적으로 증강 강도 조정**

4. **모델 경량화**: Transformer 대신 **경량 자회귀 모델** 탐색으로 계산 효율성과 일반화 성능 균형

***

## 4. 연구 영향 및 향후 고려사항[1]

### 4.1 학계 및 산업에 미치는 영향[1]

#### **4.1.1 학계 영향**[1]

1. **시계열 자기 지도 학습의 새로운 방향**: TS-TCC는 **시간적 의존성을 명시적으로 고려한 첫 주요 작업** 중 하나이며, 시계열 표현 학습 연구의 표준으로 작용

2. **대조 학습의 확장**: 이미지 기반 대조 학습에서 **시계열 도메인으로의 성공적 확장**을 시연하여, 다른 순차 데이터(NLP, 음성 등)로의 확장 가능성 제시

3. **무감독 학습의 실용성 증대**: 레이블 데이터 부족 환경에서 **자기 지도 학습의 실질적 유용성** 입증

#### **4.1.2 산업 적용**[1]

1. **의료 센서 데이터**: EEG, ECG 등 의료 생체 신호 분석에서 **레이블 데이터 부족 문제 완화**

2. **IoT/스마트 디바이스**: 수집되는 대량의 미레이블 센서 데이터에서 **효율적인 특징 추출 가능**

3. **산업 모니터링**: 결함 진단 등에서 **전이 학습을 통한 빠른 배포**

### 4.2 향후 연구 시 고려할 점[1]

#### **4.2.1 방법론적 개선**[1]

1. **적응적 증강 전략**: 데이터 특성에 따라 **동적으로 증강 강도 조정**하는 메커니즘 개발

2. **다중 시간 스케일 고려**: 단기, 중기, 장기 시간적 의존성을 **계층적으로 모델링**

3. **노이즈 강건성**: 실제 환경의 **노이즈, 이상치에 대한 명시적 강건성 개선**

#### **4.2.2 평가 범위 확대**[1]

1. **다양한 작업**: 분류뿐 아니라 **예측, 이상 탐지, 시계열 분할** 등으로 확대

2. **대규모 데이터셋**: 더 큰 규모의 **현실 데이터셋에서 성능 검증**

3. **도메인 이동(Domain Shift)**: 훈련과 배포 환경의 **분포 변화에 대한 강건성 평가**

#### **4.2.3 모델 효율성**[1]

1. **계산 복잡도 감소**: 현재 Transformer 기반 모델의 **계산 비용 최적화**

2. **경량 모델 개발**: 엣지 기기 배포를 위한 **축소 모델 변형**

3. **온라인 학습**: 스트리밍 시계열에 대한 **효율적 업데이트 메커니즘**

#### **4.2.4 이론적 이해**[1]

1. **수렴성 분석**: 대조 손실이 의미 있는 표현으로 **수렴함을 보장하는 이론적 분석**

2. **일반화 경계**: 학습된 표현의 **일반화 성능에 대한 이론적 상한** 도출

3. **증강 효과 분석**: 어떤 증강이 왜 효과적인지에 대한 **심층적 이론적 분석**

---

## 결론[1]

TS-TCC는 **시계열 데이터의 고유한 특성을 반영한 첫 번째 포괄적 대조 학습 프레임워크**로, 자기 지도 학습 분야에서 주요 진전을 이루었다. 특히 **시간적 표현과 판별력 있는 특징의 동시 학습**, **레이블 효율성**, **전이 학습 성능**에서 우수한 결과를 보여준다. 향후 연구는 모델 효율성, 평가 범위 확대, 도메인 강건성 등에 초점을 맞춘다면, 이 연구가 **시계열 머신러닝의 실용적 적용**을 크게 촉진할 수 있을 것으로 예상된다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/722178d6-15a2-467a-bd28-7be3fddccae2/2106.14112v1.pdf)
