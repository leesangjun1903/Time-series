# TEST: Text Prototype Aligned Embedding to Activate LLM's Ability for Time Series

## Executive Summary

"TEST: Text Prototype Aligned Embedding to Activate LLM's Ability for Time Series"는 ICLR 2024에 발표된 논문으로, 대규모 언어 모델(LLM)의 시계열 데이터 처리 능력을 활성화하는 데이터 중심적 방법론을 제시합니다. 본 논문의 핵심은 시계열을 LLM이 이해할 수 있는 임베딩으로 변환하고, 프리트레인된 LLM을 동결한 상태에서 다양한 시계열 작업을 수행하는 TS-for-LLM 패러다임입니다. TEST는 인스턴스 레벨, 피처 레벨, 텍스트 프로토타입 정렬 대비 학습을 결합하여 128개의 유니변량 및 30개의 다변량 시계열 분류 데이터셋, 장단기 예측, 그리고 몇샷(few-shot) 학습에서 기존 SOTA 모델과 비교 가능하거나 우수한 성능을 달성합니다.

***

## 1. 핵심 주장 및 주요 기여

### 1.1 핵심 주장

TEST의 중심 논제는 **시계열(TS)을 LLM 친화적 표현으로 변환하면, 프리트레인된 LLM을 수정하지 않고도 시계열 작업 수행이 가능하다**는 것입니다. 저자들은 기존의 두 가지 접근 방식을 대조합니다:

- **LLM-for-TS (모델 중심)**: LLM을 시계열용으로 파인튜닝하거나 처음부터 훈련
  - 장점: 높은 정확도
  - 단점: 대규모 데이터셋 필요, 도메인 특화성, 언어 능력 손실

- **TS-for-LLM (데이터 중심)**: 시계열을 LLM이 이해할 수 있도록 변환
  - 장점: 소규모 데이터 사용 가능, 범용성, 언어 능력 유지
  - 단점: LLM의 원래 능력을 넘기 어려움

본 논문은 후자의 접근 방식을 택하며, **LLM을 패턴 머신으로 활용**한다는 관점에서 이를 정당화합니다.

### 1.2 주요 기여

1. **패러다임 분류 및 정리**: TS+LLM 연구 영역을 체계적으로 분류하고 각 방식의 장단점 제시

2. **TEST 방법론 제안**: 
   - 인스턴스 레벨 대비 학습
   - 피처 레벨 대비 학습 (새로운 접근)
   - 텍스트 프로토타입을 통한 정렬
   - 이 세 가지를 결합한 통합 프레임워크

3. **이론적 기여**: 소프트 프롬프트 튜닝이 지도 학습 파인튜닝과 거의 동등하다는 수학적 증명

4. **광범위한 실증 검증**: 
   - 158개 분류 데이터셋 (UCR 128 + UEA 30)
   - 27개 예측 데이터셋 (장단기 + 몇샷 + 제로샷)
   - 8개 LLM 모델 (BERT, GPT-2, ChatGLM, LLaMA-2)
   - 대다수에서 SOTA 또는 그에 상응하는 성능

***

## 2. 해결하는 문제 및 제안 방법

### 2.1 문제 정의

저자들은 세 가지 관점에서 TS-for-LLM 접근의 필요성을 정당화합니다:

**데이터 관점**
- 시계열 데이터의 규모 제약: 최대 10GB (NLP의 수 TB, CV의 수십 TB 대비)
- 전문 분야의 특성상 수집이 어려움
- 어노테이션 비용 높음

**모델 관점**
- 시계열의 도메인 간 큰 차이 (의료 TS ≠ 산업 TS ≠ 기후 TS)
- 각 도메인별 특화 모델 필요 → 범용성 부족
- LLM-for-TS는 각 도메인마다 새로운 모델 개발 필요

**사용성 관점**
- LLM의 언어 능력 유지 중요
- 접근성과 사용 편의성

### 2.2 기술적 문제

**1. 다변량 시계열의 의존성 손실**

단순히 다변량 시계열을 여러 유니변량 시계열로 분리하여 입력하면:
- 변수 간 의존성 완전 무시
- 입력 순서, 프롬프트 문장에 따라 결과 크게 변동
- LLM이 긴 입력 시퀀스 처리 어려움

**2. 시계열-텍스트 임베딩 공간 갭**

- 기존 대비 학습(CL)은 SVM 같은 간단한 분류기용으로 설계
- 복잡하고 프리트레인된 LLM의 임베딩 공간과는 크기(dimension)와 의미론적 구조가 다름
- 제약 없는 CL은 LLM의 인식 공간과 크게 이탈 가능

**3. 텍스트 정렬의 어려움**

- 시계열은 이미지처럼 명확한 텍스트 설명 부재
- ECG 같은 특수 분야만 부분적 텍스트 정보 존재
- 대부분의 시계열 데이터는 annotation bottleneck 심각

### 2.3 제안 방법: TEST 프레임워크

TEST는 두 개의 핵심 단계로 구성됩니다:

#### **단계 1: 시계열 토큰 증강 및 인코더 학습**

**정의 (Definition 1): 시계열의 토큰 임베딩**

다변량 시계열 $x = \{x^d_t\}^{T,D}_{t=1,d=1}$를 슬라이딩 윈도우로 K개의 비중첩 부분수열로 분할:

$$s = \{s_k\}^K_{k=1}, \quad s_k = x_{t_i:t_j}, \quad 1 \leq t_i < t_j \leq T$$

임베딩 함수 $f_e$를 통해 M차원 표현 공간으로 매핑:

$$e = \{e_k\}^K_{k=1} = f_e(s) = f_e(f_s(x))$$

**증강 전략**

- **약한 증강** ($T_{weak}$): Jitter-scale (신호에 무작위 변동 추가, 크기 확대)
- **강한 증강** ($T_{strong}$): Permutation-jitter (무작위 분할 및 셔플)

**자기인코더 손실** (표현성 보장):

$$L_{ae} = \frac{1}{N}\sum^N_{i=1} sim(s, f_d(e))$$

#### **단계 2: 인스턴스-피처 대비 학습**

**인스턴스 레벨 대비 (Instance-wise Contrast)**

각 인스턴스를 독립적으로 취급, 같은 인스턴스의 증강 뷰를 양성 쌍으로, 다른 인스턴스를 음성으로 사용:

$$L_{ins} = -\log \frac{\exp(\sigma(e, e^+))}{\exp(\sigma(e, e^+)) + \sum^B_{i=1} \exp(\sigma(e, e^-_i))}$$

여기서:
$$\sigma(e, e^{+/-}) = \frac{\text{sim}(f_p(e), f_p(e^{+/-}))}{\tau}$$

- $f_p$: 프로젝션 헤드 (1층 MLP)
- $\text{sim}$: 코사인 유사도
- $\tau$: 인스턴스 레벨 온도 파라미터
- B: 미니배치 크기

**피처 레벨 대비 (Feature-wise Contrast)** - 새로운 기여

인스턴스 간의 독립성을 깨고, 피처(변수) 간 의미 정보 활용:

미니배치의 임베딩으로 만든 특성 행렬 $m \in \mathbb{R}^{B \times M}$ (B: 배치 크기, M: 차원)에서:
- 행(row): 인스턴스 임베딩
- 열(column): 피처 표현 (변수 간 유사도)

기존의 단순 정렬-차이 대비:

$$L_{fea} = -\sum^M_{i=1} \left(\sigma(m_i, m^+_i) - \sigma(m_i, m^-_i)\right)$$

개선된 피처 카테고리 균일성:

$$L_{fea} = -\sum^M_{i=1} \log \frac{\exp(\sigma(m_i, m^+_i))}{\sum^M_{j=1}[\exp(\sigma(m_i, m^+_j)) + \exp(\sigma(m_i, m^-_j))]}$$

**의의**: 피처 간 차이 보존 → 표현 공간의 축소 방지 → 이후 텍스트 프로토타입 정렬의 기초 제공

#### **단계 3: 텍스트 프로토타입 정렬 (Text-Prototype-Aligned Contrast)**

**핵심 관찰**: LLM의 토큰 임베딩 공간은 이산(discrete)이지만, 시계열 임베딩 공간은 연속(continuous). 고차원 공간에서는 대부분의 벡터가 서로 직교 → 프로토타입의 종류보다 개수가 중요.

P개의 대표적 텍스트 임베딩(프로토타입) $t_{p_i}$를 선택하여 시계열 임베딩을 정렬:

$$L_{text} = -\sum^P_{i=1} \left[\underbrace{\text{sim}(t_{p_i}, e)}_{\text{Text alignment}} - \underbrace{L_{fea}(e \cdot t_p, e^+ \cdot t_p, e^- \cdot t_p)}_{\text{Text contrast}}\right]$$

**컴포넌트**:
1. **텍스트 정렬항** ($\text{sim}(t_{p_i}, e)$): 두 공간의 범위를 대략 동일하게 유지
2. **텍스트 대비항** ($L_{fea}(e \cdot t_p, ...)$): 프로토타입을 좌표축처럼 사용하여 시계열 임베딩 매핑

**프로토타입 선택 방법**: 텍스트 임베딩 공간의 K-means 클러스터링으로 P개의 대표 점 선택

**해석**: "TS → 패턴 → 텍스트"의 경로로 LLM의 패턴 인식 능력 활성화. 의미론적 이해는 불필요.

#### **단계 4: 학습 가능한 소프트 프롬프트**

TS 임베딩이 생성되더라도, LLM은 여전히 TS 작업 방법을 모름. 소프트 프롬프트(soft prompt)로 LLM 지도:

$$L_{promp} = L_{reg/cls}(\text{concat}(p_e, e))$$

- $p_e$: 학습 가능한 소프트 프롬프트 (태스크별 임베딩)
- $e$: TS 임베딩
- $L_{reg/cls}$: 회귀 또는 분류 손실

**이론적 정당화** (Equation 5):

조건부 생성 태스크에서, 자동회귀 LLM $p_\phi(y|x)$의 파인튜닝:

$$\max_\phi p_\phi(y'|x) = \max_\phi \sum_{i \in Y_{idx}} \log p_\phi(z'_i | h_{<i})$$

여기서 soft prompt 튜닝 시 과거 활성화 $h_i$의 변환:

$$h_i = \begin{cases} p^e_\theta[i, :], & \text{if } i \in p_{e_{idx}} \\ \text{LM}_\phi(z_i, h_i), & \text{otherwise} \end{cases}$$

Taylor 전개를 통해:

$$\sum_{i \in Y_{idx}} \log p_\phi(z_i | h_{ < i}) \cdot \sum_{i \in p_{e_{idx}}} \log p_\Delta(\delta z_i | h_{ < i})$$

→ **프롬프트 튜닝이 지도 파인튜닝과 거의 동등**

또한 Equation 5는 TS 임베딩 공간이 텍스트 임베딩 공간을 충분히 커버해야 함을 시사.

#### **통합 손실 함수 및 훈련**

**1단계: 인코더 학습** (Algorithm 1, epochs 동안)

$$\theta_{f_e} \leftarrow \theta_{f_e} - \eta \nabla_{\theta_{f_e}} (L_{ins} + L_{text})$$
$$\theta_{f_d} \leftarrow \theta_{f_d} - \eta \nabla_{\theta_{f_d}} L_{ae} \quad \text{(선택)}$$
$$\theta_{f_p} \leftarrow \theta_{f_p} - \eta \nabla_{\theta_{f_p}} L_{ins}$$

**2단계: 프롬프트 학습** (epochs 동안)

$$p_e \leftarrow p_e - \eta \nabla_{\theta_{p_e}} L_{promp}$$
$$\theta_{f_d} \leftarrow \theta_{f_d} - \eta' \nabla_{\theta_{f_d}} L_{reg} \quad \text{(선택)}$$
$$\theta_{f_c} \leftarrow \theta_{f_c} - \eta \nabla_{\theta_{f_c}} L_{cls} \quad \text{(선택)}$$

***

## 3. 모델 구조

### 3.1 인코더 아키텍처

**Causal Temporal Convolutional Network (TCN)**

목표: 시계열 정보 추출, 시간-메모리 효율성, 가변 길이 입력 지원

구성:
- **10개 레이어** 컨볼루션 블록
- **각 블록**: GELU → DilatedConv → BatchNorm → GELU → DilatedConv (skip connection)
- **Dilation**: 레이어 $i$에서 $2^i$로 지수적 증가 (receptive field 확대)
- **중간 채널**: 40
- **최종 채널**: LLM 임베딩 차원과 동일 (768~4096)

**설계 선택의 근거**:
1. Causal convolution: 미래 정보 누수 방지
2. Dilated convolution: 긴 시간 의존성 포착
3. Skip connection: 깊은 네트워크의 그래디언트 흐름 개선
4. 채널 일치: 임베딩 공간 정렬 용이

### 3.2 LLM 백본 모델

| 모델 | 크기 | 임베딩 차원 | 아키텍처 |
|------|------|-----------|---------|
| BERT | 110M, 335M | 768, 1024 | Bidirectional Transformer |
| GPT-2 | 117M, 345M, 774M | 768, 1024, 1280 | Autoregressive Transformer |
| ChatGLM | 6B | 4096 | Bidirectional + Autoregressive |
| LLaMA-2 | 7B, 13B | 4096 | Autoregressive Transformer |

**선택 기준**:
- 다양한 크기: 스케일 효과 측정
- 양방향(BERT) vs 자기회귀(GPT-2, LLaMA): 아키텍처 영향 분석
- 공개 모델: 재현성 및 접근성

### 3.3 파이프라인

```
시계열 입력 x
    ↓
[토큰화] → 부분수열 s
    ↓
[인코더 (TCN)] → TS 임베딩 e
    ↓
[대비 학습 (3단계)]
  - L_ins: 인스턴스 레벨
  - L_fea: 피처 레벨
  - L_text: 텍스트 프로토타입
    ↓
[소프트 프롬프트] + e
    ↓
[동결된 LLM]
    ↓
[분류/회귀 헤드]
    ↓
예측 y
```

***

## 4. 성능 향상 및 일반화 능력

### 4.1 분류 작업 (Classification)

**유니변량 시계열 분류 (UCR Archive, 128개 데이터셋)**

- **원본 LLM**: ~50% 정확도 (무작위 추측 수준)
- **TEST 적용 후**: 
  - GPT2-774M: ≥68% 정확도 (18% 향상)
  - 모델 크기 ~300M에서 기준 모델(TCN, LSTM) 초과
  - 모델 크기 ~700M에서 SOTA 트랜스포머(TimesNet) 초과

**다변량 시계열 분류 (UEA Archive, 30개 데이터셋)**

- **원본 LLM**: ~20% 정확도 (무작위 추측 수준)
- **TEST 적용 후**:
  - GPT2-774M: ≥45% 정확도 (25% 향상)
  - 유니변량보다 더 큰 향상 → 다변량 의존성 포착 성공

**Ablation Study** (모델 크기 774M):

1. **텍스트 프로토타입 선택 영향**:
   - (Value, Shape, Frequency): 기준 성능
   - 3개 클러스터 센터: ↑ 성능
   - 10개 클러스터 센터: 다양성 증가, 더 나은 임베딩 공간 커버

2. **프롬프트 설계 영향**:
   - 소프트 vs 하드 프롬프트: ≥10% 차이
   - 초기화: 작업 설명 초기화 > 무작위 초기화 (수렴 속도)
   - 길이: 길이 10에서 최적 (1B 모델 기준)

### 4.2 예측 작업 (Forecasting)

**장기 예측 (ETT, Weather, Electricity, Traffic, ILI)**

- **비교 모델**: TimesNet, DLinear, Informer (SOTA), TCN, LSTM

| 데이터셋 | TEST | TimesNet | DLinear | Informer |
|---------|------|----------|---------|----------|
| ETTh2 (avg) | 0.331 | 0.414 | 0.559 | 0.437 |
| Electricity (avg) | 0.162 | 0.192 | 0.212 | 0.214 |
| Traffic (avg) | 0.430 | 0.620 | 0.625 | 0.610 |
| Weather (avg) | 0.229 | 0.236 | 0.265 | 0.309 |

**성능 평가**:
- TEST는 TimesNet과 비등하거나 우수
- 특히 Weather에서 강력 (0.229 vs 0.236 DLinear)
- 장기 예측 능력 입증

**단기 예측 (TSER Archive, 19개 데이터셋)**

- SOTA 기준 비교 가능 성능

### 4.3 일반화 성능

#### 크로스-도메인 일반화

**통합 예측 실험** (Figure 3g):
- 19개 TSER 데이터셋을 하나의 대규모 데이터셋으로 병합
- 일반화 손실 최소화 측정

**결과**:
- LLM 기반 모델(TEST, GPT4TS) > 기존 전문 모델
- **상대 향상**: ~15-20% 
- **해석**: LLM의 프리트레인이 다양한 패턴 학습 → 도메인 간 전이 용이

#### 몇샷(Few-shot) 학습

**설정**: 10% 학습 데이터로만 훈련 (90% 제외)

| 데이터셋 | TEST | GPT4TS | DLinear | PatchTST |
|---------|------|--------|---------|----------|
| Weather (평균 MSE) | 0.243 | 0.238 | 0.241 | 0.242 |
| ETTh1 (평균 MSE) | 0.479 | 0.590 | 0.691 | 0.633 |

**성능**:
- TEST: 평균 MSE 23.5% 감소 (vs SOTA 기준)
- LLM의 프리트레인 지식이 데이터 부족 상황에서 강력 역할
- **통계적 의의**: 소규모 데이터셋도 효과적

### 4.4 표현 학습

**자기지도 표현 평가**:

TEST의 인코더가 생성한 표현을 SVM 분류기로 평가 (UCR 128개 데이터셋):

| 방법 | 평균 정확도 | 상태 |
|------|-----------|------|
| TEST (인코더) | ~0.81 | SOTA 대비 우수 |
| TEST (LLM 통과 후) | ~0.85 | SOTA 초과 |
| TS2Vec | ~0.80 | SOTA CL 방법 |
| T-Loss | ~0.75 | 기본 CL |

**해석**:
- 인코더 단계: SOTA 수준의 표현 학습
- LLM 단계: 임베딩이 더욱 판별적(discriminative) → LLM이 작용 입증

**텍스트 매칭 사례** (Figure 4):

TS 토큰을 LLM의 단어 임베딩 공간에서 최근접 단어로 매핑:

```
예제:
상향 추세 → "active", "finally", "limit"
하향 추세 → "silent", "absent"
안정적 → "important", "change"
```

**발견**:
- 대부분 감정 관련 형용사(sentiment adjectives)
- **해석**: 모델이 분류를 감정 분류 문제로 "치환" (shortcut)
- TS 패턴을 "Shapelet"처럼 텍스트로 표현 가능

***

## 5. 모델의 한계

### 5.1 명시적 한계

#### 1. 프롬프트 설계의 민감성

**문제**: 소프트 프롬프트의 길이, 초기화, 유형에 따라 성능 편차 크다.

- 소프트 vs 하드 프롬프트: ≥10% 성능 차이
- 초기화: 무작위 vs 작업 설명 기반 (수렴 속도에만 영향)
- 길이: 1-20의 범위에서 변수별로 최적점 다름

**영향**: 하이퍼파라미터 튜닝의 추가 비용 증가

#### 2. 텍스트 프로토타입 선택의 불확실성

**문제**: 프로토타입의 종류(Value/Shape/Frequency vs 클러스터 센터) 및 개수(3 vs 10)에 따라 성능 변동.

**근거**: "프로토타입의 개수가 중요하다"는 주장이지만, 선택 방법의 이론적 근거 부족.

**해결**: 논문에서 직접적 지침 제시 부재 → 실제 적용 시 검색 필요

#### 3. 모델 크기 의존성

**패턴**:
- 작은 모델(117M): TEST 효과 제한적
- 중간 모델(300-350M): 기준 모델 초과 시작
- 큰 모델(700M+): SOTA 트랜스포머 초과

**원인 분석 불충분**:
- 추가 파라미터의 단순 효과 vs 프리트레인 데이터셋 효과 분리 안 됨
- "더 많은 데이터가 도움이 될 것"이라는 추측만 제시

**영향**: 소규모 LLM 적용 가능성 제한

#### 4. 도메인 이해의 부재

**철학적 문제**: TS와 텍스트의 정렬이 인간 감각 수준에서는 무의미.

- "상향 추세" → "active" (형용사): 의미론적 연결 불명확
- 모델이 이해하는 "패턴"과 인간의 해석 사이 갭

**해결 방향**: "LLM은 패턴 머신"이라는 비유로 정당화하지만, 근본적 한계 유지

### 5.2 암묵적 한계

#### 1. 계산 효율성 분석 부재

**문제**:
- 3단계 손실 함수의 계산 복잡도 미제시
- LLM 인퍼런스 시간 vs SOTA 모델 비교 없음
- 소프트 프롬프트 최적화의 수렴 속도 분석 없음

**영향**: 실제 배포 시 계산 비용-성능 트레이드오프 판단 어려움

#### 2. 데이터셋 규모의 모순

**문제**: 
- 논문에서 "시계열 데이터가 10GB 이하"라고 주장
- 실험에 사용된 가장 큰 데이터셋: Traffic (17,544 시간 × 862 변수) ≈ 15MB
- **실제로는 소규모 데이터에서만 검증**

**영향**: 대규모 시계열(예: 고주파 센서 데이터, 위성 이미지) 적용 가능성 불명확

#### 3. 통계적 신뢰도

**문제**:
- 실험 반복 횟수: 최대 3회
- 신뢰 구간 미제시
- 많은 비교 대상(5종류 × 12개 베이스라인) → 다중 비교 보정 부재

**영향**: 성능 향상의 통계적 유의성 검증 불충분

#### 4. 모달리티 정렬 성능 평가 부재

**문제**:
- 텍스트 프로토타입 정렬이 실제로 얼마나 효과적인지 정량 평가 없음
- 인스턴스-피처-텍스트 대비 각 단계의 기여도 분석 부재

**해결 필요**: 예를 들어, 각 손실 항의 ablation 실험 확대

***

## 6. 2020년 이후 관련 최신 연구 비교 분석

### 6.1 TS+LLM 패러다임 비교

| 방법 | 제안자 | 연도 | 카테고리 | 핵심 전략 | 주요 성과 | 한계 |
|------|--------|------|---------|---------|---------|------|
| **Time-LLM** | Jin et al. | 2024 | 리프로그래밍 | 텍스트 프로토타입으로 TS 표현 | 제로샷에서 우수, 일반 예측 SOTA | 파인튜닝 필요, 대규모 데이터 의존 |
| **GPT4TS** | Zhou et al. | 2023 | 감독 파인튜닝 (SFT) | LLM 직접 파인튜닝 | 높은 정확도, 엔드-to-엔드 | 언어 능력 손실, 도메인별 파인튜닝 필요 |
| **TEST** | Sun et al. | 2024 | 외부 인코더 | 3단계 대비 학습 + 소프트 프롬프트 | 매개변수 효율적, 다중 능력, 일반화 우수 | 프롬프트 민감성, 프로토타입 선택 불확실 |
| **TimeCMA** | Liang et al. | 2024 | 크로스모달 정렬 | TS vs LLM 임베딩 이중 인코딩 | 다변량 의존성 학습, 계산 효율적 | 텍스트 정렬 복잡성 높음 |
| **TimeRAG** | Park et al. | 2024 | RAG 기반 | 역사적 수열 검색 + 프롬프트 | 전이 가능성 향상, 패턴 유사도 활용 | 지식베이스 구축 필요, 검색 오버헤드 |
| **PromptCast** | Xue & Salim | 2023 | 프롬프트 기반 | 자연어 프롬프트로 TS 설명 | 프롬프트 엔지니어링 활용 | 프롬프트 품질 의존, 수동 작업 |
| **IDDLLM** | 2025년 | 2025 | 정수-소수 분해 | TS를 정수-소수 부분 분리 + 크로스 어텐션 | 46개 설정 중 34위 1위, 9위 2위 | 분해 메커니즘 복잡성 |
| **LLM-PS** | 2025년 | 2025 | 시간 패턴 + 의미론 | 시간 패턴과 연속 의미 추출 | 단기/장기/몇샷/제로샷 모두 SOTA | 의미론 추출 방법 복잡 |
| **LoFT-LLM** | 2025년 | 2025 | 저주파 중심 | 저주파 성분과 LLM 결합 | 제한된 데이터에서 강력 | 고주파 정보 손실 가능 |

### 6.2 시계열 표현 학습 방법 비교

#### 자기지도 대비 학습 (Self-Supervised Contrastive Learning)

| 방법 | 발표 | 기법 | 특징 | 성능 |
|------|------|------|------|------|
| **SimCLR-TS** | 2021 | 인스턴스 레벨 대비 | 산업용 TS, 데이터 증강 | 기준 수준 |
| **TS-TCC** | 2021 | 시간-맥락 대비 | 시간 레벨과 맥락 결합 | 기준 향상 |
| **TS2Vec** | 2022 | 인스턴스 판별 | 유니버설 표현, 데이터셋 간 전이 | SOTA (2022) |
| **CoST** | 2022 | 계절-추세 분해 | 분해 성분별 대비 | 예측 우수 |
| **MHCCL** | 2023 | 계층적 클러스터 대비 | 다변량 의존성 명시 | 다변량 특화 |
| **TEST** | 2024 | 인스턴스+피처+텍스트 | 3단계 정렬, LLM 연동 | 다중 태스크 우수 |
| **CoGenT** | 2025 | 대비+생성 하이브리드 | SimCLR + MAE 결합 | F1 59.2% 향상 (vs SimCLR) |
| **TimesBERT** | 2025 | BERT 스타일 사전학습 | 기초 모델, 범용 표현 | 통용적 능력 |

#### 주요 발견:

1. **피처 레벨 대비의 중요성** (TEST 기여):
   - 기존: 인스턴스 간 대비만 고려
   - TEST: 피처(변수) 간 대비 추가 → 다변량 의존성 포착 개선

2. **분해 기반 방법의 한계**:
   - CoST: 계절-추세 분해 가정이 모든 TS에 적용 불가
   - TEST: 분해 가정 없이 더 일반적

3. **LLM 연동의 새로운 방향**:
   - TEST: 외부 인코더 + LLM 결합 → 매개변수 효율적
   - TimesBERT: LLM 자체를 TS 기초 모델로 → 엔드-to-엔드

### 6.3 LLM 기반 예측의 도전과 개선

#### LLM 기반 예측의 근본 문제

**발견** (Gruver et al. 2024, "Revisiting LLMs as Zero-Shot Forecasters"):
- LLM은 마지막 값 반복(last value repetition) 경향
- 노이즈가 많은 실데이터에서 성능 저하
- 단순 선형 모델이 더 효율적일 수 있음

**TEST의 해결책**:
- 노이즈 억제 메커니즘 미제시
- 대신 소프트 프롬프트를 통한 태스크별 조정

#### 최신 개선 방향 (2025)

1. **텍스트 임베딩 직접 활용** (LETS-C):
   - LLM 파인튜닝 대신 사전학습된 텍스트 임베딩 모델 사용
   - 14.5% 매개변수로 SOTA 달성
   - **시사**: TS-텍스트 정렬의 핵심은 LLM 용량이 아닐 수도

2. **시간 패턴과 의미론 결합** (LLM-PS):
   - 시간 패턴: 이동평균, 자기상관
   - 의미론: 시간-텍스트 모듈로 연속 시간 구간의 의미 추출
   - 결과: 단기/장기/몇샷/제로샷 모두 SOTA

3. **저주파 중심 접근** (LoFT-LLM):
   - 제한된 데이터에서는 저주파 성분에 집중
   - 고주파 노이즈 제거로 LLM의 패턴 인식 개선
   - 적용: 금융, 에너지 등 고주파 노이즈 많은 분야

4. **크로스모달 정렬** (TimeCMA):
   - 이중 경로: TS 인코더 (약한 임베딩) + LLM 기반 (강한 임베딩)
   - 두 경로 임베딩을 상호 학습
   - 개선: 계산 효율성, 다변량 의존성

### 6.4 TEST의 상대적 위치

#### 경쟁 우위:

1. **일반화 성능**: 크로스도메인 실험에서 강력 (Figure 3g)
   - TS+LLM 방법 중 최우수
   - 이유: 임베딩 공간을 LLM 텍스트 공간과 정렬 → 다양한 데이터에 대응

2. **매개변수 효율성**: 
   - LLM 동결 상태 → 추가 학습 매개변수 최소
   - Soft prompt는 수천 개, 인코더는 ~1M 정도
   - 비교: GPT4TS (전체 파인튜닝) vs TEST

3. **다중 능력**: 
   - 분류, 예측, 표현 학습 모두 우수
   - 대부분 방법은 예측 또는 분류 특화

#### 제약:

1. **이론적 기초**: 
   - 텍스트 프로토타입 정렬의 이론적 근거 약함
   - "고차원에서 벡터 거의 직교" 주장이 핵심인데, 프로토타입 선택 방법 미상세

2. **실증 범위**:
   - 대규모 시계열 데이터 테스트 없음 (최대 데이터셋 ~200MB)
   - 고주파 센서 데이터(예: 비디오, 음성) 미테스트

3. **후속 연구와의 비교**:
   - IDDLLM (2025)이 더 나은 성과 보고 (34/46 1위)
   - 하지만 TEST는 간단성과 투명성 유지

***

## 7. 앞으로의 연구에 미치는 영향 및 고려사항

### 7.1 연구 분야에 미친 영향

#### 1. TS-for-LLM 패러다임의 정당화

**기여**: 
- LLM을 TS용으로 수정하지 않고도 성능 달성 가능 증명
- "동결 LLM + 외부 인코더" 패러다임의 타당성 입증
- 이후 LETS-C, TimeCMA 등의 연구에 영감

**영향 범위**:
- 학계: TS+LLM의 양 방향 탐색 활성화
- 산업: 제한된 컴퓨팅 리소스에서 LLM 활용 가능성 제시

#### 2. 피처 레벨 대비 학습의 도입

**새로운 개념**: 
- 기존 CL은 인스턴스 또는 시간 레벨에만 집중
- TEST의 피처 레벨 대비 → 변수 간 의존성 명시적 학습

**파급**:
- 다변량 TS 분석에 새로운 차원 추가
- MHCCL, 기타 다변량 특화 방법의 선행 연구로 작용

#### 3. LLM을 "패턴 머신"으로 해석

**철학적 기여**:
- LLM은 "이해"하는 모델이 아니라 "패턴을 인식"하는 모델
- TS-텍스트 간 의미론적 정렬이 필요 없을 수 있음

**파급**:
- 다중 모달리티 정렬 연구의 방향성 제시
- 사람이 이해할 수 없는 정렬도 LLM은 효과적으로 활용

#### 4. 이론과 실제의 갭 제시

**발견**: 프로토타입 개수 > 종류 (고차원 직교성)

**영향**: 
- 차원이 높을수록 효과적일 수 있다는 가설 제기
- 후속 연구: 최적 프로토타입 개수, 선택 기준 탐구

### 7.2 앞으로의 연구 방향

#### 1. 프롬프트 설계의 자동화

**문제**: 프롬프트 길이, 초기화, 유형에 따라 성능 크게 변동

**제안**:
- AutoML 기법으로 프롬프트 최적화
- Reinforcement Learning으로 프롬프트 학습
- 예: RL로 소프트 프롬프트 토큰 최적화

#### 2. 프로토타입 선택의 이론화

**문제**: 텍스트 프로토타입 선택 원리 불명확

**제안**:
- 최적 프로토타입 개수의 이론적 기준 도출 (차원 함수로)
- 선택 알고리즘: K-means 대신 더 정교한 방법
- 도메인별 최적 프로토타입 특성 분석

#### 3. 대규모 시계열 데이터 검증

**현재**: 최대 200MB 규모 데이터
**필요**: 
- 고주파 센서 데이터 (Hz~MHz)
- 광시계열 데이터 (위성, 기상)
- 스트리밍 TS (온라인 학습)

**해결 방안**:
- 메모리 효율적 인코더 설계
- 미니배치 기반 적응적 학습

#### 4. LLM 모델 크기 의존성 분리

**현재**: 큰 모델일수록 우수하지만, 원인 미분석

**필요 연구**:
- 모델 크기 vs 사전학습 데이터 효과 분리
- 소규모 LLM에서의 TEST 효과 개선
- 지식 증류(knowledge distillation)로 경량화

#### 5. 동적 텍스트 프로토타입

**아이디어**: 정적 프로토타입 → 동적 프로토타입
- 태스크별로 프로토타입 적응
- TS의 특성에 따라 프로토타입 조정
- 학습 과정에서 프로토타입 업데이트

#### 6. 해석 가능성 강화

**현재 한계**: "TS 토큰이 어떤 형용사와 대응"이라는 현상만 제시

**필요**:
- Attention visualization으로 어떤 TS 특성이 어떤 텍스트와 대응되는지 분석
- Concept activation vectors로 해석 가능한 벡터 공간 구축
- 사람과 모델의 패턴 인식 비교

#### 7. 다중 LLM 앙상블

**가능성**: 서로 다른 LLM 백본을 결합
- BERT(양방향)의 분류 능력 + GPT-2(자기회귀)의 예측 능력
- 앙상블로 강건성 증대

#### 8. 도메인별 특화 버전

**현재**: 범용 TEST

**방향**:
- 의료 TS: 도메인 특화 용어(심박, 호흡) 프로토타입
- 금융 TS: 금융 용어 프로토타입
- 기후 TS: 기상 용어 프로토타입

### 7.3 실제 적용 시 고려사항

#### 1. 프로토타입 선택

**실무 가이드**:
```
Step 1: 도메인 분석
  - 시계열의 특성 파악 (값의 크기, 변동 범위, 추세/계절성)

Step 2: 프로토타입 후보 생성
  Option A: 도메인 용어 (Value, Shape, Frequency, Volatility, ...)
  Option B: 클러스터 센터 (K-means on LLM embeddings)
  
Step 3: 교차검증으로 최적 선택
  - 검증셋에서 성능 비교
  - 3~10개 범위에서 그리드 서치

Step 4: 최종 선택
```

#### 2. 계산 비용 고려

**리소스 요구**:
- 인코더 훈련: GPU 메모리 적당 (1단계, TCN 기반)
- LLM 인퍼런스: GPU 메모리 높음 (8B 모델 기준 16GB+)
- 프롬프트 최적화: 상대적 저비용

**최적화 전략**:
- 양자화(quantization)로 LLM 메모리 축소 (int8, int4)
- 특정 토큰만 계산 (token pruning)

#### 3. 데이터 부족 상황

**TEST의 장점**:
- 10% 데이터에서도 유효 (few-shot 실험)
- 프리트레인된 LLM의 지식 활용

**제약**:
- 완전히 새로운 도메인에서는 여전히 부족
- 해결: 도메인별 사전학습 또는 전이 학습

#### 4. 배포 전략

**개발**:
```
1. 오프라인 인코더 훈련 (한 번만)
2. 온라인 프롬프트 튜닝 (빠름)
3. LLM 인퍼런스 (배치 처리로 최적화)
```

**모니터링**:
- 프롬프트 성능 드리프트 추적
- 재교육 필요성 판단 기준 수립

***

## 결론

TEST는 시계열을 LLM의 언어 임베딩 공간에 정렬하는 우아한 방법론을 제시하며, 동결된 LLM만으로도 분류, 예측, 표현 학습에서 SOTA 성능을 달성합니다. 특히 **피처 레벨 대비 학습**이라는 새로운 개념을 도입하여 다변량 시계열의 변수 간 의존성을 명시적으로 학습하고, **텍스트 프로토타입 정렬**로 TS와 텍스트 공간을 연결합니다.

주요 강점은 매개변수 효율성, 크로스도메인 일반화, 몇샷 학습 성능이며, 제약은 프롬프트 민감성과 프로토타입 선택의 불확실성입니다. 2025년까지의 후속 연구(IDDLLM, LLM-PS, LETS-C, TimesBERT)는 TEST의 기초 위에서 점진적 개선을 이루고 있으며, 향후 연구는 프롬프트 자동화, 프로토타입 이론화, 대규모 데이터 검증, 해석 가능성 강화에 집중할 것으로 예상됩니다.

***

## References

 Sun, C., Li, H., Li, Y., & Hong, S. (2024). TEST: Text Prototype Aligned Embedding to Activate LLM's Ability for Time Series. *ICLR 2024*, arXiv:2308.08241v2. [ppl-ai-file-upload.s3.amazonaws](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/dc78f7ab-053a-4602-84ec-c80c10bfb2d0/2308.08241v2.pdf)

 Jin, M., Wang, S., Ma, L., et al. (2024). Time-LLM: Time Series Forecasting by Reprogramming Language Models. *ICLR 2024*. [arxiv](https://arxiv.org/abs/2506.11050)

 Zhou, H., Zhang, S., Peng, J., et al. (2023). GPT4TS: Towards Efficient and Accurate Time Series Forecasting with Large Language Models. *arXiv:2308.08469*. [nature](https://www.nature.com/articles/s41598-025-06581-x)

 Liang, C., Li, C., Liu, Y., et al. (2024). TimeCMA: Towards LLM-Empowered Multivariate Time Series Forecasting via Cross-Modality Alignment. *AAAI 2024*. [spiedigitallibrary](https://www.spiedigitallibrary.org/conference-proceedings-of-spie/13681/3073528/SST-LLM--time-series-forecasting-based-on-large-language/10.1117/12.3073528.full)

 Yue, Z., Wang, Y., Duan, J., et al. (2022). TS2Vec: Towards Universal Representation of Time Series. *AAAI 2022*. [ieeexplore.ieee](https://ieeexplore.ieee.org/document/10889933/)

 Woo, G., Liu, C., Sahoo, D., et al. (2022). CoST: Contrastive Learning of Disentangled Seasonal-Trend Representations for Time Series Forecasting. *ICLR 2022*. [ojs.aaai](https://ojs.aaai.org/index.php/AAAI/article/view/34067)
