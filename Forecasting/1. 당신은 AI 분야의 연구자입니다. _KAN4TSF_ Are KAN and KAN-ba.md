<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" style="height:64px;margin-right:32px"/>

# 1. 당신은 AI 분야의 연구자입니다. "KAN4TSF: Are KAN and KAN-based models Effective for Time Series Forecasting?"의 핵심 주장과 주요 기여를 간결하게 요약하세요.

2. 이 논문이 "해결하고자 하는 문제, 제안하는 방법(수식 포함), 모델 구조, 성능 향상 및 한계"를 중심으로 자세하게 설명하세요.
3.특히 "모델의 일반화 성능 향상 가능성"과 관련된 내용을 중점적으로 다뤄 주세요.
4.요약 후에는 "해당 논문이 앞으로의 연구에 미치는 영향과 앞으로 연구 시 고려할 점"도 자세히 기술해 주세요.
“2020년 이후 관련 최신 연구 비교 분석”
수식을 LaTeX 코드로 답변 형식을 맞춰주고, LaTeX 렌더링을 위해 마크다운에 달러 기호를 사용해 주세요.

이제 논문 내용을 충분히 파악했습니다. 상세하고 구조화된 분석 답변을 작성하겠습니다.

***

# KAN4TSF 논문 심층 분석: KAN 기반 시계열 예측의 가능성과 한계

## 1. 핵심 주장 및 주요 기여 요약

**KAN4TSF**는 Kolmogorov-Arnold Network(KAN)를 시계열 예측(TSF)에 처음으로 체계적으로 도입하여, KAN 기반 모델이 성능·통합성·효율·해석 가능성 측면에서 실효성이 있음을 실험적으로 검증한 논문입니다.[^1_1]

핵심 주장과 기여는 다음과 같습니다.[^1_1]

- **최초의 종합 연구**: KAN이 시계열 예측에 효과적인지를 다각도로(성능, 통합, 속도, 해석성) 분석한 최초의 연구
- **RMoK 모델 제안**: Reversible Mixture of KAN Experts(RMoK) — 단일 레이어 구조로 성능과 해석성을 균형 있게 달성
- **SOTA 달성**: 7개 실세계 데이터셋에서 대부분의 경우 최고 성능 달성
- **메커니즘 해석**: 시계열의 주기성과 KAN 특징 가중치 분포 간의 상관관계를 시각화로 규명

***

## 2. 해결하고자 하는 문제

### 기존 딥러닝 방식의 두 가지 한계

기존 주류 예측 모델들은 **범용 근사 정리(Universal Approximation Theorem, UAT)** 에 기반하는데, UAT는 특정 정확도로 연속 함수를 근사하기 위해 "필요한 네트워크 크기(깊이·너비)"를 보장하지 못합니다. 즉, 근사(approximation)는 가능하지만 표현(representation)의 보장이 없습니다.[^1_1]

두 번째로, 기존 모델들은 예측 메커니즘이 **블랙박스**여서 해석 가능성이 낮고, 의료·법률·금융처럼 오류 허용도가 낮은 분야에서 신뢰성 문제가 있습니다.[^1_1]

### KAN이 이 문제를 해결하는 이유

KAN의 수학적 기반인 **Kolmogorov-Arnold 표현 정리(KART)** 는 다음을 보장합니다.[^1_1]

> 다변량 연속 함수는 유한 개의 단변량 연속 함수의 조합으로 **표현(represent)** 될 수 있다.

이는 UAT와 달리, 네트워크 크기와 입력 형태 간의 명확한 관계를 수립합니다. 또한 학습된 KAN을 심볼릭 함수 집합으로 단순화하는 **가지치기(pruning) 전략**을 통해 해석성을 크게 향상시킵니다.[^1_1]

***

## 3. 제안 방법 및 수식

### 3.1 문제 정의

다변량 시계열 예측은 역사 데이터 $\mathbf{X} = [X_1, \cdots, X_T] \in \mathbb{R}^{T \times C}$ ($T$: 시간 스텝, $C$: 변수 수)가 주어졌을 때, 미래 $P$ 스텝 $\mathbf{Y} = [X_{T+1}, \cdots, X_{T+P}] \in \mathbb{R}^{P \times C}$ 을 예측하는 것입니다.[^1_1]

### 3.2 KAN 레이어 수식

$L$개 레이어의 KAN은 다음과 같이 구성됩니다.[^1_1]

$\text{KAN}(\mathbf{x}) = (\Phi_L \circ \Phi_{L-1} \circ \cdots \circ \Phi_2 \circ \Phi_1)\mathbf{x}$

각 레이어의 $l$번째에서 $j$번째 특성 변환은 다음과 같습니다.[^1_1]

$x_{l,j} = \sum_{i=1}^{n_{l-1}} \phi_{l-1,j,i}(x_{l-1,i}), \quad j = 1, \cdots, n_l$

여기서 각 활성화 함수 $\phi$는 두 부분으로 구성됩니다.[^1_1]

$\phi(x) = w_b \cdot \text{SiLU}(x) + w_s \cdot \text{Spline}(x)$

$\text{Spline}(x) = \sum_i c_i B_i(x)$로, B-spline 함수들의 선형 결합입니다.[^1_1]

### 3.3 MoK(Mixture of KAN Experts) 레이어

$N$개의 KAN 전문가를 가진 MoK 레이어는 다음과 같습니다.[^1_1]

$x_{l+1} = \sum_{i=1}^{N} G(x_l)_i K_i(x_l)$

게이팅 네트워크 $G(\cdot)$는 두 가지 방식으로 구현됩니다.[^1_1]

**Softmax 게이팅 (밀집형):**
$G_{\text{softmax}}(x) = \text{Softmax}(x w_g)$

**Sparse 게이팅 (효율형, 상위 k개만 활성화):**
$G_{\text{sparse}}(x) = \text{Softmax}(\text{KeepTopK}(H(x), k))$
$H(x) = x w_g + \text{Norm}(\text{Softplus}(x w_{\text{noise}}))$

### 3.4 RMoK 전체 구조

RMoK는 `RevIN+ → MoK Layer → RevIN-`의 단순한 단일 레이어 구조입니다.[^1_1]

- **RevIN+**: 분포 이동(distribution shift)에 대응하기 위해 학습 가능한 어파인 변환으로 입력 시계열 정규화
- **MoK Layer**: 변수별로 최적 KAN 전문가를 동적으로 선택하여 예측
- **RevIN-**: 동일한 어파인 파라미터로 예측 결과를 원래 분포 공간으로 역변환


### 3.5 손실 함수

전문가 부하 불균형 방지를 위해 변동 계수(CV)를 활용한 부하 균형 손실을 추가합니다.[^1_1]

$\mathcal{L}_{\text{load-balancing}} = \text{CV}(\text{loads})^2$

$\mathcal{L} = \text{MSE}(Y, \hat{Y}) + w_l \cdot \mathcal{L}_{\text{load-balancing}}$

***

## 4. 모델 구조 심화: 핵심 설계 원칙

| 구성 요소 | 역할 | 설계 의도 |
| :-- | :-- | :-- |
| RevIN (양방향) | 분포 정규화·역정규화 | 시계열의 비정상성(non-stationarity) 대응 [^1_1] |
| 다중 KAN 변형 | Spline, Wavelet, Taylor, Jacobi 등 다양한 전문가 | 분포 다양성에 적응적 대응 [^1_1] |
| Sparse Gating | 상위 $k$개 전문가만 활성화 | 전문가 수 증가 시 효율성 유지 [^1_1] |
| 단일 레이어 구조 | 깊은 스택 대신 단순 구조 | 해석 가능성 최대화 [^1_1] |


***

## 5. 성능 향상 분석

### 5.1 주요 실험 결과

7개 데이터셋 기준, RMoK는 28개 예측 시나리오 중 **31개 지표에서 1위**를 달성했습니다.  특히:[^1_1]

- **변수가 적은 데이터셋**(ETTh1/h2, ETTm1/m2): RMoK-S/B 모두 강세
- **변수가 많은 데이터셋**(ECL 321변수, Traffic 862변수): RMoK-B(8 전문가)가 RMoK-S(4 전문가)를 크게 상회 → **MoE 구조가 대규모 다변량 데이터에 특히 효과적**
- **Traffic 데이터셋**: 복잡한 시공간 상관관계로 PatchTST가 1위, RMoK는 준최적(suboptimal) 달성


### 5.2 KAN vs Linear 비교

같은 MoE 구조에서 KAN 전문가(RMoK-S)는 Linear 전문가(RMoL-S)보다 대부분의 경우 우수한 성능을 보였습니다.  이는 KAN의 **함수 표현 방식이 시계열의 주기성·추세 포착에 더 효율적**임을 시사합니다. 또한 MoE 구조는 KAN과 Linear 모두에서 유효하며, 이는 게이팅 네트워크가 변수를 특정 전문가에 할당하는 메커니즘 자체의 효과임을 보여줍니다.[^1_1]

### 5.3 iTransformer 통합 실험

iTransformer의 어텐션 모듈 내 선형 프로젝션을 MoK 레이어로 교체했을 때, 다양한 KAN 변형 대비 **MoK가 가장 일관된 성능 향상**을 달성했습니다. 특히 순수 KAN(B-spline)을 단독으로 통합하면 오히려 성능이 크게 저하(ETTm1 96에서 MSE 0.341 → 0.689)되었습니다.[^1_1]

***

## 6. 모델의 일반화 성능 향상 가능성

### 6.1 RevIN을 통한 분포 이동 대응

RMoK에서 **RevIN**은 각 변수의 입력 시계열을 학습 가능한 어파인 변환으로 정규화하고, 예측 후 동일 파라미터로 역변환합니다. 이 인스턴스 정규화 방식은 트레이닝-테스트 간의 통계적 분포 차이(distribution shift)를 효과적으로 흡수하여 도메인 일반화를 가능하게 합니다.[^1_1]

### 6.2 MoE 구조의 다분포 적응

시계열은 현실에서 비정상적(non-stationary)이고 변수 간 분포 차이가 크다는 특성이 있습니다. MoK의 핵심 아이디어는 **"특정 spline 함수가 특정 데이터 분포에 더 적합할 수 있다"** 는 가설에서 출발합니다.  게이팅 네트워크가 입력 특징으로부터 변수별 최적 전문가를 동적으로 선택함으로써, 단일 KAN으로는 포착하기 어려운 다양한 분포 패턴에 적응합니다. 이는 Weather, ECL, Traffic처럼 변수가 많고 분포가 다양한 데이터셋에서 RMoK-B가 RMoK-S보다 월등히 성능이 높은 결과로 확인됩니다.[^1_1]

### 6.3 KAN의 주기성 학습과 일반화

시각화 실험에서 Weather 데이터셋의 기온 변수(10분 간격)를 분석한 결과, KAN의 특징 가중치가 **0, 72, 144 시간 스텝 근처에서 세 개의 피크**를 형성함을 발견했습니다.  이는 각각 전날 동일 시점(0), 반주기(72), 인접 시점(144)에 해당하며, 코사인 함수의 영점과 정확히 일치합니다. 이로써 KAN이 도메인 지식 없이도 시계열의 주기 구조를 자동으로 학습함을 보여주며, 이 특성이 다양한 데이터셋에 걸친 일반화 성능의 원천임을 시사합니다.[^1_1]

### 6.4 한계: 일반화를 저해하는 요인

그러나 일반화 측면에서 다음의 한계도 존재합니다.[^1_1]

- **변수 간 상관관계 무시**: RMoK는 채널 독립(channel-independent) 방식으로 동작하여 변수 간 시공간 의존성을 모델링하지 않음. Traffic 데이터셋처럼 복잡한 공간 의존성이 있는 경우 PatchTST 등에 열세
- **Spline 함수 선택의 이론적 근거 부재**: 어떤 KAN 변형이 특정 데이터 분포에 최적인지를 실험 외에 판단할 이론적 지침이 없음
- **단일 레이어 표현력 한계**: 단순성을 위해 단일 레이어를 선택했으나, 복잡한 다단계 시간 패턴을 포착하기에 부족할 수 있음
- **연산 속도**: KAN(B-spline 기반)은 Linear 대비 현저히 느림(Table 5: 학습 5.94 it/s vs DLinear 102.51 it/s). Taylor 기반 KAN은 개선되었으나 여전히 격차 존재[^1_1]

***

## 7. 2020년 이후 관련 연구 비교 분석

| 모델 | 연도 | 핵심 기법 | KAN 관련성 | 특이점 |
| :-- | :-- | :-- | :-- | :-- |
| **Informer** | 2021 | ProbSparse 어텐션, $O(T\log T)$ | 기반 비교 모델 | Transformer 복잡도 혁신 [^1_1] |
| **PatchTST** | 2023 | 패치 기반 Transformer | 주요 베이스라인 | 채널 독립 Transformer [^1_1] |
| **DLinear/RLinear** | 2023 | 단일 선형 레이어 + 정규화 | 직접 비교 대상 | 단순 선형이 Transformer 능가 [^1_1] |
| **iTransformer** | 2024 | 변수-토큰 역전 Transformer | MoK 통합 대상 | MoK 통합 시 성능 향상 [^1_1] |
| **T-KAN / MT-KAN** | 2024 | KAN + 개념 드리프트 감지 | 동시기 KAN 연구 | 기호 회귀로 해석성 강조 [^1_2] |
| **TKAN** | 2024 | KAN + LSTM 결합 (RKAN) | 시계열 특화 KAN | 다단계 예측에 특화 [^1_3] |
| **Time-MoE** | 2024 | 24억 파라미터 MoE 기반 FM | 구조적 유사성 | 대규모 파운데이션 모델 [^1_4] |
| **TimeKAN** | 2025 | KAN 기반 주파수 분해 학습 | 후속 KAN 연구 | 다중 주파수 성분 분리 [^1_5] |
| **HaKAN** | 2026 | Hahn 다항식 기반 KAN, 패치 구조 | 최신 KAN 진화 | 지역·전역 패턴 동시 포착 [^1_6] |
| **MoHETS** | 2025 | 이종 전문가 MoE | MoK와 개념 유사 | 공유 전문가 + 라우팅 전문가 [^1_7] |

특히 **MoLE(Mixture-of-Linear-Experts)** 는 RMoK의 MoE 구조 설계에 영감을 준 연구로, 선형 전문가만으로도 MoE 구조를 통해 시계열의 다양한 주기 패턴에 적응할 수 있음을 보였습니다. RMoK는 여기서 한 발 더 나아가 전문가를 KAN 변형으로 교체함으로써 표현력을 높였습니다.[^1_8]

***

## 8. 향후 연구에 미치는 영향과 고려할 점

### 8.1 향후 연구에 미치는 영향

**KAN4TSF**는 시계열 예측 분야에서 KAN 연구의 **출발점이자 표준 벤치마크**로 기능합니다. 이후 TimeKAN, HaKAN, AR-KAN, P-KAN  등 다수의 후속 연구가 직접적으로 이 논문을 참조하며 KAN을 시계열 예측에 적용했습니다. 또한 **"단일 레이어 + MoE" 패러다임**은 복잡한 다층 구조 없이도 경쟁력 있는 성능이 가능함을 보여줌으로써, 파라미터 효율적인 경량 모델 연구에 방향성을 제시합니다.[^1_6][^1_9][^1_10][^1_5][^1_1]

### 8.2 향후 연구 시 고려할 점

**모델 구조 측면:**

- 채널 의존 모델링(cross-variate attention 등)과 KAN을 결합하여 Traffic처럼 공간 상관관계가 강한 데이터셋에서의 성능 향상 도모
- 단일 레이어의 한계를 극복하기 위한 **다층 RMoK**(Multi-layer MoK) 구조 탐색 (이미 후속 MMK 연구에서 시도됨 )[^1_11]
- 주파수 도메인 정보(FFT, 웨이블릿)와 KAN을 결합하는 하이브리드 아키텍처[^1_12]

**이론 및 수식 측면:**

- 어떤 spline 함수(B-spline, Taylor, Jacobi, Wavelet 등)가 어떤 시계열 분포 유형에 최적인지에 대한 **이론적 분류 기준 수립** 필요
- 시계열 예측에서 KART의 표현 이론이 실제 유한 샘플 일반화 오류 경계(generalization error bound)와 어떻게 연결되는지 분석 필요

**실험 설계 측면:**

- 벤치마크 데이터셋을 ETT·ECL·Traffic·Weather 외 더 다양한 도메인(의료, 금융 고빈도 데이터, 이상 탐지 등)으로 확장하여 일반화 검증
- 비정상 시계열(concept drift가 심한 실시간 데이터)에서의 온라인 학습(continual learning)과 KAN의 결합 가능성 탐구
- 현재 논문이 다루지 않은 **예측 불확실성 정량화**(probabilistic forecasting)에 KAN의 적용. P-KAN  연구처럼 분포 파라미터를 직접 출력하는 방향[^1_9]

**효율성 측면:**

- KAN의 학습 속도 병목(특히 B-spline 기반)을 해소하기 위한 하드웨어 최적화 및 커널 퓨전 연구
- 대규모 파운데이션 모델(Time-MoE처럼 수십억 파라미터) 맥락에서의 KAN 스케일링 법칙 탐구[^1_4]
<span style="display:none">[^1_13][^1_14][^1_15][^1_16][^1_17][^1_18][^1_19][^1_20][^1_21][^1_22][^1_23][^1_24][^1_25][^1_26][^1_27][^1_28][^1_29][^1_30][^1_31][^1_32][^1_33][^1_34][^1_35][^1_36][^1_37][^1_38][^1_39][^1_40][^1_41][^1_42]</span>

<div align="center">⁂</div>

[^1_1]: 2408.11306v1.pdf

[^1_2]: https://arxiv.org/abs/2406.02496

[^1_3]: https://arxiv.org/abs/2405.07344

[^1_4]: https://arxiv.org/html/2409.16040v4

[^1_5]: http://arxiv.org/pdf/2502.06910.pdf

[^1_6]: https://arxiv.org/pdf/2601.18837.pdf

[^1_7]: https://arxiv.org/html/2601.21866v1

[^1_8]: https://proceedings.mlr.press/v238/ni24a.html

[^1_9]: https://arxiv.org/abs/2510.16940

[^1_10]: https://arxiv.org/abs/2509.02967

[^1_11]: http://arxiv.org/pdf/2408.11306.pdf

[^1_12]: https://arxiv.org/html/2506.12696v1

[^1_13]: https://arxiv.org/abs/2511.18613

[^1_14]: https://www.arxiv.org/pdf/2510.16940.pdf

[^1_15]: https://arxiv.org/html/2505.15151v1

[^1_16]: https://arxiv.org/abs/2502.18410

[^1_17]: https://arxiv.org/html/2508.08825v1

[^1_18]: https://arxiv.org/html/2601.10563

[^1_19]: https://arxiv.org/pdf/2502.18410.pdf

[^1_20]: https://arxiv.org/html/2408.07314v1

[^1_21]: https://arxiv.org/abs/2411.00278

[^1_22]: https://pubs.acs.org/doi/10.1021/acs.est.4c11113

[^1_23]: https://link.springer.com/10.1007/s10586-025-05574-9

[^1_24]: https://www.mdpi.com/2227-7390/12/19/3022

[^1_25]: https://ieeexplore.ieee.org/document/11100692/

[^1_26]: https://www.ssrn.com/abstract=4825654

[^1_27]: http://arxiv.org/pdf/2405.08790.pdf

[^1_28]: http://arxiv.org/pdf/2406.17890.pdf

[^1_29]: http://arxiv.org/pdf/2406.02496.pdf

[^1_30]: http://arxiv.org/pdf/2411.00278.pdf

[^1_31]: https://arxiv.org/pdf/2406.02486.pdf

[^1_32]: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5220118

[^1_33]: https://www.datasciencewithmarco.com/blog/kolmogorov-arnold-networks-kans-for-time-series-forecasting

[^1_34]: https://ir.bjut.edu.cn/irpui/item/ir/435535

[^1_35]: https://www.datasciencewithmarco.com/blog/mixture-of-kan-experts-for-high-performance-time-series-forecasting

[^1_36]: https://axi.lims.ac.uk/paper/2406.02496

[^1_37]: https://pmc.ncbi.nlm.nih.gov/articles/PMC12222760/

[^1_38]: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4825654

[^1_39]: https://proceedings.mlr.press/v238/ni24a/ni24a.pdf

[^1_40]: https://dergipark.org.tr/en/download/article-file/5130772

[^1_41]: https://5g-stardust.eu/wp-content/uploads/sites/97/2025/01/GLOBECOM_WS_KANs-1.pdf

[^1_42]: https://openreview.net/forum?id=e1wDDFmlVu

