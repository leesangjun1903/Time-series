# Discrete Graph Structure Learning for Forecasting Multiple Time Series

## 1. 핵심 주장과 주요 기여

본 논문은 다중 시간 시리즈(multiple time series) 예측 문제에서 **그래프 구조를 자동으로 학습하면서 동시에 예측 성능을 향상시킬 수 있다**는 핵심 주장을 제시한다. 제안된 방법 GTS(Graph for Time Series)의 주요 기여는 다음과 같다:[1]

**핵심 기여점:**

시간 시리즈 간의 숨겨진 관계를 나타내는 그래프 구조를 단일 수준 최적화(unilevel optimization)를 통해 학습하는 방식을 제안한다. 이는 기존의 이중 수준 최적화(bilevel optimization) 방식인 LDS(Learning Discrete Structures)와 달리, 계산 효율성을 크게 개선하면서도 더 우수한 예측 성능을 달성한다.[1]

모델의 매개변수 개수가 시간 시리즈 개수의 제곱에 비례하여 증가하지 않도록 설계되어, 더 많은 시간 시리즈에 대해 확장 가능하다. 또한 사전 지식을 정규화 항으로 추가하여 학습된 그래프가 알려진 구조에서 의미 있는 변형만 가지도록 제어할 수 있다.[1]

## 2. 문제 정의, 제안 방법, 모델 구조 및 성능

### 2.1 해결하고자 하는 문제

다중 시간 시리즈 예측에서 각 시간 시리즈 간의 의존성을 모델링하기 위해 그래프 신경망(GNN)이 효과적임이 입증되었다. 하지만 실제 응용에서는 그래프 구조가 주어지지 않는 경우가 많다. 예를 들어, 에너지 그리드 센서 데이터의 경우 네트워크 위상 정보가 보호될 수 있고, 그 외에도 이러한 정보를 얻기 어려울 수 있다.[1]

따라서 **주어지지 않은 그래프 구조를 자동으로 학습하면서 동시에 예측 정확도를 극대화하는 방법**이 필요하다.[1]

### 2.2 기존 방법의 한계

이전 연구인 LDS는 그래프를 초매개변수로 취급하여 이중 수준 최적화 문제로 공식화한다:[1]

$$
\min_{\theta} \mathbb{E}_{A \sim \text{Ber}(\theta)}[F(A, w(\theta), X_{\text{val}})]
$$

$$
\text{s.t.} \quad w(\theta) = \arg\min_{w} \mathbb{E}_{A \sim \text{Ber}(\theta)}[L(A, w, X_{\text{train}})]
$$

여기서 $$\theta \in ^{n \times n}$$는 각 엣지의 확률을 나타내는 확률 행렬이다.[1]

LDS의 문제점:

1) **계산 비용이 높다**: 내부 최적화 $$\arg\min_w$$의 미분을 위해 RNN처럼 역전파를 수행해야 하므로 메모리 집약적이거나 시간이 많이 소요된다.[1]

2) **확장성이 떨어진다**: $$\theta$$의 크기가 $$\Theta(n^2)$$이므로 시간 시리즈 개수가 증가할수록 매개변수가 제곱으로 증가한다.[1]

### 2.3 제안 방법: GTS (Graph for Time Series)

GTS는 **단일 수준 최적화**를 통해 위의 문제를 해결한다:[1]

$$
\min_{w} \mathbb{E}_{A \sim \text{Ber}(\theta(w))}[F(A, w, X_{\text{train}})]
$$

핵심 차이점: 내부 최적화 $$w(\theta)$$ 대신, 확률 행렬 $$\theta$$를 모델 매개변수 $$w$$의 함수 $$\theta(w)$$로 직접 매개변수화한다. 이를 통해 그래프 학습이 일반적인 신경망 학습의 부산물이 된다.[1]

#### 2.3.1 그래프 구조 매개변수화

**핵심 문제**: 이진 행렬 $$A \in \{0,1\}^{n \times n}$$는 직접 미분이 불가능하다.[1]

**해결 방법**: 베르누이 분포의 Gumbel-Softmax 재매개변수화 기법을 사용한다:[1]

$$
A_{ij} = \text{sigmoid}\left(\frac{\log(\theta_{ij}/(1-\theta_{ij})) + (g^1_{ij} - g^2_{ij})}{s}\right)
$$

여기서 $$g^1_{ij}, g^2_{ij} \sim \text{Gumbel}(0,1)$$이고, 온도 매개변수 $$s$$를 학습 중 점진적으로 0으로 감소시킨다. $$s \to 0$$일 때, $$A_{ij}$$는 확률 $$\theta_{ij}$$로 1, 나머지 확률로 0이 된다.[1]

**확률 행렬 $$\theta$$의 매개변수화:**

1) **특성 추출기 (Feature Extractor)**:[1]
   - 각 시간 시리즈 $$X^i$$에 대해 특성 벡터 $$z_i$$를 생성한다.
   - 시간 차원에서 합성곱을 수행하고 벡터화 후 완전연결 계층을 적용한다:
   $$z_i = \text{FC}(\text{vec}(\text{Conv}(X^i)))$$
   - 가중치는 모든 시간 시리즈에서 공유된다.[1]

2) **링크 예측기 (Link Predictor)**:[1]
   - 특성 벡터 쌍 $$(z_i, z_j)$$를 입력받아 링크 확률 $$\theta_{ij} \in $$을 출력한다.[1]
   - 두 벡터를 연결한 후 두 개의 완전연결 계층을 적용한다:
   $$\theta_{ij} = \text{FC}(\text{FC}(z_i \parallel z_j))$$
   - 마지막 활성화 함수는 시그모이드이다.[1]

#### 2.3.2 그래프 신경망 예측 모델

시간 시리즈 예측을 위해 **확산 합성곱 GRU (Diffusion Convolutional GRU, DCRNN)**를 사용한다:[1]

$$
R_{t'} = \text{sigmoid}(W_R \star_A [X_{t'} \parallel H_{t'-1}] + b_R)
$$
$$
C_{t'} = \tanh(W_C \star_A [X_{t'} \parallel (R_{t'} \odot H_{t'-1})] + b_C)
$$
$$
U_{t'} = \text{sigmoid}(W_U \star_A [X_{t'} \parallel H_{t'-1}] + b_U)
$$
$$
H_{t'} = U_{t'} \odot H_{t'-1} + (1 - U_{t'}) \odot C_{t'}
$$

그래프 합성곱 연산 $$\star_A$$는 다음과 같이 정의된다:[1]

$$
W^Q \star_A Y = \sum_{k=0}^{K} \left[w^Q_{k,1}(D_O^{-1}A)^k + w^Q_{k,2}(D_I^{-1}A^T)^k\right]Y
$$

여기서 $$D_O$$와 $$D_I$$는 각각 출도 행렬과 입도 행렬이며, $$K$$는 확산 차수 초매개변수이다.[1]

### 2.4 정규화를 통한 사전 지식 통합

**기본 손실 함수**:[1]

$$
\ell^t_{\text{base}}(\hat{X}_{t+T+1:t+T+\tau}, X_{t+T+1:t+T+\tau}) = \frac{1}{\tau}\sum_{t'=t+T+1}^{t+T+\tau} |\hat{X}_{t'} - X_{t'}|
$$

**정규화 항** (선택사항):[1]

$$
\ell_{\text{reg}} = \sum_{ij} [-A^a_{ij}\log\theta_{ij} - (1-A^a_{ij})\log(1-\theta_{ij})]
$$

여기서 $$A^a$$는 사전에 알려진 그래프 구조이다. 전체 학습 손실은 $$\sum_t \ell^t_{\text{base}} + \lambda \ell_{\text{reg}}$$이며, $$\lambda > 0$$은 정규화 강도이다.[1]

이러한 정규화는 특히 k-최근접 이웃(kNN) 그래프를 사전 정보로 사용할 때 유용하며, 희소성을 자연스럽게 유도한다.[1]

### 2.5 성능 향상

광범위한 실험을 통해 GTS는 다음과 같은 성능 향상을 달성했다:[1]

**METR-LA 데이터셋 (교통 예측)**:[1]
- 15분 예측: GTS MAE = 2.64 vs DCRNN MAE = 2.77 vs LDS MAE = 2.75
- 30분 예측: GTS MAE = 3.01 vs DCRNN MAE = 3.15 vs LDS MAE = 3.14
- 60분 예측: GTS MAE = 3.41 vs DCRNN MAE = 3.60 vs LDS MAE = 3.63

**PEMS-BAY 데이터셋 (교통 예측)**:[1]
- 15분 예측: GTS MAE = 1.32 vs DCRNN MAE = 1.38 vs LDS MAE = 1.33
- 30분 예측: GTS MAE = 1.64 vs DCRNN MAE = 1.74 vs LDS MAE = 1.67
- 60분 예측: GTS MAE = 1.91 vs DCRNN MAE = 2.07 vs LDS MAE = 1.99

**PMU 데이터셋 (전력 그리드 센서)**:[1]
- 15분 예측: GTS MAE = 0.26×10^-3 vs NRI MAE = 0.66×10^-3 vs LDS MAE = 0.49×10^-3

**계산 효율성**: GTS의 훈련 시간은 DCRNN의 약 3배인 반면, LDS는 DCRNN보다 수십 배 느리다. 이는 단일 수준 최적화로 인한 효율성 향상을 명확히 보여준다.[1]

### 2.6 모델의 한계

1) **그래프 해석성의 제한**: 논문에서 명시했듯이, 학습된 그래프의 목적은 예측 정확도 향상이지 인과관계 발견이 아니다. 따라서 학습된 그래프가 실제 물리적 구조(예: 교통 네트워크)와 일치하지 않을 수 있다.[1]

2) **정규화에 대한 민감성**: 정규화 강도 $$\lambda$$의 값에 따라 예측 성능과 그래프 구조의 유사도 사이에 트레이드오프가 존재한다. 최적의 $$\lambda$$ 값을 찾기 위해 그리드 서치가 필요하다.[1]

3) **높은 동적성을 가진 시스템에서의 한계**: GTS는 학습 데이터에서 고정된 그래프 구조를 가정한다. 실제 시간 시리즈 간의 관계가 시간에 따라 변한다면, 이를 모델링하기 어렵다.[1]

4) **스파이크/이상치 처리**: 실험 결과에서 보았듯이, GTS도 데이터의 급격한 스파이크나 이상치를 잘 포착하지 못한다.[1]

## 3. 일반화 성능 향상 가능성

### 3.1 구조 정규화의 역할

GTS의 일반화 성능은 **구조 정규화**를 통해 크게 개선될 수 있다. PMU 데이터셋 실험에서:[1]

- 정규화 없음 (λ=0): MAE = 2.47×10^-4 (최고 성능), 학습된 그래프가 사전 지식과 크게 다름
- λ=20: MAE = 2.87×10^-4 (약 16% 성능 저하), 하지만 학습된 그래프가 사전 지식과 매우 유사 (평균 교차 엔트로피 = 0.34)[1]

이는 **적절한 정규화 강도(예: λ=10)에서 예측 성능과 그래프 구조 간의 좋은 균형을 달성할 수 있음**을 보여준다.[1]

### 3.2 사전 지식의 활용

데이터가 충분하지 않을 때, 사전 정보(kNN 그래프 등)를 정규화 항으로 통합하면:[1]

- 모델이 의미 있는 그래프 구조로 수렴하도록 유도한다.
- 과적합을 방지한다.
- 도메인 지식을 명시적으로 반영한다.

METR-LA에서 λ=0.3일 때, 예측 성능이 약 2-3% 저하되지만 학습된 그래프가 실제 도로 네트워크와 유사하게 된다.[1]

### 3.3 모델 변형의 영향

**GTSv (T-GCN을 사용한 변형)** 실험 결과:[1]

GTS와 비교해 약간 낮은 성능을 보이지만, DCRNN과 비교하면 훨씬 우수하다. 이는 **그래프 학습 컴포넌트가 특정 GNN 아키텍처보다 성능에 더 중요한 역할을 한다**는 것을 의미한다.[1]

따라서:
- 최신 GNN 아키텍처(예: Transformer 기반)를 적용해도 성능 향상이 가능하다.
- 핵심은 효과적인 그래프 구조 학습이다.

### 3.4 다양한 데이터셋에서의 일반화

세 가지 서로 다른 데이터셋에서 일관된 성능 향상을 보였다:[1]

| 데이터셋 | 특성 | GTS의 강점 |
|---------|------|-----------|
| METR-LA | 207개 센서, 교통 데이터, 알려진 그래프 | 일반화된 그래프 발견 |
| PEMS-BAY | 325개 센서, 교통 데이터, 알려진 그래프 | 확장성 입증 |
| PMU | 42개 센서, 전력 데이터, 미지의 구조 | 그래프 구조 자동 발견 |

이는 GTS가 **다양한 규모와 도메인에서 강건한 일반화 성능**을 보임을 나타낸다.[1]

## 4. 미래 연구에 미치는 영향과 고려사항

### 4.1 학문적 영향

1) **그래프 구조 학습의 새로운 패러다임**: GTS의 단일 수준 최적화 접근은 이중 수준 최적화의 계산 비용 문제를 극복하는 방법을 제시한다. 이는 구조 학습이 필요한 다른 분야(예: 인과 추론, 사회 네트워크 분석)에도 응용될 수 있다.[1]

2) **스파 속성화 유도의 우아한 방법**: $$\ell_1$$ 제약 대신 정규화 항으로 희소 그래프를 유도하는 방식은 더 유연하고 효과적이다.[1]

3) **신경망 기반 매개변수화의 가능성**: 특성 추출과 링크 예측을 신경망으로 수행하는 방식은 다양한 구조 학습 문제에 적용 가능하다.

### 4.2 실제 응용 발전 방향

1) **동적 그래프 학습**: 현재 GTS는 고정된 그래프를 학습한다. 시간 변화하는 관계를 모델링하기 위해 시간 가변 그래프 학습으로 확장할 수 있다.[1]
   - 각 시간 윈도우마다 다른 그래프를 학습하거나,
   - 그래프 변화의 부드러움을 정규화 항으로 제약할 수 있다.

2) **이상치와 스파이크 처리**: 현재 모델이 급격한 변화를 못 포착하는 문제를 해결하기 위해:
   - 강건한 손실 함수(Huber loss, quantile loss)의 사용,
   - 이상치 감지 모듈의 통합을 고려할 수 있다.

3) **매우 큰 규모 시스템으로의 확장**: $$n$$이 매우 큰 경우:
   - 희소 그래프 학습을 통해 계산 복잡성 감소,
   - 계층적 또는 모듈화된 그래프 구조 학습,
   - 그래프 컨볼루션의 근사 방법 적용.

4) **도메인 지식의 더 효과적인 통합**: 현재의 정규화 방법을 넘어:
   - 물리적 제약이나 도메인 규칙을 경성(hard) 제약으로 명시,
   - 사전 학습된 그래프 구조의 활용,
   - 전이 학습 전략.

### 4.3 방법론적 고려사항

1) **초매개변수 튜닝의 자동화**: $$\lambda$$, $$k$$ (kNN), 온도 감소 일정 등 여러 초매개변수가 있다. 베이지안 최적화나 자동 기계학습 기법을 적용하여 튜닝 비용을 줄일 수 있다.[1]

2) **해석가능성 개선**: 학습된 그래프의 엣지가 물리적으로 의미 있는지 검증하는 방법 개발:
   - 어텐션 메커니즘을 통한 해석성 강화,
   - 그래프 엣지와 예측 오차 간의 관계 분석.

3) **인과 구조 학습으로의 확장**: 현재는 상관관계 기반의 그래프를 학습하지만, 인과 구조 학습을 위해:
   - 방향성 그래프 학습,
   - 시간 지연 정보의 활용,
   - 인과 추론 원리의 통합.

### 4.4 NRI와의 관계 및 차별성

GTS는 NRI(Neural Relational Inference)와 유사한 목표를 가지지만, 본질적 차이가 있다:[1]

- **NRI**: 변분 자동 인코더 방식, 각 윈도우마다 다른 구조 학습, 상호작용 시스템 동역학 모델링에 적합
- **GTS**: 확정적 구조 하나를 학습, 고정된 통계 관계 모델링에 적합, 계산 효율성 우수

미래에는 두 방식을 결합한 **하이브리드 접근법**도 가능할 것이다: 
- 대부분의 경우 고정된 그래프 구조(GTS)를 사용하면서,
- 급격한 변화가 필요할 때만 동적 구조 학습(NRI 방식)을 적용.

### 4.5 실무 응용 시 점검 항목

GTS를 실제 문제에 적용할 때 고려할 점:[1]

1) **데이터 품질**: 신뢰할 수 없는 측정값, 결측치, 이상치가 많으면 학습 그래프의 신뢰도 저하
2) **충분한 학습 데이터**: 매개변수 개수가 $$O(n^2)$$는 아니지만, 복잡한 구조를 학습하려면 충분한 시간 윈도우 필요
3) **정규화 강도 선택**: 예측 정확도와 구조 해석성 사이의 트레이드오프 관리
4) **그래프 안정성**: 학습 데이터의 분할(train/val/test)에 따라 그래프 구조가 얼마나 변하는지 검증
5) **계산 자원**: GPU 메모리와 훈련 시간이 허용되는 수준인지 확인

***

## 결론

"Discrete Graph Structure Learning for Forecasting Multiple Time Series" 논문은 **시간 시리즈 예측에서 그래프 구조를 효율적으로 학습하는 획기적인 방법**을 제시한다. GTS는 단일 수준 최적화를 통해 기존 LDS 방식의 계산 병목을 극복하면서도 우수한 예측 성능을 달성한다.[1]

특히 **구조 정규화를 통한 사전 지식 통합**은 제한된 데이터 환경에서 모델의 일반화 성능을 크게 개선할 수 있는 중요한 메커니즘이다. 향후 연구는 동적 그래프 학습, 이상치 처리, 인과 구조 발견 등으로 확장될 수 있으며, 이는 의료 진단 시스템, 금융 시장 분석, 스마트 시티 관리 등 다양한 실무 분야에 적용될 잠재력을 가지고 있다.[1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/91070816-49ce-4f86-aa77-c64ef2f2b892/2101.06861v3.pdf)
