# Learning Neural Event Functions for Ordinary Differential Equations

## 1. 핵심 주장과 주요 기여 (간결한 요약)

이 논문의 핵심 주장은 **기존 Neural ODE의 한계를 극복하기 위해 신경망으로 매개변수화된 이벤트 함수를 도입**하는 것입니다. 주요 기여는 다음과 같습니다:[1]

**기본 개선점**: 기존 Neural ODE는 고정된 종료 시간에 의존하지만, 이 논문은 상태에 의존하는 암묵적 종료 기준을 학습합니다. 이를 통해 신경망이 **사전에 언제 이벤트가 발생할지 몰라도 불연속적인 상태 변화를 자동으로 모델링**할 수 있습니다.[1]

**핵심 기술**: 미분가능한 이벤트 처리를 위한 수학적 프레임워크를 개발하여, 역모드 자동미분을 통해 이벤트 함수의 매개변수를 학습할 수 있도록 했습니다.[1]

**적용 영역**: 물리 시뮬레이션(충돌), 하이브리드 시스템(스위칭 동역학), 시간 포인트 프로세스(Temporal Point Processes) 및 이산 제어까지 확장합니다.[1]

---

Learning Neural Event Functions for Ordinary Differential Equations는 기존의 신경 상미분 방정식(Neural ODE) 모델을 확장하여, 시스템의 상태가 급격하게 변하는 불연속적인 '이벤트(Event)'를 학습하고 모델링할 수 있게 하는 기술입니다.

- 기존 Neural ODE의 한계: 기존 모델은 시간에 따라 연속적으로 변하는 시스템을 모델링하는 데는 뛰어났으나, 공이 바닥에 튕기거나(충돌) 화학 반응이 시작되는 지점처럼 불연속적이고 순식간에 일어나는 변화를 처리하는 데는 어려움이 있었습니다.
- 이벤트 함수의 도입: 사용자가 종료 시점을 직접 지정하는 대신, 신경망으로 구현된 이벤트 함수 $(\(g\))$ 를 사용하여 시스템이 특정 조건에 도달했는지를 감시합니다.

## 2. 문제 정의, 제안 방법, 모델 구조 상세 설명

### 2.1 해결하고자 하는 문제

**기존 Neural ODE의 한계**: 기본 Neural ODE 모델은 다음과 같이 표현됩니다:[1]

$$ \frac{dz}{dt} = f(t, z(t), \theta) $$

여기서 $$z(t)$$는 연속 상태이고 $$f$$는 신경망입니다. 그러나 이러한 ODE는 본질적으로 **연속함수만 모델링**할 수 있어서, 다음의 상황들을 제대로 처리하지 못합니다:[1]

- **물리적 충돌**: 탄성공이 바닥에 닿을 때 속도가 즉시 반대 방향으로 뒤바뀌는 현상
- **화학 반응**: 특정 조건에서 반응이 급격히 일어나는 현상
- **스위칭 동역학**: 시스템이 이산적으로 다른 동역학 모드로 전환되는 경우

이 논문은 **탱성공 예제**로 이를 명확히 보여줍니다. 공의 위치 $$x(t)$$와 속도 $$v(t)$$는 $$\frac{dz}{dt} = [v(t), a]$$를 따르지만, 공이 바닥에 닿으면 속도가 즉시 반대가 되어야 합니다. 기존 Neural ODE는 이를 학습하지 못하고 외삽에서 실패합니다.[1]

### 2.2 제안하는 방법: 이벤트 함수와 미분가능한 처리

시스템의 상태 $\(z(t)\)$ 의 변화율을 신경망 $\(f(z(t),t,\theta )\)$ 로 정의했을 때, 솔버는 초기값 $\(z(t_{0})\)$ 부터 목표 시점 $\(t_{1}\)$ 까지의 상태를 다음의 적분 과정을 통해 계산합니다:

$$\(z(t_{1})=z(t_{0})+\int_{t_{0}}^{t_{1}}f(z(t),t,\theta )dt\)$$

즉, 솔버는 연속적인 시간 흐름에 따른 상태의 누적 변화량을 계산하는 도구로 정의됩니다. 

시스템은 신경망 $\(f\)$ 에 의해 정의된 궤적을 따라 연속적으로 움직입니다.

#### 이벤트 발생 조건 (Root-finding)

$$\(t^{\*}=\min \{t\in [t_{0},t_{max}]\mid g(z(t),\phi )=0\}\)$$

솔버는 적분 과정 중에 이벤트 함수 $\(g\)$ 의 부호가 변하는 지점을 감시합니다.  
$\(g(z(t),\phi )=0\)$ 이 되는 가장 빠른 시간 $\(t^{*}\)$ 를 수치적인 루트 파인딩(Root-finding) 알고리즘(예: Newton's method 또는 Bisection)을 통해 찾아냅니다.

**이벤트 함수 도입**: 기존 ODE 솔버의 이벤트 처리 기능을 차용하여:[1]

```math
t^*, z(t^*) = \text{ODESolveEvent}(z_0, f, g, t_0, \theta, \phi)
```

```math
t^{*},z(t^{*}))=\text{ODESolveEvent}(z(t_{0}),f,g,t_{0},t_{max},\theta ,\phi )
```

- 입력:
  - $\(z(t_{0})\)$ : 초기 상태 값
  - $\(f(z(t),t,\theta )\)$ : 시스템의 변화율을 정의하는 신경망 (Dynamics)
  - $\(g(z(t),\phi )\)$ : 이벤트 발생 여부를 감시하는 신경망 (Event Function)
  - $\(t_{0},t_{max}\)$ : 계산을 시작할 시간과 강제 종료할 최대 시간

- 출력:
  - $\(t^{\*}\)$ : 이벤트가 발생한 시각 $(\(g=0\)$ 인 지점)
  - $\(z(t^{*})\)$ : 이벤트 발생 순간의 시스템 상태 

여기서 $$g(t, z(t), \phi) = 0$$이 되는 시점 $$t^\*$$에서 ODE 풀이가 중단됩니다. 중요한 점은 $$t^*$$이 입력이 아닌 **상태 궤적에 의존하는 함수**라는 것입니다.[1]

#### 이벤트 감지 기능의 통합 (ODESolveEvent) 
논문에서는 일반적인 솔버에 이벤트 감지 로직이 추가된 ODESolveEvent라는 인터페이스를 정의하여 사용합니다: 
- 입력: 초기 상태 $(\(z_{0}\))$ , 동역학 함수 $(\(f\))$ , 이벤트 함수 $(\(g\))$ , 시간 범위 $(\(t_{0},t_{1}\))$ 등
- 출력: 이벤트가 발생한 시점 $(\(t^{\*}\))$ 과 그 시점의 상태 $(\(z(t^{*})\))$
- 동작: 솔버가 적분을 수행하다가 신경망으로 정의된 이벤트 함수 $\(g(z(t),\phi )\)$ 의 값이 0이 되는 지점을 발견하면, 그 즉시 계산을 멈추고 해당 시점을 반환합니다. 

#### 시점 $(\(t^{\*}\))$의 수치적 탐색 
ODE 솔버가 상태를 계산하는 동안, 이벤트 함수 $\(g\)$ 의 부호가 바뀌는 지점(예: 양수에서 음수로 변하는 순간)을 감시합니다. 
- 루트 파인딩(Root-finding): $\(g(z(t^{\*}),\phi )=0\)$ 이 되는 정확한 시간 $\(t^{*}\)$ 를 수치 해석 기법을 통해 찾아냅니다.
- 자동 감지: 사용자가 "언제"라고 지정하지 않아도, 모델은 $\(g\)$ 가 0이 되는 지점을 이벤트 발생 시점으로 자동 간주합니다.

- 적응형 계산 (Adaptive Computation): 솔버는 문제의 복잡도에 따라 스스로 계산 단계(Step)의 크기를 조절합니다. 간단한 구간은 빠르게 통과하고, 급격한 변화가 있는 구간은 정밀하게 계산하여 효율성을 극대화합니다.
- 미분 가능성 (Differentiability): 솔버 내부의 수치 해석 과정을 일일이 저장하지 않고도, Adjoint Sensitivity Method를 통해 최종 결과물로부터 모델 파라미터까지의 그래디언트(기울기)를 계산할 수 있도록 설계되었습니다. 이를 통해 메모리 효율성을 유지하며 딥러닝 모델처럼 학습이 가능합니다. 

**수학적 핵심: 암묵 함수 정리(Implicit Function Theorem) 적용**

이 기술의 핵심은 $\(t^{\*}\)$ 에서 미분 값을 구해 파라미터 $\(\theta \)$ 와 $\(\phi \)$ 를 업데이트하는 것입니다.  
암묵 함수 정리(Implicit Function Theorem, IFT)는 직접적으로 정의되지 않은 함수 관계에서 미분값을 도출하는 수학적 도구입니다.  

- 암시적 종료 조건 학습: 시스템의 상태가 언제 변해야 하는지 사전에 알 필요 없이, 데이터로부터 변화가 일어나는 시점과 그 결과를 스스로 학습합니다.
- 미분 가능한 이벤트 처리: 이벤트가 발생하는 정확한 시간을 수치적으로 찾아내고, 이 과정을 통해 역전파(Backpropagation)가 가능하도록 설계되어 전체 모델을 끝까지 학습시킬 수 있습니다.
- 하이브리드 시스템 모델링: 연속적인 움직임과 이산적인 변화가 공존하는 '하이브리드 동역학 시스템'을 완벽하게 재구성하고 외삽(Extrapolation)할 수 있습니다. 

시스템의 사전 지식 없이 데이터만으로 이벤트 발생 시점과 결과를 학습하는 원리는 미분 가능한 이벤트 감지(Differentiable Event Detection) 메커니즘에 있습니다.

모델은 시스템의 상태 $\(z(t)\)$ 를 입력받아 스칼라 값을 출력하는 신경망 $\(g(z(t),\phi )\)$ 를 정의합니다. 이 함수는 시스템이 특정 "임계점"에 도달했는지를 판단하는 기준이 됩니다. 

이벤트 함수를 루트 찾기 문제로 재해석합니다:[1]

$$ g_{\text{root}}(t, z_0, t_0, \theta) = g\left(t, z = \text{ODESolve}(z_0, f, t_0, t, \theta)\right) $$

이 논문에서는 이벤트 발생 조건인 $\(g(z(t^{\*}),\phi )=0\)$ 을 만족하는 이벤트 시점 $\(t^{*}\)$ 의 그래디언트를 구하기 위해 이 정리를 사용합니다. 

우리는 $\(t^{\*}\)$ 가 파라미터 $\(\phi \)$ 에 따라 변한다는 것을 알지만, $\(t^{\*}=\text{어떠한\ 식}(\phi )\)$ 형태의 명시적인 함수로 표현할 수는 없습니다.  
하지만 이벤트 발생 순간에는 항상 다음의 등식이 성립합니다.

```math
G(\phi ,t^{*})=g(z(t^{*},\phi ),\phi )=0
```

이 식의 양변을 파라미터 $\(\phi \)$ 에 대해 전미분(Total Differentiation)하면 다음과 같습니다.

$$\(\frac{\partial g}{\partial \phi }+\frac{\partial g}{\partial z}\frac{\partial z}{\partial \phi }=0\)$$

여기서 $\(z\)$ 는 다시 $\(t^{\*}\)$ 에 의존하므로, 연쇄 법칙을 적용하여 정리하면 최종적으로 이벤트 시점의 변화량 $(\(\partial t^{*}/\partial \phi \))$ 을 구할 수 있는 수식이 도출됩니다:

```math
\frac{\partial t^{*}}{\partial \phi }=-\left(\underbrace{\frac{\partial g}{\partial z}f(z(t^{*}))+\frac{\partial g}{\partial t^{*}}}_{\text{시간에\ 따른\ g의\ 변화율}}\right)^{-1}\frac{\partial g}{\partial \phi }
```

<details>

### 1단계: 암묵적 관계식의 전미분 
이벤트가 발생하는 시점 $\(t^{\*}\)$ 에서 이벤트 함수 $\(g\)$ 는 정의에 의해 항상 $\(0\)$ 입니다.  
파라미터 $\(\phi \)$ 가 변하더라도 이벤트가 발생하는 "그 순간"의 조건은 유지되어야 하므로, 항등식 $\(g(z(t^{\*},\phi ),t^{\*},\phi )=0\)$ 을 파라미터 $\(\phi \)$ 에 대해 전미분합니다.  
연쇄 법칙(Chain Rule)을 적용하면 다음과 같습니다.

$`\frac{\partial g}{\partial z}\frac{dz}{d\phi }+\frac{\partial g}{\partial t^{*}}\frac{\partial t^{*}}{\partial \phi }+\frac{\partial g}{\partial \phi }=0`$

### 2단계: ODE 동역학 관계식 대입 
위 식에서 상태 변수 $\(z\)$ 는 시간 $\(t^{\*}\)$ 에 의존하며, $\(t^{\*}\)$ 는 다시 파라미터 $\(\phi \)$ 에 의존합니다.  
따라서 $\(z\)$ 의 $\(\phi \)$ 에 대한 변화율은 라이프니츠 규칙에 따라 다음과 같이 표현됩니다.

$`\frac{dz}{d\phi }=\frac{dz}{dt^{*}}\frac{\partial t^{*}}{\partial \phi }`$

이때 상미분 방정식(ODE)의 정의에 따라 $\(\frac{dz}{dt^{*}}=f(z(t^{\*}),t^{\*},\theta )\)$ 이므로, 이를 1단계의 식에 대입합니다.

$`\frac{\partial g}{\partial z}\left(f(z(t^{*}),t^{*},\theta )\frac{\partial t^{*}}{\partial \phi }\right)+\frac{\partial g}{\partial t^{*}}\frac{\partial t^{*}}{\partial \phi }+\frac{\partial g}{\partial \phi }=0`$

### 3단계: 공통항 정리 및 최종식 도출 
$\(\frac{\partial t^{\*}}{\partial \phi }\)$ 를 공통 인수로 묶어서 정리하면 다음과 같습니다.

$`\left(\frac{\partial g}{\partial z}f(z(t^{*}),t^{*},\theta )+\frac{\partial g}{\partial t^{*}}\right)\frac{\partial t^{*}}{\partial \phi }=-\frac{\partial g}{\partial \phi }`$

이제 좌변의 계수 행렬의 역행렬을 양변에 곱하여 최종적인 변화량 식을 얻습니다.

$`\frac{\partial t^{*}}{\partial \phi }=-\left(\frac{\partial g}{\partial z}f(z(t^{*}),t^{*},\theta )+\frac{\partial g}{\partial t^{*}}\right)^{-1}\frac{\partial g}{\partial \phi }`$

이는 이벤트 함수의 파라미터가 변할 때 이벤트 발생 시간이 얼마나 민감하게 반응하는지를 나타냅니다.
      
</details>

이 식을 통해 우리는 이벤트 함수 $(\(g\))$ 가 조금 변했을 때 이벤트 시점 $(\(t^{*}\))$ 이 얼마나 이동하는지를 수학적으로 정확히 계산할 수 있게 됩니다. 

암묵 함수 정리에 의해, 임의의 입력 $$\xi \in \{z_0, t_0, \theta\}$$에 대해:[1]

```math
\frac{dt^*}{d\xi} = -\left(\frac{dg_{\text{root}}(t^*, z_0, t_0, \theta)}{dt}\right)^{-1} \left(\frac{\partial g(t^*, z(t^*))}{\partial z} \frac{\partial z(t^*)}{\partial \xi}\right)
```

로 일반화할 수 있습니다.

**손실 함수의 그래디언트 계산**

모델의 최종 목적은 예측된 궤적과 실제 데이터 사이의 오차(Loss, $\(L\)$ )를 줄이는 것입니다. 이벤트 시점 $\(t^{*}\)$ 을 포함한 전체 학습 과정에서의 그래디언트 흐름은 다음과 같습니다.

이벤트는 $\(g(t,z(t))=0\)$ 이 되는 시점 $\(t^{\*}\)$ 에서 발생합니다.  
파라미터 $\(\theta \)$ 가 변함에 따라 이벤트 시점 $\(t^{\*}\)$ 과 상태 $\(z(t^{\*})\)$ 가 모두 변하므로, 항등식 $\(g(t^{\*}(\theta ),z(t^{*}(\theta ),\theta ))=0\)$ 의 양변을 시간 $\(t\)$ 에 대해 미분하여 궤적을 따라가는 $\(g\)$ 의 변화율을 구합니다.  
이를 전시간 미분이라고 하며 다음과 같이 전개됩니다.

$`\frac{dg}{dt}=\frac{\partial g}{\partial t}+\frac{\partial g}{\partial z}^{T}\frac{dz}{dt}`$

이와 유사하게 Root-finding 시스템으로 이벤트를 찾았을 때의 손실이 $$L(t^\*, z(t^*))$$에 의존할 때:[1]

```math
\frac{\partial g_{\text{root}}(t^*, z_0, t_0, \theta)}{dt} = \frac{\partial g(t^*, z(t^*))}{\partial t} + \frac{\partial g(t^*, z(t^*))}{\partial z}^T f^*
```

여기서 $$f^\* = f(t^\*, z(t^\*))$$입니다.

최종 그래디언트는:[1]

$$ \frac{dL}{d\xi} = v^T \frac{\partial z(t^*)}{\partial \xi} $$

여기서:

```math
v = \left(\frac{\partial L}{\partial t^*} + \frac{\partial L}{\partial z(t^*)}^T f^*\right) \left(-\frac{dg_{\text{root}}(t^*, z_0, t_0, \theta)}{dt}\right)^{-1} \frac{\partial g(t^*, z(t^*))}{\partial z} + \frac{\partial L}{\partial z(t^*)}
```

<details>

최종 그래디언트 $\(\frac{dL}{d\xi }=v^{T}\frac{\partial z(t^{\*})}{\partial \xi }\)$ 는 손실 함수 $\(L(t^{\*},z(t^{*}))\)$ 에 연쇄 법칙을 적용하고, 암묵 함수 정리로부터 얻은 이벤트 시점의 미분값을 대입하여 도출됩니다.  
여기서 $\(\xi \)$ 는 학습 가능한 파라미터 ( $\(z_{0},\theta \)$ 등)를 의미합니다. 

### 1단계: 손실 함수의 전미분 (Total Derivative) 
손실 함수 $\(L\)$ 은 $\(t^{\*}\)$ 와 $\(z(t^{\*})\)$ 를 통해 파라미터 $\(\xi \)$ 에 의존합니다.  
$\(\xi \)$ 에 대한 $\(L\)$ 의 전미분은 다음과 같습니다.

$`\frac{dL}{d\xi }=\frac{\partial L}{\partial t^{*}}\frac{dt^{*}}{d\xi }+\frac{\partial L}{\partial z(t^{*})}^{T}\frac{dz(t^{*})}{d\xi }`$

### 2단계: 상태 변수 $\(z(t^{\*})\)$ 의 전미분 
이벤트 시점의 상태 $\(z(t^{*})=z(t^{\*}(\xi ),\xi )\)$ 이므로, $\(\xi \)$ 에 대한 전미분은 다음과 같이 전개됩니다.  
이때 $\(\frac{\partial z}{\partial t}=f^{\*}\)$ 임을 이용합니다.

$`\frac{dz(t^{*})}{d\xi }=\frac{\partial z(t^{*})}{\partial t^{*}}\frac{dt^{*}}{d\xi }+\frac{\partial z(t^{*})}{\partial \xi }=f^{*}\frac{dt^{*}}{d\xi }+\frac{\partial z(t^{*})}{\partial \xi }`$

이를 1단계 식에 대입하여 정리하면 다음과 같습니다.

$`\frac{dL}{d\xi }=\left(\frac{\partial L}{\partial t^{*}}+\frac{\partial L}{\partial z(t^{*})}^{T}f^{*}\right)\frac{dt^{*}}{d\xi }+\frac{\partial L}{\partial z(t^{*})}^{T}\frac{\partial z(t^{*})}{\partial \xi }`$

### 3단계: 이벤트 시점 미분값 $(\(\frac{dt^{\*}}{d\xi }\))$ 대입 
이전 식에서 유도한 암묵 함수 정리 결과의 일반화된 식에 의해, $\(\frac{dt^{\*}}{d\xi }\)$ 는 다음과 같이 정의됩니다.

$`\frac{dt^{*}}{d\xi }=-\left(\frac{dg_{\text{root}}}{dt}\right)^{-1}\frac{\partial g}{\partial z}^{T}\frac{\partial z(t^{*})}{\partial \xi }`$

이 식을 2단계의 최종식에 대입합니다.

$`\frac{dL}{d\xi }=\left(\frac{\partial L}{\partial t^{*}}+\frac{\partial L}{\partial z(t^{*})}^{T}f^{*}\right)\left(-\frac{dg_{\text{root}}}{dt}\right)^{-1}\frac{\partial g}{\partial z}^{T}\frac{\partial z(t^{*})}{\partial \xi }+\frac{\partial L}{\partial z(t^{*})}^{T}\frac{\partial z(t^{*})}{\partial \xi }`$

### 4단계: 공통항 정리 및 $\(v\)$ 의 도출 
$\(\frac{\partial z(t^{\*})}{\partial \xi }\)$ 를 공통 인수로 묶어내면 전체 식이 $\(v^{T}\)$ 의 형태로 정리됩니다.

$`\frac{dL}{d\xi }=\underbrace{\left[\left(\frac{\partial L}{\partial t^{*}}+\frac{\partial L}{\partial z(t^{*})}^{T}f^{*}\right)\left(-\frac{dg_{\text{root}}}{dt}\right)^{-1}\frac{\partial g}{\partial z}^{T}+\frac{\partial L}{\partial z(t^{*})}^{T}\right]}_{v^{T}}\frac{\partial z(t^{*})}{\partial \xi }`$

이 괄호 안의 전치(Transpose) 결과가 문제에서 정의된 벡터 $\(v\)$와 일치하게 됩니다.

이 식은 이벤트 시점의 시간적 변화와 상태 변화가 손실 함수에 미치는 영향을 통합하여 파라미터를 업데이트할 수 있게 합니다.
      
</details>

**핵심 이점**: 이 계산은 이벤트 함수 $$g$$의 그래디언트만 필요하고, ODE 솔버를 통해 미분할 필요가 없습니다. 따라서 하나의 역방향 ODE 솔버 호출로 완료됩니다.[1]

### 2.3 신경망 이벤트 ODE 모델 구조

**알고리즘 1: 신경 이벤트 ODE**[1]

```
입력: 초기 조건 (t₀, z₀), 최종 종료 시간 T, 드리프트 함수 f, 
      이벤트 함수 g, 순간 업데이트 함수 h

i = 0
while tᵢ < T do
    tᵢ₊₁, z'ᵢ₊₁ = ODESolveEvent(zᵢ, f, g, tᵢ)    ▷ 다음 이벤트까지 풀이
    zᵢ₊₁ = h(tᵢ₊₁, z'ᵢ₊₁)                        ▷ 상태 즉시 업데이트
    i = i + 1
end while
반환: 이벤트 시간 {tᵢ}과 구간별 연속 궤적 {zᵢ(t)}
```

**세 가지 핵심 신경망 성분**:[1]

1. **드리프트 함수 $$f(t, z(t); \theta)$$**: 연속 동역학을 모델링
2. **이벤트 함수 $$g(t, z(t); \phi)$$**: 이벤트 발생 조건 모델링
3. **순간 업데이트 함수 $$h(t, z'(t); \psi)$$**: 이벤트 발생 시 상태 변화 적용

***

## 3. 성능 향상 및 한계

### 3.1 성능 향상: 실험 결과

**실험 1: 스위칭 선형 동역학 시스템 (Switching Linear Dynamical System)**[1]

팬 모양 트랙을 따라 움직이는 입자를 모델링하는 문제:

| 모델 | 테스트 손실 (MSE) |
|------|-----------------|
| RNN (LSTM) | 0.261 ± 0.078 |
| Neural ODE | 0.157 ± 0.005 |
| **Neural Event ODE** | **0.093 ± 0.037** |

**Neural Event ODE가 최고 성능**: 기존 Neural ODE 대비 약 41% 개선, LSTM 대비 약 64% 개선[1]

**실험 2: 다중 물체 충돌 물리 시뮬레이션**[1]

상자 내 두 개의 탄성공 충돌 모델링:

| 모델 | @25 | @50 | @100 | ODE 복잡도@50 | 이벤트 함수 복잡도@50 |
|------|-----|-----|------|---------------|-------------------|
| RNN (LSTM) | 0.01 | 0.07 | 0.24 | — | — |
| Neural ODE | 0.00 | 0.06 | 0.18 | 3,810 | — |
| **Neural Event ODE** | 0.01 | 0.07 | 0.19 | **160** | **160** |

**효율성 극적 개선**: Neural ODE는 함수 평가 3,810회, Neural Event ODE는 총 320회(드리프트 160회 + 이벤트 160회)로 **약 95% 계산량 감소**[1]

**실험 3: 탄성공 외삽 (Figure 1)**[1]

- **Neural ODE**: 훈련 영역 내에서는 동작하지만, 외삽에서 완전 실패
- **Neural Event ODE**: 선형 모델로도 정확한 동역학 회복, 완벽한 외삽 성능

### 3.2 시간 포인트 프로세스와 재매개변수화 그래디언트

**개선 사항**: 재매개변수화 그래디언트가 REINFORCE 대비 훨씬 빠른 수렴[1]

| 방법 | 5 이벤트 수렴 속도 | 10 이벤트 수렴 속도 |
|------|-----------------|------------------|
| REINFORCE | 느린 수렴 | 매우 느린 수렴 |
| **재매개변수화 그래디언트** | **빠른 수렴** | **적절한 수렴** |

**이산 제어 응용** (Figure 4c, 4d):[1]

- HIV 동역학 모델: 재매개변수화 그래디언트가 가장 우수
- Hodgkin-Huxley 신경 동역학: **결정론적 정책이 확률론적 정책보다 더 우수한 성능**

### 3.3 현실적 한계

**1. 미니배칭 (Minibatching) 문제**[1]

이 방법의 주요 제약: 각 궤적이 서로 다른 이벤트 위치를 가질 수 있습니다. ODE 솔버는 미니배치 내 시스템의 독립성을 명시적으로 처리하지 않아서, 스파스 집계자(min/max 연산)를 사용해야 합니다. 이는 **미니배치의 한 이벤트 함수가 트리거될 때마다 전체 통합을 재시작**해야 하므로 오버헤드가 발생합니다.[1]

**2. 탈주 이벤트 경계 (Runaway Event Boundaries)**[1]

문제: 신경망 이벤트 함수가 절대 0을 지나지 않으면 어떻게 될까요? 고차원에서 신경망의 근(root)은 예측 불가능하므로 궤적이 이벤트를 만나지 않을 수 있습니다. 이 경우:

- 이벤트 함수 매개변수에 그래디언트가 없음
- 모델이 순수 Neural ODE로 퇴화

**해결책**: 이벤트 함수 매개변수를 큰 표준 편차로 초기화하면 부분적으로 완화되지만, 근본적인 해결책은 아닙니다. 임계값 기반 이벤트 함수(섹션 5)는 적분이 항상 양수이므로 덜 문제가 됩니다.[1]

**3. 이벤트 개수의 불연속성 (Discrete Number of Events)**[1]

문제: 매개변수 공간에서 작은 변화가 이벤트 개수를 급격히 변경할 수 있습니다. 이는 목적 함수의 불연속성을 초래합니다:

- 샘플링 기반 학습에서 재매개변수화 그래디언트가 미분가능성을 요구
- 이벤트 개수에 의존하는 목적 함수는 불연속

**극복 방법**: 대용 목적함수 사용(Shchur et al., 2020 참조)[1]

***

## 4. 일반화 성능 향상 가능성 (강조)

### 4.1 외삽 능력 (Extrapolation Capability)

**탈성공 예제의 깊은 의미**[1]

Figure 1에 보이듯이:
- **기존 Neural ODE**: 훈련 시간 구간에서 피팅하지만, 외삽에서 완전히 실패. 이는 비선형 ODE가 불연속적인 동작(속도 반전)을 표현할 수 없기 때문입니다.
- **Neural Event ODE**: 선형 드리프트 함수(매우 제한적)로도 정확하게 동역학을 회복하고 완벽하게 외삽합니다.

**왜 일반화가 개선되는가**[1]

신경망이 연속 동역학만 학습하는 것이 아니라 **이벤트 발생의 사실적 조건**을 명시적으로 모델링하기 때문입니다. 이는 분포 외(out-of-distribution) 입력에 대한 모델의 구조적 편향(inductive bias)을 강화합니다.

### 4.2 스위칭 동역학 시스템에서의 일반화

**훈련-테스트 불일치 극복**[1]

- 훈련: 100개의 짧은 궤적(길이 4 → 50개 이산화 스텝)
- 테스트: 25개의 훨씬 긴 궤적(길이 12 → 150개 이산화 스텝)

즉, 테스트 궤적이 훈련보다 **3배 더 깁니다**. Neural Event ODE는 여전히 매우 낮은 테스트 손실(0.093)을 유지하여 **명시적인 스위칭 조건 학습이 시간 영역에서의 외삽을 가능**하게 함을 보여줍니다.[1]

### 4.3 물리 시뮬레이션에서의 구조적 이해

**충돌 모델링의 이점**[1]

Figure 3에서 보이듯이:
- RNN과 기존 Neural ODE는 손실을 줄이기 위해 "물리적으로 부자연스러운" 행동(공이 공중에 떠 있음)을 학습
- Neural Event ODE는 실제 충돌 조건을 명시적으로 모델링하여, **더 해석 가능하고 물리적으로 타당한** 표현을 학습

이는 **모델이 데이터의 기저 구조를 이해**함을 의미하므로 분포 외 상황으로의 일반화가 더 쉽습니다.

### 4.4 효율성과 샘플 효율

**계산 복잡도 감소가 일반화를 돕는 이유**[1]

- Neural Event ODE: 함수 평가 ~320회 (160 드리프트 + 160 이벤트)
- Neural ODE: 함수 평가 ~3,810회

더 적은 계산이 필요하다는 것은:
1. 더 안정적인 수치 적분 (오차 누적 감소)
2. 더 명확한 경사 신호 (스티프 ODE의 수치 불안정성 회피)
3. 메모리 효율성 개선

이는 **더 좋은 그래디언트 신호 → 더 나은 일반화**를 의미합니다.[1]

### 4.5 재매개변수화 그래디언트의 분산 감소

**시간 포인트 프로세스에서의 이점**[1]

Figure 4(a), (b)에서 재매개변수화 그래디언트는:
- 더 빠른 수렴
- 더 낮은 손실 변동성

더 낮은 분산의 그래디언트는 훈련 과정이 더 안정적이고 일반화 갭을 줄이는 데 도움됩니다.[1]

---

## 5. 연구에 미치는 영향과 고려사항

### 5.1 이론적 기여

**기본 패러다임 확장**[1]

이 논문은 Neural ODE 프레임워크를 **불연속적 시스템**으로 확장한 첫 체계적 접근입니다. 이를 통해:

1. 미분가능성과 불연속성의 경계를 흐릿하게 함
2. 역모드 자동미분이 더 일반적인 시스템 클래스에 적용 가능함을 증명
3. 물리 시뮬레이션, 점프 프로세스, 의사결정 모델 등 새로운 영역의 기초 제공

### 5.2 실천적 고려사항

**앞으로 연구 시 주의할 점**:[1]

1. **초기화 전략 중요성**: 탈주 이벤트 경계를 피하려면 이벤트 함수를 큰 표준 편차로 초기화해야 합니다. 더 정교한 초기화 기법 개발 필요.[1]

2. **대규모 미니배칭**: 현재 미니배칭 오버헤드는 병렬 계산 효율을 제한합니다. GPU 메모리 활용을 개선하는 새로운 배치 전략 필요.[1]

3. **고차원 확장성**: 고차원 문제에서 이벤트 함수의 근을 찾기가 어려워질 수 있습니다. 적응적 샘플링이나 보조 신경망을 통한 "사전(prior)" 학습이 도움될 수 있습니다.

4. **목적 함수 설계**: 이벤트 개수가 이산적이므로, 연속 프록시 목적 함수를 설계하는 것이 중요합니다. 예를 들어 soft 이벤트 탐지를 고려할 수 있습니다.

5. **다양한 이벤트 함수 클래스 탐색**: 
   - 상태 종속 이벤트(섹션 4): 일반적이지만 학습이 어려움
   - 임계값 기반 이벤트(섹션 5): 안정적이지만 표현력 제한

### 5.3 응용 전망

**의료 이미징과의 연관성** (당신의 배경 고려)

이 방법이 유망할 수 있는 영역:

1. **X선 이미지 동역학 모델링**: 뼈 억제 후 조직 경계의 급격한 변화를 명시적으로 모델링
2. **이상 탐지**: 정상적인 신체 반응의 "이벤트"(예: 기침, 심박)를 감지하는 신경망
3. **다중 장기 상호작용**: 기관 간 불연속적 신호 변환을 모델링

### 5.4 거시적 영향

**깊은 학습의 물리-인정 방향**[1]

이 연구는:
- 물리 법칙(차등 방정식)의 엄격성과 신경망의 유연성의 조화
- 해석 가능한 머신러닝 방향으로의 발전 (각 이벤트의 명시적 표현)
- 강화 학습, 제어 이론, 통계 학습 간 다리 역할

***

## 결론

Neural Event ODE는 **상태 불연속성의 명시적 모델링을 통해 기존 Neural ODE의 표현 능력을 비약적으로 확장**합니다. 특히 외삽, 물리적 해석 가능성, 계산 효율성 측면에서 현저한 개선을 보이며, 시간 포인트 프로세스와 이산 제어라는 새로운 응용 영역을 개척합니다.[1]

다만 **미니배칭, 탈주 경계, 불연속 목적 함수** 등의 실천적 한계를 극복하려면 추가 연구가 필요합니다. 앞으로의 연구는 이러한 제약을 해결하면서도 더 높은 차원의 문제로 확장하고, 도메인-특화 이벤트 함수 설계 기법을 개발하는 방향으로 나아가야 할 것입니다.[1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/c73a9339-6e14-4b32-81ac-8daeab7747ab/2011.03902v4.pdf)
