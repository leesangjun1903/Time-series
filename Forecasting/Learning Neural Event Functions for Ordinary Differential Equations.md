# Learning Neural Event Functions for Ordinary Differential Equations

## 1. 핵심 주장과 주요 기여 (간결한 요약)

이 논문의 핵심 주장은 **기존 Neural ODE의 한계를 극복하기 위해 신경망으로 매개변수화된 이벤트 함수를 도입**하는 것입니다. 주요 기여는 다음과 같습니다:[1]

**기본 개선점**: 기존 Neural ODE는 고정된 종료 시간에 의존하지만, 이 논문은 상태에 의존하는 암묵적 종료 기준을 학습합니다. 이를 통해 신경망이 **사전에 언제 이벤트가 발생할지 몰라도 불연속적인 상태 변화를 자동으로 모델링**할 수 있습니다.[1]

**핵심 기술**: 미분가능한 이벤트 처리를 위한 수학적 프레임워크를 개발하여, 역모드 자동미분을 통해 이벤트 함수의 매개변수를 학습할 수 있도록 했습니다.[1]

**적용 영역**: 물리 시뮬레이션(충돌), 하이브리드 시스템(스위칭 동역학), 시간 포인트 프로세스(Temporal Point Processes) 및 이산 제어까지 확장합니다.[1]

---

## 2. 문제 정의, 제안 방법, 모델 구조 상세 설명

### 2.1 해결하고자 하는 문제

**기존 Neural ODE의 한계**: 기본 Neural ODE 모델은 다음과 같이 표현됩니다:[1]

$$ \frac{dz}{dt} = f(t, z(t), \theta) $$

여기서 $$z(t)$$는 연속 상태이고 $$f$$는 신경망입니다. 그러나 이러한 ODE는 본질적으로 **연속함수만 모델링**할 수 있어서, 다음의 상황들을 제대로 처리하지 못합니다:[1]

- **물리적 충돌**: 탄성공이 바닥에 닿을 때 속도가 즉시 반대 방향으로 뒤바뀌는 현상
- **화학 반응**: 특정 조건에서 반응이 급격히 일어나는 현상
- **스위칭 동역학**: 시스템이 이산적으로 다른 동역학 모드로 전환되는 경우

이 논문은 **탱성공 예제**로 이를 명확히 보여줍니다. 공의 위치 $$x(t)$$와 속도 $$v(t)$$는 $$\frac{dz}{dt} = [v(t), a]$$를 따르지만, 공이 바닥에 닿으면 속도가 즉시 반대가 되어야 합니다. 기존 Neural ODE는 이를 학습하지 못하고 외삽에서 실패합니다.[1]

### 2.2 제안하는 방법: 이벤트 함수와 미분가능한 처리

**이벤트 함수 도입**: 기존 ODE 솔버의 이벤트 처리 기능을 차용하여:[1]

```math
t^*, z(t^*) = \text{ODESolveEvent}(z_0, f, g, t_0, \theta, \phi)
```

여기서 $$g(t, z(t), \phi) = 0$$이 되는 시점 $$t^\*$$에서 ODE 풀이가 중단됩니다. 중요한 점은 $$t^*$$이 입력이 아닌 **상태 궤적에 의존하는 함수**라는 것입니다.[1]

**수학적 핵심: 암묵 함수 정리(Implicit Function Theorem) 적용**

이벤트 함수를 루트 찾기 문제로 재해석합니다:[1]

$$ g_{\text{root}}(t, z_0, t_0, \theta) = g\left(t, z = \text{ODESolve}(z_0, f, t_0, t, \theta)\right) $$

암묵 함수 정리에 의해, 임의의 입력 $$\xi \in \{z_0, t_0, \theta\}$$에 대해:[1]

```math
\frac{dt^*}{d\xi} = -\left(\frac{dg_{\text{root}}(t^*, z_0, t_0, \theta)}{dt}\right)^{-1} \left(\frac{\partial g(t^*, z(t^*))}{\partial z} \frac{\partial z(t^*)}{\partial \xi}\right)
```

**손실 함수의 그래디언트 계산**

손실이 $$L(t^\*, z(t^*))$$에 의존할 때:[1]

```math
\frac{\partial g_{\text{root}}(t^*, z_0, t_0, \theta)}{dt} = \frac{\partial g(t^*, z(t^*))}{\partial t} + \frac{\partial g(t^*, z(t^*))}{\partial z}^T f^*
```

여기서 $$f^\* = f(t^\*, z(t^\*))$$입니다.

최종 그래디언트는:[1]

$$ \frac{dL}{d\xi} = v^T \frac{\partial z(t^*)}{\partial \xi} $$

여기서:

```math
v = \left(\frac{\partial L}{\partial t^*} + \frac{\partial L}{\partial z(t^*)}^T f^*\right) \left(-\frac{dg_{\text{root}}(t^*, z_0, t_0, \theta)}{dt}\right)^{-1} \frac{\partial g(t^*, z(t^*))}{\partial z} + \frac{\partial L}{\partial z(t^*)}
```

**핵심 이점**: 이 계산은 이벤트 함수 $$g$$의 그래디언트만 필요하고, ODE 솔버를 통해 미분할 필요가 없습니다. 따라서 하나의 역방향 ODE 솔버 호출로 완료됩니다.[1]

### 2.3 신경망 이벤트 ODE 모델 구조

**알고리즘 1: 신경 이벤트 ODE**[1]

```
입력: 초기 조건 (t₀, z₀), 최종 종료 시간 T, 드리프트 함수 f, 
      이벤트 함수 g, 순간 업데이트 함수 h

i = 0
while tᵢ < T do
    tᵢ₊₁, z'ᵢ₊₁ = ODESolveEvent(zᵢ, f, g, tᵢ)    ▷ 다음 이벤트까지 풀이
    zᵢ₊₁ = h(tᵢ₊₁, z'ᵢ₊₁)                        ▷ 상태 즉시 업데이트
    i = i + 1
end while
반환: 이벤트 시간 {tᵢ}과 구간별 연속 궤적 {zᵢ(t)}
```

**세 가지 핵심 신경망 성분**:[1]

1. **드리프트 함수 $$f(t, z(t); \theta)$$**: 연속 동역학을 모델링
2. **이벤트 함수 $$g(t, z(t); \phi)$$**: 이벤트 발생 조건 모델링
3. **순간 업데이트 함수 $$h(t, z'(t); \psi)$$**: 이벤트 발생 시 상태 변화 적용

***

## 3. 성능 향상 및 한계

### 3.1 성능 향상: 실험 결과

**실험 1: 스위칭 선형 동역학 시스템 (Switching Linear Dynamical System)**[1]

팬 모양 트랙을 따라 움직이는 입자를 모델링하는 문제:

| 모델 | 테스트 손실 (MSE) |
|------|-----------------|
| RNN (LSTM) | 0.261 ± 0.078 |
| Neural ODE | 0.157 ± 0.005 |
| **Neural Event ODE** | **0.093 ± 0.037** |

**Neural Event ODE가 최고 성능**: 기존 Neural ODE 대비 약 41% 개선, LSTM 대비 약 64% 개선[1]

**실험 2: 다중 물체 충돌 물리 시뮬레이션**[1]

상자 내 두 개의 탄성공 충돌 모델링:

| 모델 | @25 | @50 | @100 | ODE 복잡도@50 | 이벤트 함수 복잡도@50 |
|------|-----|-----|------|---------------|-------------------|
| RNN (LSTM) | 0.01 | 0.07 | 0.24 | — | — |
| Neural ODE | 0.00 | 0.06 | 0.18 | 3,810 | — |
| **Neural Event ODE** | 0.01 | 0.07 | 0.19 | **160** | **160** |

**효율성 극적 개선**: Neural ODE는 함수 평가 3,810회, Neural Event ODE는 총 320회(드리프트 160회 + 이벤트 160회)로 **약 95% 계산량 감소**[1]

**실험 3: 탄성공 외삽 (Figure 1)**[1]

- **Neural ODE**: 훈련 영역 내에서는 동작하지만, 외삽에서 완전 실패
- **Neural Event ODE**: 선형 모델로도 정확한 동역학 회복, 완벽한 외삽 성능

### 3.2 시간 포인트 프로세스와 재매개변수화 그래디언트

**개선 사항**: 재매개변수화 그래디언트가 REINFORCE 대비 훨씬 빠른 수렴[1]

| 방법 | 5 이벤트 수렴 속도 | 10 이벤트 수렴 속도 |
|------|-----------------|------------------|
| REINFORCE | 느린 수렴 | 매우 느린 수렴 |
| **재매개변수화 그래디언트** | **빠른 수렴** | **적절한 수렴** |

**이산 제어 응용** (Figure 4c, 4d):[1]

- HIV 동역학 모델: 재매개변수화 그래디언트가 가장 우수
- Hodgkin-Huxley 신경 동역학: **결정론적 정책이 확률론적 정책보다 더 우수한 성능**

### 3.3 현실적 한계

**1. 미니배칭 (Minibatching) 문제**[1]

이 방법의 주요 제약: 각 궤적이 서로 다른 이벤트 위치를 가질 수 있습니다. ODE 솔버는 미니배치 내 시스템의 독립성을 명시적으로 처리하지 않아서, 스파스 집계자(min/max 연산)를 사용해야 합니다. 이는 **미니배치의 한 이벤트 함수가 트리거될 때마다 전체 통합을 재시작**해야 하므로 오버헤드가 발생합니다.[1]

**2. 탈주 이벤트 경계 (Runaway Event Boundaries)**[1]

문제: 신경망 이벤트 함수가 절대 0을 지나지 않으면 어떻게 될까요? 고차원에서 신경망의 근(root)은 예측 불가능하므로 궤적이 이벤트를 만나지 않을 수 있습니다. 이 경우:

- 이벤트 함수 매개변수에 그래디언트가 없음
- 모델이 순수 Neural ODE로 퇴화

**해결책**: 이벤트 함수 매개변수를 큰 표준 편차로 초기화하면 부분적으로 완화되지만, 근본적인 해결책은 아닙니다. 임계값 기반 이벤트 함수(섹션 5)는 적분이 항상 양수이므로 덜 문제가 됩니다.[1]

**3. 이벤트 개수의 불연속성 (Discrete Number of Events)**[1]

문제: 매개변수 공간에서 작은 변화가 이벤트 개수를 급격히 변경할 수 있습니다. 이는 목적 함수의 불연속성을 초래합니다:

- 샘플링 기반 학습에서 재매개변수화 그래디언트가 미분가능성을 요구
- 이벤트 개수에 의존하는 목적 함수는 불연속

**극복 방법**: 대용 목적함수 사용(Shchur et al., 2020 참조)[1]

***

## 4. 일반화 성능 향상 가능성 (강조)

### 4.1 외삽 능력 (Extrapolation Capability)

**탈성공 예제의 깊은 의미**[1]

Figure 1에 보이듯이:
- **기존 Neural ODE**: 훈련 시간 구간에서 피팅하지만, 외삽에서 완전히 실패. 이는 비선형 ODE가 불연속적인 동작(속도 반전)을 표현할 수 없기 때문입니다.
- **Neural Event ODE**: 선형 드리프트 함수(매우 제한적)로도 정확하게 동역학을 회복하고 완벽하게 외삽합니다.

**왜 일반화가 개선되는가**[1]

신경망이 연속 동역학만 학습하는 것이 아니라 **이벤트 발생의 사실적 조건**을 명시적으로 모델링하기 때문입니다. 이는 분포 외(out-of-distribution) 입력에 대한 모델의 구조적 편향(inductive bias)을 강화합니다.

### 4.2 스위칭 동역학 시스템에서의 일반화

**훈련-테스트 불일치 극복**[1]

- 훈련: 100개의 짧은 궤적(길이 4 → 50개 이산화 스텝)
- 테스트: 25개의 훨씬 긴 궤적(길이 12 → 150개 이산화 스텝)

즉, 테스트 궤적이 훈련보다 **3배 더 깁니다**. Neural Event ODE는 여전히 매우 낮은 테스트 손실(0.093)을 유지하여 **명시적인 스위칭 조건 학습이 시간 영역에서의 외삽을 가능**하게 함을 보여줍니다.[1]

### 4.3 물리 시뮬레이션에서의 구조적 이해

**충돌 모델링의 이점**[1]

Figure 3에서 보이듯이:
- RNN과 기존 Neural ODE는 손실을 줄이기 위해 "물리적으로 부자연스러운" 행동(공이 공중에 떠 있음)을 학습
- Neural Event ODE는 실제 충돌 조건을 명시적으로 모델링하여, **더 해석 가능하고 물리적으로 타당한** 표현을 학습

이는 **모델이 데이터의 기저 구조를 이해**함을 의미하므로 분포 외 상황으로의 일반화가 더 쉽습니다.

### 4.4 효율성과 샘플 효율

**계산 복잡도 감소가 일반화를 돕는 이유**[1]

- Neural Event ODE: 함수 평가 ~320회 (160 드리프트 + 160 이벤트)
- Neural ODE: 함수 평가 ~3,810회

더 적은 계산이 필요하다는 것은:
1. 더 안정적인 수치 적분 (오차 누적 감소)
2. 더 명확한 경사 신호 (스티프 ODE의 수치 불안정성 회피)
3. 메모리 효율성 개선

이는 **더 좋은 그래디언트 신호 → 더 나은 일반화**를 의미합니다.[1]

### 4.5 재매개변수화 그래디언트의 분산 감소

**시간 포인트 프로세스에서의 이점**[1]

Figure 4(a), (b)에서 재매개변수화 그래디언트는:
- 더 빠른 수렴
- 더 낮은 손실 변동성

더 낮은 분산의 그래디언트는 훈련 과정이 더 안정적이고 일반화 갭을 줄이는 데 도움됩니다.[1]

---

## 5. 연구에 미치는 영향과 고려사항

### 5.1 이론적 기여

**기본 패러다임 확장**[1]

이 논문은 Neural ODE 프레임워크를 **불연속적 시스템**으로 확장한 첫 체계적 접근입니다. 이를 통해:

1. 미분가능성과 불연속성의 경계를 흐릿하게 함
2. 역모드 자동미분이 더 일반적인 시스템 클래스에 적용 가능함을 증명
3. 물리 시뮬레이션, 점프 프로세스, 의사결정 모델 등 새로운 영역의 기초 제공

### 5.2 실천적 고려사항

**앞으로 연구 시 주의할 점**:[1]

1. **초기화 전략 중요성**: 탈주 이벤트 경계를 피하려면 이벤트 함수를 큰 표준 편차로 초기화해야 합니다. 더 정교한 초기화 기법 개발 필요.[1]

2. **대규모 미니배칭**: 현재 미니배칭 오버헤드는 병렬 계산 효율을 제한합니다. GPU 메모리 활용을 개선하는 새로운 배치 전략 필요.[1]

3. **고차원 확장성**: 고차원 문제에서 이벤트 함수의 근을 찾기가 어려워질 수 있습니다. 적응적 샘플링이나 보조 신경망을 통한 "사전(prior)" 학습이 도움될 수 있습니다.

4. **목적 함수 설계**: 이벤트 개수가 이산적이므로, 연속 프록시 목적 함수를 설계하는 것이 중요합니다. 예를 들어 soft 이벤트 탐지를 고려할 수 있습니다.

5. **다양한 이벤트 함수 클래스 탐색**: 
   - 상태 종속 이벤트(섹션 4): 일반적이지만 학습이 어려움
   - 임계값 기반 이벤트(섹션 5): 안정적이지만 표현력 제한

### 5.3 응용 전망

**의료 이미징과의 연관성** (당신의 배경 고려)

이 방법이 유망할 수 있는 영역:

1. **X선 이미지 동역학 모델링**: 뼈 억제 후 조직 경계의 급격한 변화를 명시적으로 모델링
2. **이상 탐지**: 정상적인 신체 반응의 "이벤트"(예: 기침, 심박)를 감지하는 신경망
3. **다중 장기 상호작용**: 기관 간 불연속적 신호 변환을 모델링

### 5.4 거시적 영향

**깊은 학습의 물리-인정 방향**[1]

이 연구는:
- 물리 법칙(차등 방정식)의 엄격성과 신경망의 유연성의 조화
- 해석 가능한 머신러닝 방향으로의 발전 (각 이벤트의 명시적 표현)
- 강화 학습, 제어 이론, 통계 학습 간 다리 역할

***

## 결론

Neural Event ODE는 **상태 불연속성의 명시적 모델링을 통해 기존 Neural ODE의 표현 능력을 비약적으로 확장**합니다. 특히 외삽, 물리적 해석 가능성, 계산 효율성 측면에서 현저한 개선을 보이며, 시간 포인트 프로세스와 이산 제어라는 새로운 응용 영역을 개척합니다.[1]

다만 **미니배칭, 탈주 경계, 불연속 목적 함수** 등의 실천적 한계를 극복하려면 추가 연구가 필요합니다. 앞으로의 연구는 이러한 제약을 해결하면서도 더 높은 차원의 문제로 확장하고, 도메인-특화 이벤트 함수 설계 기법을 개발하는 방향으로 나아가야 할 것입니다.[1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/c73a9339-6e14-4b32-81ac-8daeab7747ab/2011.03902v4.pdf)
