# TS2Vec: Towards Universal Representation of Time Series

### 1. 핵심 주장과 주요 기여

**TS2Vec**는 시계열 데이터의 **임의의 의미 수준(arbitrary semantic level)**에서 보편적 표현을 학습하는 첫 번째 통합 프레임워크입니다. 기존 방법들이 인스턴스 수준의 표현만 학습하거나 특정 의미 수준에만 초점을 맞춘 반면, TS2Vec은 타임스탬프 수준부터 전체 시계열 수준까지 다양한 세밀도(granularity)의 표현을 동시에 학습합니다.[1]

주요 기여는 다음과 같습니다:[1]

- **계층적 대조 학습(Hierarchical Contrasting)**: 인스턴스 차원과 시간 차원 모두에서 양성/음성 샘플을 구별하여 다중 스케일의 문맥 정보를 포착합니다.
- **문맥 일관성(Contextual Consistency)**: 증강된 문맥 뷰에서 동일 타임스탐프의 표현을 양성 쌍으로 선택하는 새로운 전략을 제안합니다.
- **보편적 적용성**: 분류, 예측, 이상 탐지 등 다양한 시계열 작업에서 SOTA 성능을 달성합니다.

***

### 2. 문제 정의 및 해결 방법

#### 2.1 기존 방법의 한계

기존 시계열 표현 학습 방법들은 세 가지 주요 문제를 가지고 있습니다:[1]

1. **세밀도 부재**: 인스턴스 수준 표현은 예측이나 이상 탐지 같은 세밀한 작업에 부족합니다.
2. **다중 스케일 특징 미흡**: 시계열의 다양한 해상도에서 문맥 정보를 구분하지 못합니다.
3. **부적절한 귀납적 편향(Inductive Bias)**: 컴퓨터 비전 및 NLP에서 차용한 변환 불변성(transformation-invariance)이 시계열에 항상 타당하지 않습니다. 예를 들어, 크롭 연산(cropping)은 시계열의 분포와 의미를 변경할 수 있습니다.[1]

#### 2.2 모델 구조

TS2Vec의 인코더는 세 가지 핵심 구성요소로 이루어져 있습니다:[1]

- **입력 투사층(Input Projection Layer)**: 각 타임스탐프 $$t$$의 관측값 $$x_{i,t}$$을 고차원 잠재 벡터 $$z_{i,t}$$로 매핑합니다.
  
  $$z_{i,t} = Wx_{i,t} + b$$

- **타임스탑 마스킹(Timestamp Masking)**: 잠재 벡터에서 베르누이 분포($$p=0.5$$)로 무작위 타임스탐프를 마스킹합니다. 원본 입력이 아닌 잠재 벡터에 마스킹하는 이유는 시계열의 값 범위가 무한할 수 있기 때문입니다.[1]

- **확장된 CNN 모듈(Dilated CNN)**: 10개의 잔여 블록으로 구성되며, 각 블록 $$l$$의 확장 인자는 $$2^l$$입니다. 이는 서로 다른 도메인에서 큰 수용장(receptive field)을 가능하게 합니다.[1]

#### 2.3 문맥 일관성 전략

**새로운 양성 쌍 선택 전략**:[1]

TS2Vec은 기존 방법들(부분 시계열 일관성, 시간 일관성, 변환 일관성)의 문제점을 해결합니다. 예를 들어:

- **부분 시계열 일관성**: 수준 이동(level shifts)이 발생하면 실패
- **시간 일관성**: 이상이 발생하면 거짓 양성 쌍 생성

TS2Vec의 **문맥 일관성**은 두 증강된 문맥에서 동일 타임스탐프의 표현을 양성 쌍으로 설정합니다:[1]

- **타임스탐프 마스킹**: 무작위로 타임스탐프를 마스킹하여 새로운 문맥 뷰 생성
- **무작위 크롭**: 두 겹치는 시간 구간 $$[a_1, b_1]$$, $$[a_2, b_2]$$를 샘플링하여 겹치는 구간 $$[a_2, b_1]$$에서 일관성을 강제합니다.

이 전략의 이점은 시계열의 크기를 변경하지 않으면서도 견고한 표현을 학습합니다.[1]

#### 2.4 계층적 대조 손실 함수

**시간 대조 손실(Temporal Contrastive Loss)**:[1]

$$\ell^{(i,t)}_{\text{temp}} = -\log \frac{\exp(r_{i,t} \cdot r'_{i,t})}{\sum_{t' \in \Omega} \left[\exp(r_{i,t} \cdot r'_{i,t'}) + \mathbb{1}[t \neq t'] \exp(r_{i,t} \cdot r_{i,t'})\right]}$$

여기서 $$\Omega$$는 두 부분 시계열의 겹치는 영역의 타임스탐프 집합이고, 동일 타임스탐프의 표현을 양성으로, 다른 타임스탐프의 표현을 음성으로 취급합니다.[1]

**인스턴스 대조 손실(Instance-wise Contrastive Loss)**:[1]

$$\ell^{(i,t)}_{\text{inst}} = -\log \frac{\exp(r_{i,t} \cdot r'_{i,t})}{\sum^B_{j=1}\left(\exp(r_{i,t} \cdot r'_{j,t}) + \mathbb{1}[i \neq j] \exp(r_{i,t} \cdot r_{j,t})\right)}$$

배치 내의 다른 시계열에서 동일 타임스탐프의 표현을 음성 샘플로 사용합니다.[1]

**통합 손실 함수**:[1]

$$L_{\text{dual}} = \frac{1}{NT} \sum_i \sum_t \left(\ell^{(i,t)}_{\text{temp}} + \ell^{(i,t)}_{\text{inst}}\right)$$

계층적 대조 손실은 최대 풀링을 통해 재귀적으로 계산됩니다. 표현 길이가 1이 될 때까지 반복하며, 각 수준에서 계산된 손실을 합산한 후 평균을 구합니다.[1]

---

### 3. 성능 향상

#### 3.1 시계열 분류

TS2Vec은 **125개 UCR 데이터셋에서 평균 2.4% 정확도 향상**, **29개 UEA 데이터셋에서 3.0% 향상**을 달성했습니다:[1]

| 데이터셋 | TS2Vec | T-Loss | TS-TCC | TNC | DTW |
|---------|--------|--------|--------|-----|-----|
| UCR (125개) | 0.830 | 0.806 | 0.757 | 0.761 | 0.727 |
| UEA (29개) | 0.712 | 0.675 | 0.682 | 0.677 | 0.650 |

훈련 시간도 가장 짧아 0.9시간으로 기존 방법들(228.4시간 TNC, 38시간 T-Loss)보다 훨씬 효율적입니다.[1]

#### 3.2 시계열 예측

선형 회귀를 타임스탐프 표현 위에 적용하여 예측을 수행합니다. TS2Vec은 **MSE에서 32.6% 감소**(단변량 설정)와 **28.2% 감소**(다변량 설정)를 달성했습니다:[1]

- ETTh1 데이터셋 (H=24): MSE 0.039 (Informer: 0.098)
- Electricity 데이터셋 (평균): MSE 0.209 (Informer: 0.310)

한번 학습된 표현을 다양한 예측 지평(H)에 직접 적용 가능하여 보편성을 입증합니다.[1]

#### 3.3 이상 탐지

**정상 설정**에서 Yahoo 데이터셋 F1 스코어 **0.745** (SR: 0.563), KPI 데이터셋 **0.677** (SR: 0.622)을 달성:[1]

이상 점수는 마스킹 입력과 정상 입력의 표현 거리로 정의됩니다:

$$\alpha_t = \|r^u_t - r^m_t\|_1$$

***

### 4. 일반화 성능 향상 메커니즘

#### 4.1 계층적 대조 학습의 역할

다양한 세밀도 수준에서 대조를 수행함으로써 모델은 **다중 스케일의 문맥 정보**를 포착합니다. 이는 기존 방법들(T-Loss는 인스턴스 수준만, TS-TCC는 타임스탐프 수준만)과 달리 포괄적인 표현을 학습하게 합니다.[1]

**절제 연구** 결과: 계층적 대조 제거 시 정확도가 **1.7% 감소**했습니다.[1]

#### 4.2 문맥 일관성의 강건성

시계열의 분포 변화에 대한 강건성:

- 수준 이동 시에도 모델은 다른 패턴을 구분
- 이상 점프 발생 시에도 거짓 양성 쌍 생성 방지

기존의 부분 시계열 일관성으로 대체 시 정확도 **4.9% 감소**, 시간 일관성으로 대체 시 **2.2% 감소**.[1]

#### 4.3 누락 데이터에 대한 견고성

**중요한 발견**: TS2Vec은 50% 누락률에서도 거의 동일한 성능을 유지:[1]

- StarLightCurves: 2.1% 감소
- UWaveGestureLibraryAll: 거의 0% 감소

이는 타임스탐프 마스킹과 계층적 대조가 불완전한 문맥에서 표현을 추론하는 능력을 제공하기 때문입니다.[1]

#### 4.4 주요 구성요소의 효과

| 구성요소 | 정확도 감소 |
|---------|-----------|
| 시간 대조 제거 | 1.0% ↓ |
| 인스턴스 대조 제거 | 0.5% ↓ |
| 계층적 대조 제거 | 1.7% ↓ |
| 무작위 크롭 제거 | 2.1% ↓ |
| 타임스탐프 마스킹 제거 | 0.9% ↓ |

모든 구성요소가 필수적이며, 특히 **무작위 크롭이 표현 붕괴(representation collapse)를 방지**합니다.[1]

***

### 5. 모델의 한계

#### 5.1 하이퍼파라미터 민감도

비지도 학습이므로 조기 중단(early stopping)이 불가능하여 **고정된 하이퍼파라미터 사용**:[1]
- 배치 크기 변화에 따른 개별 데이터셋 성능 차이 존재
- 표현 차원 고정(320)으로 인한 제한

#### 5.2 모델 선택의 제약

**백본 아키텍처 제약**:[1]
- Transformer 사용 시 정확도 **18.2% 감소**
- LSTM 사용 시 **5.0% 감소**

확장된 CNN의 선택이 중요하지만, 다른 아키텍처의 최적화 가능성이 탐색되지 않음.[1]

#### 5.3 크롭 전략의 고정

무작위 크롭의 겹침 비율이나 전략 조정 시 최적화 가능성 미검토.[1]

#### 5.4 극장기(Very Long) 시계열 처리

3,000개 타임스탐프로 사전 분할하므로 매우 긴 시계열에서의 성능이 명확하지 않습니다.[1]

***

### 6. 연구에 미치는 영향과 향후 고려사항

#### 6.1 학계적 영향

TS2Vec은 **시계열 표현 학습의 보편성** 개념을 정립했습니다. 단일 프레임워크가 분류, 예측, 이상 탐지 등 다양한 작업을 처리할 수 있음을 입증했습니다.[1]

#### 6.2 실무 적용 가능성

- **일회 학습, 다중 작업 활용**: 표현을 한번 학습하면 다양한 하위 작업에 재사용 가능
- **높은 계산 효율**: 훈련 시간이 매우 짧음 (0.9시간)
- **누락 데이터 강건성**: 실제 산업 데이터의 결측값 문제 해결

#### 6.3 향후 연구 방향

**1. 도메인 특화 최적화**
- 각 도메인(금융, 에너지, 의료 등)에 맞는 하이퍼파라미터 튜닝 메커니즘 개발
- 의존하지 않은 조기 중단 기준 모색

**2. 아키텍처 개선**
- 다른 백본(GNN, 하이브리드 모델) 탐색
- 시계열의 비선형성을 더 잘 포착하는 구조 개발

**3. 계층적 학습의 확장**
- 더 세밀한 의미 수준 추가
- 개념 수준의 계층 구조 학습

**4. 멀티모달 시계열**
- 이미지, 텍스트 등과 결합된 시계열 표현 학습
- 교차 모달 일관성 추가

**5. 약한 지도 학습(Weak Supervision) 통합**
- 제한된 레이블 활용으로 표현 개선
- 자기 지도 + 약한 지도 하이브리드 방식

**6. 분포 이동(Distribution Shift) 대응**
- 시계열의 분포가 변할 때 표현 적응 메커니즘
- 도메인 일반화 기법 통합

#### 6.4 연구자 고려사항

**표현 학습 설계 시**:
- 시계열의 고유한 특성(분포 변화, 비정상성)을 고려한 대조 손실 설계
- 변환 불변성 가정의 타당성 검증
- 다중 의미 수준 동시 학습의 필요성 평가

**평가 프로토콜**:
- 단순 선형 프로브를 넘어 다양한 하위 작업 설계
- 전이 학습 성능 평가의 중요성

**실무 배포 시**:
- 누락 데이터 처리 메커니즘 확인
- 계산 효율성과 성능의 트레이드오프 분석

***

### 결론

TS2Vec은 시계열 표현 학습의 **패러다임 전환**을 제시합니다. 기존의 특정 작업을 위한 표현이 아닌, **다양한 의미 수준의 보편적 표현**을 학습하는 첫 통합 프레임워크로서, 문맥 일관성과 계층적 대조라는 새로운 개념으로 시계열의 본질적 특성을 포착합니다. 특히 누락 데이터에 대한 강건성과 계산 효율성은 실제 산업 환경에서의 적용 가능성을 높입니다. 앞으로의 연구는 도메인별 최적화, 멀티모달 확장, 그리고 더욱 세밀한 의미 수준의 표현 학습에 초점을 맞춰야 할 것입니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/1b91846e-b360-4305-a2bf-3eda67abe567/2106.10466v4.pdf)
