# Towards Spatio-Temporal Aware Traffic Time Series Forecasting

## 1. 핵심 주장과 주요 기여

본 논문은 교통 시계열 예측(traffic time series forecasting)에서 기존의 **시공간 불가지론적(spatio-temporal agnostic)** 모델의 한계를 극복하기 위해 **시공간 인식(spatio-temporal aware)** 모델링 프레임워크를 제안합니다.[1]

**핵심 주장**

서로 다른 위치의 시계열은 고유한 패턴을 가지며, 동일한 시계열 내에서도 시간대에 따라 패턴이 변화합니다. 기존 딥러닝 모델들(RNN, TCN, Attention)은 모든 위치와 시간대에 동일한 모델 파라미터를 사용하여 이러한 동적 특성을 포착하지 못합니다.[1]

**주요 기여**

- **시공간 인식 파라미터 생성 네트워크**: 위치별(location-specific)이고 시간 변화하는(time-varying) 모델 파라미터를 생성하여 시공간 불가지론적 모델을 시공간 인식 모델로 전환합니다.[1]

- **효율적인 윈도우 어텐션(Window Attention)**: 프록시(proxy) 메커니즘을 활용하여 어텐션의 복잡도를 $$O(H^2)$$에서 $$O(H)$$로 감소시켜 선형 복잡도를 달성합니다.[1]

- **모델 불가지론적 접근**: 제안된 방법은 RNN, TCN, Attention 등 다양한 유형의 예측 모델에 적용 가능하며, 추가적인 메타 정보(POI 등) 없이 순수하게 데이터 기반으로 작동합니다.[1]

- **우수한 실증 결과**: 4개의 교통 시계열 데이터셋(PEMS03, PEMS04, PEMS07, PEMS08)에서 최신 기법들을 정확도와 효율성 측면에서 모두 능가합니다.[1]

## 2. 문제, 제안 방법, 모델 구조, 성능 및 한계

### 2.1 해결하고자 하는 문제

**문제 정의**

$$N$$개의 센서로부터 수집된 다변량 시계열 $$\mathbf{X} \in \mathbb{R}^{N \times T \times F}$$가 주어졌을 때, 시간 $$t$$에서 과거 $$H$$개의 타임스탬프를 기반으로 미래 $$U$$개의 타임스탬프를 예측하는 함수를 학습합니다:[1]

$$
\mathcal{F}_\phi(\mathbf{x}_{t-H+1}, \ldots, \mathbf{x}_{t-1}, \mathbf{x}_t) = (\hat{\mathbf{x}}_{t+1}, \hat{\mathbf{x}}_{t+2}, \ldots, \hat{\mathbf{x}}_{t+U})
$$

**핵심 도전 과제**

1. **공간적 다양성**: 서로 다른 위치의 시계열은 고유한 패턴을 가집니다. 예를 들어, 같은 도로에 배치된 센서들은 유사한 패턴을 보이지만, 다른 도로의 센서들과는 다른 패턴을 보입니다.[1]

2. **시간적 변동성**: 동일한 시계열 내에서도 평일과 주말, 출퇴근 시간대와 비출퇴근 시간대에 따라 패턴이 변화합니다.[1]

3. **기존 모델의 한계**: 기존 모델들은 모든 위치와 시간대에 동일한 파라미터(예: attention의 projection matrices $$\mathbf{Q}, \mathbf{K}, \mathbf{V}$$)를 사용하여 "평균적인" 패턴만 학습하게 됩니다.[1]

### 2.2 제안하는 방법 (수식 포함)

#### 2.2.1 시공간 인식 확률 변수 학습

**확률 잠재 변수 설계**

각 위치 $$i$$와 시간 $$t$$에 대한 고유한 확률 잠재 변수 $$\Theta_t^{(i)}$$를 다음과 같이 정의합니다:[1]

$$
\Theta_t^{(i)} = z^{(i)} + z_t^{(i)}
$$

여기서:
- $$z^{(i)}$$: 공간 인식 확률 변수(spatial-aware stochastic variable) - 위치 $$i$$의 가장 일반적이고 두드러진 패턴을 포착합니다.
- $$z_t^{(i)}$$: 시간 적응 변수(temporal adaptation variable) - 시간 $$t$$에서의 패턴 변화를 수용합니다.

**공간 인식 변수**

$$z^{(i)}$$는 다변량 가우시안 분포를 따르며, 평균 $$\mu^{(i)}$$와 공분산 행렬 $$\Sigma^{(i)}$$는 직접 학습 가능한 파라미터입니다:[1]

$$
z^{(i)} \sim \mathcal{N}(\mu^{(i)}, \Sigma^{(i)})
$$

**시간 적응 변수**

$$z_t^{(i)}$$는 변분 인코더(variational encoder) $$\mathcal{E}_\psi$$를 통해 생성됩니다:[1]

$$
\mu_t^{(i)}, \Sigma_t^{(i)} = \mathcal{E}_\psi(\mathbf{x}_{t-H+1}^{(i)}, \ldots, \mathbf{x}_t^{(i)})
$$

$$
z_t^{(i)} \sim \mathcal{N}(\mu_t^{(i)}, \Sigma_t^{(i)})
$$

#### 2.2.2 모델 파라미터 디코딩

디코더 $$\mathcal{D}_\omega$$를 사용하여 확률 잠재 변수를 모델 파라미터로 변환합니다:[1]

$$
\phi_t^{(i)} = \mathcal{D}_\omega(\Theta_t^{(i)})
$$

어텐션의 경우, $$\phi_t^{(i)} = \{\mathbf{Q}_t^{(i)}, \mathbf{K}_t^{(i)}, \mathbf{V}_t^{(i)}\}$$이며, 시공간 인식 어텐션은 다음과 같이 정의됩니다:[1]

$$
\mathbf{h} = \text{Att}(\mathbf{x} \mid \phi_t^{(1)}, \ldots, \phi_t^{(N)}) = \left[\sigma\left(\frac{(\mathbf{x}^{(i)}\mathbf{Q}_t^{(i)})(\mathbf{x}^{(i)}\mathbf{K}_t^{(i)})^T}{\sqrt{d}}\right)(\mathbf{x}^{(i)}\mathbf{V}_t^{(i)})\right]_{i=1}^N
$$

#### 2.2.3 윈도우 어텐션 메커니즘

**복잡도 감소 전략**

입력 시계열을 $$W = H/S$$개의 윈도우로 분할하고, 각 윈도우에 대해 $$p$$개의 학습 가능한 프록시 $$\mathbf{P} \in \mathbb{R}^{W \times N \times p \times d}$$를 도입합니다.[1]

윈도우 $$w$$에서의 어텐션:

$$
\mathbf{h}_w^{(i)} = \text{Att}(\mathbf{x}_w^{(i)} \mid \mathbf{P}_w^{(i)}, \mathbf{K}_t^{(i)}, \mathbf{V}_t^{(i)}) = \left[\sigma\left(\frac{\mathbf{P}_{w,j}^{(i)}(\mathbf{x}_w^{(i)}\mathbf{K}_t^{(i)})^T}{\sqrt{d}}\right)(\mathbf{x}_w^{(i)}\mathbf{V}_t^{(i)})\right]_{j=1}^p
$$

**프록시 집계**

각 윈도우의 $$p$$개 프록시를 하나의 표현으로 집계합니다:[1]

$$
\mathbf{A}_w^{(i)} = f_2(\mathbf{W}_2(f_1(\mathbf{W}_1 \mathbf{h}_w^{(i)})))
$$

$$
\hat{\mathbf{h}}_w^{(i)} = \sum_{j=1}^p \mathbf{A}_{w,j}^{(i)} \odot \mathbf{h}_{w,j}^{(i)}
$$

**윈도우 간 정보 전달**

이전 윈도우의 출력을 현재 윈도우의 프록시와 융합합니다:[1]

$$
\mathbf{P}_{w,j}^{(i)} = \vartheta(\hat{\mathbf{h}}_{w-1}^{(i)} \parallel \mathbf{P}_{w,j}^{(i)}) \quad \forall j \in [1, p]
$$

#### 2.2.4 손실 함수

$$
\arg\min_{\psi, \omega, \{\mu^i\}, \{\Sigma^i\}} \sum_t \mathcal{H}(\mathbf{X}_{t+1,\ldots,t+U}, \hat{\mathbf{X}}_{t+1,\ldots,t+U}) + \alpha D_{KL}[\Theta_t \parallel \hat{p}]
$$

여기서 첫 번째 항은 Huber 손실:[1]

$$
\mathcal{H}(\mathbf{X}_U, \hat{\mathbf{X}}_U) = \begin{cases}
\frac{1}{2}(\mathbf{X}_U - \hat{\mathbf{X}}_U)^2 & |\mathbf{X}_U - \hat{\mathbf{X}}_U| \leq \delta \\
\delta(|\mathbf{X}_U - \hat{\mathbf{X}}_U| - \frac{1}{2}\delta) & \text{otherwise}
\end{cases}
$$

두 번째 항은 KL 발산 정규화로, 사전 분포 $$\hat{p} = \mathcal{N}(0, \mathbf{I})$$와의 차이를 최소화합니다.[1]

### 2.3 모델 구조

**전체 아키텍처**

1. **인코더 $$\mathcal{E}_\psi$$**: 3층 fully-connected network (32 neurons, ReLU 활성화)로 16차원 가우시안 분포의 파라미터 생성[1]

2. **디코더 $$\mathcal{D}_\omega$$**: 3층 fully-connected network (16, 32, 5 neurons)로 projection matrices 생성[1]

3. **ST-WA 레이어**: 여러 층의 Spatio-Temporal Aware Window Attention을 스택:
   - 각 레이어는 고유한 프록시 텐서 $$\mathbf{P}$$ 보유
   - 다층 구조로 계층적 표현 학습[1]

4. **센서 상관관계 어텐션**: 윈도우 내 다른 센서 간 상호작용 모델링:

$$
B(\hat{\mathbf{h}}_w^{(i)}, \hat{\mathbf{h}}_w^{(j)}) = \frac{e^{\theta_1(\hat{\mathbf{h}}_w^{(i)})^T \theta_2(\hat{\mathbf{h}}_w^{(j)})}}{\sum_{j=1}^N e^{\theta_1(\hat{\mathbf{h}}_w^{(i)})^T \theta_2(\hat{\mathbf{h}}_w^{(j)})}}
$$

5. **예측기(Predictor)**: 2층 fully-connected network (각 512 neurons, ReLU 활성화)로 최종 예측 생성[1]

**복잡도 분석**

- 기존 self-attention: $$\Theta(LH^2)$$ ($$L$$개 레이어)
- 윈도우 어텐션: $$\Theta(H)$$ (선형 복잡도)
- 파라미터 수: 순진한 접근은 $$O(N \times d^2)$$, 제안 방법은 $$O(N \times k) + O(k \times m_1 + m_1 \times m_2 + m_2 \times d^2)$$[1]

### 2.4 성능 향상

**전체 정확도 (H=12, U=12)**

PEMS04 데이터셋 기준:[1]
- **ST-WA**: MAE=19.06, MAPE=12.52%, RMSE=31.02
- AGCRN (최고 베이스라인): MAE=19.83, MAPE=12.97%, RMSE=32.26
- 개선율: MAE 약 3.9%, MAPE 약 3.5%, RMSE 약 3.8%

**장기 예측 (H=72, U=72)**

PEMS04 데이터셋 기준:[1]
- **ST-WA**: MAE=23.54, MAPE=16.52%, RMSE=36.87
- AGCRN: MAE=57.41, MAPE=47.40%, RMSE=86.02 (메모리 부족 문제 발생)
- 개선율: MAE 약 59%, MAPE 약 65%, RMSE 약 57%

**효율성**

- PEMS04에서 H=120일 때, ST-WA는 다른 베이스라인 대비 유사하거나 더 낮은 런타임을 보이며, EnhanceNet 대비 약 3배 빠릅니다.[1]
- 메모리 사용량: SA(23.94GB) 대비 ST-WA(8.14GB)로 약 65% 감소.[1]

**모델 불가지론 검증**

GRU와 Attention에 ST-aware 파라미터 생성 적용 시:[1]
- GRU+ST: 기본 GRU 대비 MAE 약 6.5% 개선
- ATT+ST: 기본 ATT 대비 MAE 약 10.8% 개선

### 2.5 한계

**명시된 한계**

1. **가우시안 분포 가정**: 확률 잠재 변수가 가우시안 분포를 따른다고 가정하며, 이는 모든 교통 패턴에 적합하지 않을 수 있습니다. 향후 연구에서는 normalizing flows 등을 활용한 비가우시안 확률 변수 탐색이 필요합니다.[1]

2. **병렬화 미탐색**: 제안 방법의 병렬화 가능성에 대한 연구가 부족합니다.[1]

**암시적 한계**

3. **계산 비용 증가**: ST-aware 파라미터 생성으로 인해 WA 대비 훈련 시간이 약 1.65배 증가합니다 (PEMS04: WA 13.25초/epoch vs. ST-WA 21.93초/epoch).[1]

4. **하이퍼파라미터 민감성**: 프록시 개수 $$p$$, 윈도우 크기 $$S$$, 잠재 변수 차원 $$k$$ 등 여러 하이퍼파라미터에 대한 그리드 서치가 필요합니다.[1]

5. **외부 정보 미활용**: POI, 날씨, 이벤트 등의 외부 정보를 활용하지 않아, 비정상적인 교통 패턴(사고, 행사 등)에 대한 예측 성능이 제한될 수 있습니다.

## 3. 일반화 성능 향상 관련 내용

### 3.1 확률적 잠재 변수의 일반화 능력

**확률 변수의 우수성**

논문은 확률 변수가 결정론적 변수보다 더 나은 일반화 성능과 표현력을 가진다고 주장합니다. 실험 결과, 확률적 ST-WA가 결정론적 변형보다 우수한 성능을 보였습니다:[1]

- 확률적 ST-WA: MAE=19.06, MAPE=12.52%
- 결정론적 ST-WA: MAE=19.32, MAPE=12.72%[1]

**변분 인코더의 역할**

변분 인코더는 입력 데이터의 분포를 포착하여 훈련 중 보지 못한 케이스에 대해 더 나은 일반화를 제공합니다. 이는 $$z_t^{(i)}$$가 과거 $$H$$개 타임스탬프의 조건부 분포를 모델링하기 때문입니다.[1]

### 3.2 KL 정규화를 통한 과적합 방지

**정규화 효과**

KL 발산 정규화 항은 학습된 사후 분포를 사전 분포 $$\mathcal{N}(0, \mathbf{I})$$에 가깝게 만들어 과적합을 방지합니다:[1]

- 정규화 포함: MAE=19.06, MAPE=12.52%
- 정규화 제거: MAE=19.23, MAPE=12.62%[1]

이는 모델이 훈련 데이터에 과도하게 맞춰지는 것을 방지하고, 보이지 않는 패턴에 대한 일반화 능력을 향상시킵니다.

### 3.3 장기 의존성 포착

**긴 히스토리 윈도우 실험**

$$H$$를 12에서 36, 120으로 증가시킨 실험에서 ST-WA는 지속적인 성능 향상을 보였으나, 다른 베이스라인은 개선되지 않거나 오히려 성능이 저하되었습니다:[1]

PEMS04 기준:
- H=12: ST-WA MAE=19.06
- H=36: ST-WA MAE=18.90 (개선)
- H=120: ST-WA MAE=18.90 (유지)

반면 AGCRN:
- H=12: MAE=19.38
- H=36: MAE=19.69 (악화)
- H=120: MAE=19.87 (악화)[1]

이는 ST-WA가 장기 의존성을 더 잘 포착하며, 다양한 시간 스케일의 패턴에 일반화할 수 있음을 시사합니다.

### 3.4 시각화를 통한 일반화 검증

**시간적 패턴 포착**

t-SNE 시각화를 통해 projection matrices $$\phi_t^{(i)}$$가 다양한 시간 윈도우에서 서로 다른 패턴을 포착함을 확인했습니다. 특히:[1]
- 빨간색 클러스터: 상승 추세 패턴 특화
- 보라색 클러스터: 하강 추세 패턴 특화

이는 모델이 시간에 따른 다양한 패턴에 적응하며, 훈련 중 보지 못한 새로운 추세 패턴에도 일반화할 수 있음을 의미합니다.

**공간적 패턴 구분**

$$z^{(i)}$$의 t-SNE 시각화에서 같은 도로의 센서들이 클러스터를 형성하며, 반대 방향 도로의 센서들은 구분됨을 확인했습니다. 이는 모델이:[1]
- 지리적 근접성뿐만 아니라 교통 흐름의 방향성까지 학습
- 새로운 센서 위치에 대한 일반화 가능성 시사

### 3.5 데이터셋 간 성능 일관성

ST-WA는 4개의 서로 다른 PEMS 데이터셋(PEMS03, 04, 07, 08)에서 일관되게 최고 또는 차상위 성능을 달성했습니다:[1]

- PEMS03: 12개 메트릭 중 10개에서 최고
- PEMS04: 모든 메트릭에서 최고
- PEMS07: 모든 메트릭에서 최고
- PEMS08: 모든 메트릭에서 최고

이는 제안 방법이 다양한 교통 네트워크 특성(센서 수, 지역, 기간)에 일반화할 수 있음을 입증합니다.

### 3.6 모델 불가지론적 일반화

ST-aware 파라미터 생성 메커니즘이 다양한 기본 모델(GRU, Attention)에 적용되어 일관되게 성능을 향상시켰습니다. 이는:[1]
- 제안 방법이 특정 모델 구조에 국한되지 않음
- 향후 새로운 아키텍처에도 적용 가능한 일반적인 프레임워크임을 시사

## 4. 향후 연구에 미치는 영향과 고려사항

### 4.1 향후 연구에 미치는 영향

**시공간 모델링 패러다임 전환**

본 논문은 시계열 예측에서 "하나의 모델이 모든 상황에 적합하다"는 전통적 가정에 도전하며, 위치별·시간별 적응적 파라미터의 중요성을 입증했습니다. 이는 다음과 같은 연구 방향에 영향을 미칠 것입니다:[1]

1. **다른 시공간 데이터 도메인으로 확장**
   - 기상 예측, 전력 수요 예측, 전염병 확산 예측 등에 적용 가능
   - 각 도메인의 특성에 맞춘 확률 변수 설계 필요

2. **메타 러닝과의 결합**
   - ST-aware 파라미터 생성은 메타 러닝의 task-adaptive 접근과 유사
   - Few-shot 시계열 예측, 전이 학습 등에 응용 가능

3. **설명 가능한 AI 연구**
   - 학습된 확률 변수의 시각화는 모델의 의사결정 과정 해석에 기여
   - 교통 관리자가 이해할 수 있는 설명 생성 가능

**효율적인 어텐션 메커니즘 발전**

윈도우 어텐션과 프록시 메커니즘은 Transformer의 확장성 문제를 해결하는 새로운 방향을 제시합니다:[1]

1. **장문서 처리**: 문서 요약, 긴 비디오 분석 등에 적용 가능
2. **실시간 시스템**: 선형 복잡도로 실시간 교통 관리 시스템 구현 가능
3. **모바일/엣지 디바이스**: 리소스 제약 환경에서의 딥러닝 응용

### 4.2 향후 연구 시 고려할 점

**1. 비가우시안 분포 탐색**

현재 모델은 가우시안 분포를 가정하지만, 교통 패턴은 종종 멀티모달(multi-modal)하거나 꼬리가 긴(heavy-tailed) 분포를 따를 수 있습니다. 향후 연구에서는:[1]

- **Normalizing Flows**: 복잡한 분포를 모델링할 수 있는 normalizing flows 적용
- **Mixture Models**: 가우시안 혼합 모델로 멀티모달 패턴 포착
- **실증 분석**: 다양한 분포 가정의 성능 비교 필요

**2. 외부 정보 통합**

순수 데이터 기반 접근의 장점을 유지하면서도 필요시 외부 정보를 통합하는 유연한 프레임워크 설계:

- **조건부 변분 인코더**: 날씨, 이벤트 등의 조건부 정보 통합
- **하이브리드 접근**: 기본 모델은 데이터 기반, 예외 상황은 외부 정보 활용
- **프라이버시 보호**: 개인정보 보호를 고려한 외부 정보 활용 방안

**3. 동적 그래프 구조 학습**

현재 모델은 센서 간 상관관계를 어텐션으로 모델링하지만, 명시적인 그래프 구조는 고정적입니다:

- **시간 변화하는 그래프**: 교통 상황에 따라 동적으로 변하는 그래프 구조 학습
- **인과 관계 발견**: 센서 간 인과 관계를 명시적으로 모델링
- **멀티스케일 그래프**: 지역, 도시, 국가 수준의 계층적 그래프 구조

**4. 실시간 적응 및 온라인 학습**

교통 패턴은 시간이 지남에 따라 진화하므로(예: 새로운 도로 건설, 도시 개발):

- **온라인 학습**: 새로운 데이터로 지속적으로 모델 업데이트
- **개념 표류 감지**: 패턴 변화를 자동으로 감지하고 적응
- **점진적 학습**: 이전 지식을 유지하면서 새로운 패턴 학습

**5. 확장성 및 분산 학습**

대규모 교통 네트워크(수천~수만 개 센서)로 확장 시:

- **분산 훈련**: 여러 GPU/노드에서 효율적인 훈련 전략
- **연합 학습**: 데이터 프라이버시를 보호하면서 여러 도시의 데이터 활용
- **모델 압축**: 경량화된 모델로 실시간 배포 가능성 향상

**6. 불확실성 정량화**

확률 변수를 사용하므로 예측의 불확실성을 정량화할 수 있지만, 현재 모델은 이를 충분히 활용하지 못합니다:

- **예측 구간**: 점 예측뿐만 아니라 신뢰 구간 제공
- **위험 인식 의사결정**: 불확실성을 고려한 교통 관리 전략
- **앙상블 방법**: 여러 확률 샘플을 활용한 앙상블 예측

**7. 멀티태스크 학습**

교통 예측과 관련된 여러 작업을 동시에 학습:

- **이상 탐지**: 정상 패턴 학습과 동시에 이상 상황 감지
- **결측값 보간**: 센서 고장 시 데이터 복원
- **장단기 예측**: 다양한 시간 범위의 예측 동시 수행

**8. 해석 가능성 및 신뢰성**

실제 교통 관리 시스템에 배포하기 위해서는:

- **주의 가중치 분석**: 어텐션 메커니즘의 가중치를 통한 의사결정 설명
- **반사실적 설명**: "만약 $$x$$가 달랐다면" 시나리오 분석
- **공정성 검증**: 특정 지역이나 시간대에 편향되지 않은지 검증

**9. 벤치마크 및 표준화**

연구 커뮤니티의 발전을 위해:

- **표준 벤치마크**: 다양한 도시, 규모, 조건의 표준 데이터셋 구축
- **평가 메트릭 확장**: 정확도뿐만 아니라 공정성, 견고성, 효율성 평가
- **재현 가능성**: 코드, 모델, 하이퍼파라미터의 상세한 문서화

**10. 실무 적용을 위한 시스템 설계**

연구 결과를 실제 시스템에 적용하기 위한 고려사항:

- **지연 시간**: 실시간 예측을 위한 추론 시간 최적화
- **안정성**: 입력 데이터의 노이즈나 결측에 대한 견고성
- **유지보수성**: 모델 재훈련, 업데이트, 모니터링 파이프라인 구축

본 논문은 시공간 시계열 예측의 새로운 패러다임을 제시하며, 향후 이론적 발전과 실용적 응용 모두에 중요한 기여를 할 것으로 기대됩니다.[1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/0a0a8abd-6d95-4c5a-9084-8c288beae9c9/2203.15737v3.pdf)
