# Learning the Evolutionary and Multi-scale Graph Structure for Multivariate Time Series Forecasting

## 1. 핵심 주장 및 주요 기여 요약

이 논문은 **ESG (Evolving Multi-Scale Graph Neural Network)**를 제안하며, 기존 그래프 신경망 기반 다변량 시계열 예측 방법의 두 가지 핵심 한계를 해결합니다.[1]

첫째, 기존 방법들은 **고정된 인접 행렬(fixed adjacency matrix)**을 사용하여 시변수(variables) 간의 상관관계를 모델링합니다. 그러나 실제 데이터에서 변수들 간의 상호작용은 시간에 따라 동적으로 변합니다. 예를 들어, 두 시계열이 어느 기간에는 함께 움직이지만 나중에는 상이한 방향으로 변할 수 있습니다.[1]

둘째, 변수 간의 상관관계는 **관찰 시간 스케일에 따라 다양하게 나타납니다**. 단기적으로는 강한 상관을 보이는 두 시계열이 장기적으로는 상이한 패턴을 보일 수 있습니다.[1]

**주요 기여**는 다음과 같습니다:[1]

- **진화적 그래프 구조 학습기(Evolving Graph Structure Learner, EGL)**: GRU를 활용하여 시간에 따라 변하는 인접 행렬의 계열을 생성합니다. 이는 이전 시간 단계의 그래프 구조와 현재 입력 정보를 모두 고려한 순환 방식으로 작동합니다.

- **계층적 다중 스케일 아키텍처**: 확장 합성곱(dilated convolution)을 활용하여 단기부터 장기까지의 다양한 시간 스케일에서 상관관계를 포착합니다. 각 스케일에서 별도의 진화적 그래프 구조를 학습합니다.

- **통합 예측 프레임워크**: 모든 스케일의 표현을 융합하여 최종 예측을 수행하므로, 시간 종속성과 쌍별 상관관계를 동시에 포착합니다.

---

## 2. 문제 정의, 제안 방법, 성능 향상 및 한계

### 2.1 해결하고자 하는 문제

다변량 시계열 예측에서 변수 간의 **쌍별 상관관계(pair-wise correlations)**를 정확히 모델링하는 것은 중요한 과제입니다. 기존의 CNN과 RNN 조합 방식(LSTNet, TPA-LSTM)은 전역 집계(global aggregation)로 인해 정확한 쌍별 상관을 포착하기 어렵습니다.[1]

이를 해결하기 위해 최근 연구들은 그래프 신경망(GNN)을 도입했지만, 여전히 두 가지 중요한 문제가 남아있습니다:[1]

1. **시간에 따른 그래프 구조의 진화**: 변수 간의 상호작용이 고정되어 있지 않으며 시간에 따라 변합니다.
2. **다양한 시간 스케일에서의 상관관계 차이**: 같은 변수 쌍도 단기와 장기 관점에서 상이한 상관을 가집니다.

### 2.2 제안 방법 및 수식

#### 2.2.1 전체 프레임워크

ESG의 기본 구조는 다음과 같습니다:[1]

$$ \xi^{(l)} = F_t^{(l)}(\mathbf{Z}^{(l)}) $$

$$ \mathbf{A}^{(l)} = F_a^{(l)}(\xi^{(l)}) $$

$$ \mathbf{Z}'^{(l+1)} = F_g^{(l)}(\xi^{(l)}, \mathbf{A}^{(l)}) $$

$$ \hat{\mathbf{Y}} = F_o(\mathbf{X}, \xi^{(1)}, \xi^{(2)}, \ldots, \xi^{(L)}, \mathbf{Z}^{(L+1)}) $$

여기서:
- $$F_t^{(l)}$$: $l$번째 층의 시간 합성곱 모듈
- $$F_a^{(l)}$$: $l$번째 층의 진화적 그래프 구조 학습기
- $$F_g^{(l)}$$: $l$번째 층의 그래프 합성곱 모듈
- $$\mathbf{Z}^{(l)}$$: $l$번째 층의 입력
- $$F_o$$: 최종 예측을 위한 간단한 예측기(일반적으로 완전 연결 층)

#### 2.2.2 진화적 그래프 구조 학습기 (EGL)

핵심 아이디어는 그래프 구조를 시간에 따라 진화하는 노드 표현으로부터 파생시키는 것입니다.[1]

먼저 시간 시리즈를 시간 차원으로 분할합니다:

$$ \gamma^{(m)} = \text{AGG}(\xi^{((m-1)d+1:md)}) \in \mathbb{R}^{N \times C_\xi} $$

여기서 $d$는 시간 간격, $m$은 분할된 세그먼트의 인덱스입니다.

GRU를 사용하여 진화적 노드 표현 $$\alpha^{(m)} \in \mathbb{R}^{N \times C_e}$$를 생성합니다:[1]

$$ \mathbf{r}^{(m)} = \sigma(\mathbf{W}_r[\gamma^{(m)}, \alpha^{(m-1)}] + \mathbf{b}_r) $$

$$ \mathbf{u}^{(m)} = \sigma(\mathbf{W}_u[\gamma^{(m)}, \alpha^{(m-1)}] + \mathbf{b}_u) $$

$$ \mathbf{o}^{(m)} = \mu(\mathbf{W}_o[\gamma^{(m)}, (\mathbf{r}^{(m)} \odot \alpha^{(m-1)})] + \mathbf{b}_o) $$

$$ \alpha^{(m)} = \mathbf{u}^{(m)} \odot \alpha^{(m-1)} + (1 - \mathbf{u}^{(m)}) \odot \mathbf{o}^{(m)} $$

여기서 $$\mathbf{r}^{(m)}$$는 리셋 게이트, $$\mathbf{u}^{(m)}$$는 업데이트 게이트입니다.[1]

초기 숨겨진 상태는 정적 노드 표현을 활용합니다:[1]

$$ \alpha^{(0)} = \text{MLP}_s(\alpha_s) $$

최종 인접 행렬은 다음과 같이 계산됩니다:[1]

$$ \hat{\mathbf{A}}^{(m)}_{ij} = \text{MLP}_e(\alpha^{(m)}_i, \alpha^{(m)}_j) $$

$$ \mathbf{M}^{(m)}_{ij} = \text{MLP}_m(\alpha^{(m)}_i, \alpha^{(m)}_j) $$

$$ \mathbf{A}^{(m)} = \hat{\mathbf{A}}^{(m)} \odot \sigma(\mathbf{M}^{(m)}) $$

#### 2.2.3 시간 합성곱 모듈

확장 합성곱을 사용하여 다양한 시간 스케일의 패턴을 포착합니다:[1]

$$ \mathbf{Z}_i \star \mathbf{f}^{1 \times k}(t) = \sum_{\tau=0}^{k-1} \mathbf{f}^{1 \times k}(\tau)\mathbf{Z}_i(t - s \times \tau) $$

여기서 $s$는 확장 인수(dilation factor)입니다.

여러 크기의 필터를 사용하는 확장 합성곱 층:

$$ \xi'_i = \text{concat}(\mathbf{Z}_i \star \mathbf{f}^{1 \times k_1}, \mathbf{Z}_i \star \mathbf{f}^{1 \times k_2}, \ldots, \mathbf{Z}_i \star \mathbf{f}^{1 \times k_\omega}) $$

게이팅 메커니즘을 적용합니다:[1]

$$ \xi_i = \sigma(\xi'_{1,i}) \odot \mu(\xi'_{2,i}) $$

여기서 $$\sigma$$는 시그모이드, $$\mu$$는 쌍곡탄젠트 함수입니다.

#### 2.2.4 그래프 합성곱 모듈 (Mix-Hop Propagation)

정보 전파 단계:

$$ \mathbf{H}^{(\psi)} = \beta\xi + (1-\beta)\mathbf{A}\mathbf{H}^{(\psi-1)} $$

여기서 $$\mathbf{H}^{(0)} = \xi$$, $\beta$는 원본 입력과 다른 홉(hops)으로부터의 정보 비율을 제어합니다.[1]

정보 선택 단계:

$$ \mathbf{Z}' = \sum_{\psi=0}^{\Psi} \mathbf{H}^{(\psi)}\mathbf{W}^{(\psi)} $$

여기서 $$\mathbf{W}^{(\psi)}$$는 다양한 홉에 대한 가중치를 적응적으로 할당하는 특성 선택기입니다.[1]

각 스케일의 $m$번째 시간 간격에서:

$$ \mathbf{Z}'^{(l,m)} = F_g^{(l)}(\xi^{(l,(m-1)d^{(l)}+1:md^{(l)})}, \mathbf{A}^{(l,m)}) $$

### 2.3 모델 구조

ESG의 아키텍처는 **다중 스케일 추출기(multi-scale extractor)의 계층적 스택**으로 구성됩니다. 각 층은 다음 세 가지 주요 구성 요소로 이루어집니다:[1]

1. **시간 합성곱 모듈**: 확장 합성곱을 통해 다양한 시간 스케일의 특징을 추출합니다. 하위 층은 단기 정보를, 상위 층은 장기 정보를 추출합니다.

2. **진화적 그래프 구조 학습기**: 시간 합성곱의 출력으로부터 시간에 따라 변하는 인접 행렬의 계열을 생성합니다.

3. **그래프 합성곱 모듈**: Mix-hop 전파를 통해 해당 스케일에서 학습된 그래프 구조를 사용하여 노드 정보를 전파합니다.

특히 **스케일별 독립성**이 중요합니다. 각 층에서 진화적 그래프 구조 학습기와 시간 간격 $d^{(l)}$이 서로 다르므로, 모델은 각 시간 스케일에서 독특한 진화 패턴을 학습할 수 있습니다.[1]

### 2.4 성능 향상

**단일 단계 예측 (Single-step forecasting)**:[1]

- Solar-Energy 데이터셋에서 3, 24 시간 간격에 대해 기존 최선 방법 대비 3.94%, 3.96% RSE 개선
- Electricity 데이터셋에서도 우수한 성능 달성
- 모든 지표에서 MTGNN(자체 학습 인접 행렬 사용)과 비교해서도 성능 향상

**다중 단계 예측 (Multi-step forecasting)**:[1]

- NYC-Taxi 데이터셋에서 3, 6, 12 시간 간격에 대해 RMSE를 각각 7.8%, 7.8%, 10.7% 감소
- MAE를 각각 10.7%, 10.4%, 12.0% 감소
- 예측 시간이 길어질수록 개선폭이 증가하여, 장기 예측에 특히 강함

**실험 결과 요약**:[1]

| 데이터셋 | 메트릭 | 성능 개선 |
|---------|--------|----------|
| Solar-Energy | RSE (Horizon 3) | 3.94% 향상 |
| Solar-Energy | RSE (Horizon 24) | 3.96% 향상 |
| NYC-Taxi | RMSE (Horizon 3) | 7.8% 감소 |
| NYC-Taxi | MAE (Horizon 6) | 10.4% 감소 |

### 2.5 모델의 한계 및 제약

#### 2.5.1 소규모 그래프에서의 성능 감소

Exchange-rate와 Wind 데이터셋(각각 8개, 28개 노드)에서 성능이 상대적으로 낮습니다. 저자들은 이를 "더 작은 그래프 크기와 더 적은 학습 샘플"로 인한 것으로 설명합니다. 이는 ESG가 충분한 데이터가 있을 때 진화 패턴을 학습하기에 더 적합함을 시사합니다.[1]

#### 2.5.2 계산 복잡성

각 시간 단계마다 새로운 인접 행렬을 생성해야 하고, 각 스케일에서 별도의 진화적 그래프 구조 학습기를 유지해야 합니다. 이로 인해 기존의 고정 그래프 방법보다 계산 비용이 증가합니다.[1]

#### 2.5.3 그래프 구조 해석의 어려움

논문에서 명시적으로 언급하듯이, "이 논문의 최종 목표는 시계열 예측의 정확도를 개선하는 것이지, 지상 진실 그래프 구조를 발견하거나 인과관계를 추론하는 것이 아닙니다." 따라서 학습된 그래프 구조가 실제 인과관계를 정확히 반영한다고 보장할 수 없습니다.[1]

#### 2.5.4 외부 정보 의존성

정적 노드 표현 $$\alpha_s$$를 계산할 때, 모델은 학습 데이터셋에서 추출한 특성을 사용합니다. 외부 도메인 지식이 없으면 이 표현의 품질이 제한될 수 있으며, 이는 모델의 초기화와 안정성에 영향을 미칩니다.[1]

***

## 3. 일반화 성능 향상 가능성

### 3.1 다중 스케일 표현의 시너지

절제 연구(ablation study)에서 **단일 스케일만 사용하는 경우의 성능을 비교**했을 때, ESG가 상당한 우위를 나타냅니다. 특히 흥미로운 결과는 스케일 2(중간 스케일)가 두 번째로 우수한 성능을 보인다는 것으로, "다양한 스케일의 중요도가 다르며, 스케일 레벨이 증가한다고 해서 반드시 더 나은 기여를 하지는 않음"을 시사합니다.[1]

이는 모델이 **지나치게 복잡한 장기 패턴보다는 중간 정도의 시간 스케일에서 의미 있는 상관관계를 포착**하고 있음을 의미합니다.

### 3.2 진화적 그래프 구조의 일반화

**정적 그래프 제거 실험** (Static Graph Only): 진화적 그래프 구조 학습기를 제거하고 정적 그래프만 사용한 경우, 성능이 RMSE 2.7439±0.0438로 저하되었습니다. 그러나 여전히 경쟁력 있는 결과이며, 이는 자체 학습 인접 행렬의 기본적인 효용을 보여줍니다.[1]

**스케일별 진화 패턴** (Same Pattern of Evolution): 모든 스케일에서 동일한 진화 패턴을 공유하는 경우 RMSE 2.7274±0.0177로, 서로 다른 패턴을 사용하는 ESG (2.6727±0.0117)보다 성능이 낮습니다. 이는 **각 시간 스케일이 고유한 동역학을 가지고 있음**을 강력히 시사합니다.[1]

### 3.3 실제 사례 분석을 통한 검증

NYC-Bike 데이터셋의 네 개 스테이션(77, 141, 166, 217) 간의 상관관계 변화를 시각화한 결과에서:[1]

1. **시간 진화의 포착**: 스테이션 166과 141이 16:30 이전에는 강한 상관을 보이지만 이후 분리되는 현상을 인접 행렬이 정확히 포착합니다. 행 166, 열 141의 값이 시간에 따라 감소하는 패턴을 보입니다.

2. **스케일별 차이**: 스케일 1의 인접 행렬은 "매우 양극화된" 값을 보여 단기 종속성이 불명확함을 시사하는 반면, 스케일 3(장기)의 행렬은 "더 평균화된" 값으로 장기 패턴의 균일성을 나타냅니다.[1]

이러한 관찰은 **모델이 실제로 다양한 시간 스케일에서 의미 있는 상관관계 변화를 포착**하고 있음을 강력히 시사합니다.

### 3.4 장기 예측에서의 우월성

다중 단계 예측에서 예측 지평이 증가함에 따라 성능 개선폭도 증가합니다. Horizon 3에서 7.8% 개선에서 Horizon 12에서 10.7% 개선으로 향상됩니다. 이는 모델이 **복잡한 시간 역학을 더 잘 캡슐화**하고 있음을 의미하며, 장기 예측의 불확실성이 증가할수록 진화적 그래프 구조의 이점이 더욱 두드러집니다.[1]

### 3.5 일반화 향상의 메커니즘

**과도한 평탄화(over-smoothing) 완화**: Mix-hop 전파에서 원본 입력의 일부를 유지하는 $$\beta$$ 파라미터(0.05로 설정)을 사용하여 노드의 원본 상태를 보존합니다. 이는 깊은 그래프 신경망에서 흔한 과도한 평탄화 문제를 완화합니다.[1]

**적응적 특성 선택**: 각 홉에 대해 $$\mathbf{W}^{(\psi)}$$로 가중치를 적응적으로 할당하므로, 모델은 자동으로 **중요한 신호가 포함된 홉을 선택**할 수 있습니다.[1]

**계층적 특성화**: 여러 층에 걸쳐 점진적으로 복잡한 상관관계를 학습하므로, 모델이 **단순한 패턴부터 복잡한 상호작용까지 점진적으로 학습**할 수 있습니다.

***

## 4. 연구에 미치는 영향 및 향후 고려 사항

### 4.1 학문적 영향

이 논문은 **그래프 신경망 기반 시계열 예측 분야에서 패러다임 전환**을 시도합니다. 기존의 "고정 그래프" 가정을 벗어나 **동적이고 다중 스케일 관점**을 도입함으로써:

1. **이론적 기여**: 시계열 변수 간의 상관관계가 본질적으로 시간-스케일-종속적이라는 통찰을 제공합니다.

2. **방법론적 기여**: GRU 기반 진화적 그래프 학습과 다중 스케일 추출의 조합이 새로운 디자인 패턴을 제시합니다.

3. **경험적 기여**: 실제 데이터(에너지, 교통, 금융 등)에서의 우수한 성능으로 방법론의 실질적 가치를 입증합니다.

### 4.2 향후 연구 방향

#### 4.2.1 모델 개선 방향

**1) 계산 효율성 향상**: 각 시간 단계마다 인접 행렬을 계산하는 오버헤드를 줄이기 위해:
- 조건부 업데이트 메커니즘: 상관관계의 변화가 클 때만 그래프 구조를 업데이트
- 그래프 희소화(graph sparsification): 중요하지 않은 연결을 자동으로 제거

**2) 더 나은 초기화 전략**: 정적 노드 표현 학습 방법의 개선:
- 그래프 오토인코더나 다른 자기지도 학습 기법 활용
- 외부 메타데이터(지리적 위치, 카테고리 정보 등)의 통합

**3) 해석 가능성 증대**:
- 학습된 그래프 구조와 실제 인과관계 간의 관계 분석
- 주의 메커니즘(attention)을 통해 어떤 시간 스케일과 상관관계가 예측에 기여하는지 시각화

#### 4.2.2 응용 확대

**1) 도메인 특화 적용**:
- 금융 시장의 다양한 자산 간 동적 상관 모델링
- 에너지 그리드의 재생 에너지 통합 예측
- 의료 시계열(환자 모니터링, 질병 진행)의 예측

**2) 극단적 이벤트 처리**:
- 정상 상황과 비상 상황에서의 그래프 구조 분화 학습
- 이상 탐지(anomaly detection)와의 통합

#### 4.2.3 이론적 심화

**1) 일반화 성능의 수학적 분석**:
- 진화적 그래프의 복잡도와 표본 복잡도 사이의 관계
- 어떤 조건에서 모델이 일반화되는지에 대한 이론적 보증

**2) 그래프 구조 학습의 정규화**:
- 학습된 그래프의 희소성과 안정성을 제어하는 정규화 항 도입
- 그래프 구조의 부드러운 진화를 강제하는 시간 평탄화 항

### 4.3 실무적 고려사항

**1) 데이터 요구사항**: 충분한 학습 데이터가 필수입니다. 소규모 그래프(노드 수 < 50)에서는 성능이 상대적으로 낮으므로, 이를 위한 전이학습 또는 메타학습 접근이 필요합니다.

**2) 하이퍼파라미터 민감도**: 시간 간격 $$d^{(l)}$$, 필터 크기 $$k_i$$, 확장 인수 등이 데이터셋에 따라 크게 달라지므로, 체계적인 하이퍼파라미터 튜닝이 중요합니다.

**3) 실시간 배포**: 매 시간 단계마다 그래프 구조를 재계산해야 하므로, 실시간 시스템에서는 지연 문제를 고려한 설계가 필요합니다.

### 4.4 결론적 제안

이 논문의 핵심 아이디어인 **"동적이고 다중 스케일 관점의 그래프"**는 향후 시계열 예측 연구에서 표준으로 채택될 가능성이 높습니다. 특히:

- **비유클리드 데이터의 시간 역학**: 교통망, 소셜 네트워크 등에서의 동적 상호작용 모델링
- **다중 해상도 분석**: 금융, 기후, 생물의학 등 다양한 시간 스케일의 현상이 얽혀 있는 분야
- **적응형 신경망**: 입력 데이터의 특성에 동적으로 적응하는 구조를 학습하는 패러다임

이들 분야에서 ESG의 설계 원칙을 확장하거나 변형하는 연구가 활발히 진행될 것으로 예상됩니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/646c217a-7f95-427b-bb17-196735dbfe99/2206.13816v1.pdf)
