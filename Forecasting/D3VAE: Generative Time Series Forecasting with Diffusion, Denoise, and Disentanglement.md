# D3VAE: Generative Time Series Forecasting with Diffusion, Denoise, and Disentanglement

### 1. 핵심 주장과 주요 기여

**논문의 핵심 주장:**
이 논문은 **짧은 시간에 기록된 실세계 시계열 데이터의 한계**를 극복하기 위해 생성 모델링 기반의 시계열 예측 방법을 제안합니다. 기존 딥러닝 모델들이 **제한적이고 노이지한 시계열 데이터**에서 과적합과 일반화 문제를 겪는다는 점을 지적하고, 이를 해결하기 위해 확산(Diffusion), 노이즈 제거(Denoise), 해석 가능성(Disentanglement)을 결합한 새로운 프레임워크를 제시합니다.

**주요 기여:**
1. **결합된 확산 확률 모델(Coupled Diffusion Probabilistic Model)**: 입출력 시계열을 동시에 확산하여 **통계적 불확실성(aleatoric uncertainty)**을 줄이면서 일반화 능력을 개선
2. **멀티스케일 노이징 스코어 매칭(Multiscale Denoising Score Matching)**: 손상된 생성 시계열을 정제하여 예측 정확도 향상
3. **잠재변수 해석 가능성**: 전체 상관관계(Total Correlation) 최소화를 통해 잠재변수를 디엔탱글링하여 모델 해석 가능성 및 안정성 증대
4. **광범위한 실험 검증**: 합성 및 실세계 데이터에서 기존 방법 대비 **평균 43% MSE 감소, 23% CRPS 감소** 달성

***

### 2. 해결 문제, 제안 방법, 모델 구조, 성능

#### 2.1 해결하고자 하는 문제

**문제의 본질:**
- **데이터 부족 문제**: 실제 시계열은 짧은 시간 구간에 기록되어 깊은 신경망과 제한된 데이터 사이의 큰 간격 발생
- **노이즈 및 불확실성**: 시계열에 내재된 알레아토릭 불확실성(measurement noise)과 인식 불확실성(epistemic uncertainty)
- **해석 가능성 부족**: 기존 VAE 기반 모델은 잠재변수가 얽혀(entangled) 해석이 어려움
- **성능 저하**: 전통적 방법(VAR, GP)은 신뢰성이 낮고, 신경망 기반 방법(RNN, CNN, Transformer)은 불확실성 정량화 불가

#### 2.2 제안하는 방법

**2.2.1 확산 모델링 (Diffusion Modeling)**

기본 개념: 입력 시계열 $$X = X^{(0)} $$에 점진적으로 가우시안 노이즈를 추가하는 마르코프 연쇄

정방향 확산 프로세스:

$$
q(X^{(t)}|X^{(t-1)}) = N(X^{(t)}; \sqrt{1-\beta_t}X^{(t-1)}, \beta_t I)
$$

여기서 $$\beta = \{\beta_1, \ldots, \beta_T\} $$는 분산 스케줄이며, $$\alpha_t = 1 - \beta_t $$이고 $$\bar{\alpha}\_t = \prod_{s=1}^{t}\alpha_s $$입니다.

단계 t에서 직접 샘플링:

$$
q(X^{(t)}|X^{(0)}) = N(X^{(t)}; \sqrt{\bar{\alpha}_t}X^{(0)}, (1-\bar{\alpha}_t)I)
$$

**Proposition 1 (노이즈 분해)**:

$$
X = \langle X_r, \epsilon_X \rangle
$$

- $$X_r $$: 노이즈 없는 이상적 시계열
- $$\epsilon_X $$: 내재된 노이즈 (독립적)

확산된 시계열의 분해:

$$
X^{(t)} = \sqrt{\bar{\alpha}_t}X^{(0)} + (1-\bar{\alpha}_t)\delta_X := \left\langle \underbrace{\sqrt{\bar{\alpha}_t}X_r}_{\text{이상적 부분}}, \underbrace{\sqrt{\bar{\alpha}_t}\epsilon_X + (1-\bar{\alpha}_t)\delta_X}_{\text{노이스 부분}} \right\rangle
$$

**결합 확산 프로세스 (Coupled Diffusion)**:
입력과 목표 시계열을 다른 분산 스케줄로 동시에 확산:
- 입력: $$\beta_t \in [0, 1) $$
- 목표: $$\beta'_t = \omega\beta_t $$ (스케일 파라미터 $$\omega \in (0,1) $$)

이를 통해:
- **Lemma 1**: 알레아토릭 불확실성 감소 →

$$D_{KL}(q(\hat{Y}^{(t)}_r)||p_\theta(\hat{Y}^{(t)}_r)) < \epsilon $$

- **Lemma 2**: 확산 노이즈와 생성 노이즈 간격 감소 → 일반화 성능 개선

#### 2.2.2 양방향 변분 자동인코더 (BVAE)

확산 모델의 역방향 프로세스를 대체하기 위한 구조:

구조:

$$
Z = \{z_1, \ldots, z_n\}, \quad z_i \in \mathbb{R}^m
$$

신경망 매개변수 $$\phi $$ (인코더)와 $$\theta $$ (디코더)로 구성:
- 인코더: $$p_\phi(Z|X^{(t)}) = g_\phi(X^{(t)}) $$ (잠재 분포 학습)
- 디코더: $$p_\theta(\hat{Y}^{(t)}|Z) $$ (시계열 생성)

양방향 구조의 장점:
- VAE의 표현 학습 능력과 확산 모델의 표현력 결합
- 해석 가능성 인터페이스 제공
- 신호가 인코더-디코더 양방향으로 확산되어 풍부한 의미 집합

#### 2.2.3 멀티스케일 노이징 스코어 매칭 (Scaled Denoising Score Matching, DSM)

**문제**: 생성된 시계열이 손상된 목표 시계열로 이동 경향
→ 해결: 에너지 기반 모델의 노이징을 통한 "정제" 프로세스

DSM 손실 함수:

$$
L_{DSM}(\zeta) = E_{p_{\sigma_0}(\hat{Y}, Y)} \left\| \nabla_{\hat{Y}} \log(q_{\sigma_0}(\hat{Y}|Y)) + \nabla_{\hat{Y}} E(\hat{Y}; \zeta) \right\|^2
$$

가우시안 노이즈의 경우:

$$
L_{DSM}(\zeta) = E_{p_{\sigma_0}(\hat{Y}, Y)} \left\| Y - \hat{Y} + \sigma_0^2 \nabla_{\hat{Y}} E(\hat{Y}; \zeta) \right\|^2
$$

**멀티스케일 버전** (서로 다른 노이즈 레벨에 가중):

$$
L(\zeta, t) = E_{q_\sigma(\hat{Y}^{(t)}|Y)p(Y)} l(\sigma_t) \left\| Y - \hat{Y}^{(t)} + \sigma_0^2 \nabla_{\hat{Y}^{(t)}} E(\hat{Y}^{(t)}; \zeta) \right\|^2
$$

여기서 $$l(\sigma_t) = \sigma_t $$는 가중 함수이고, $$\sigma_t = 1 - \bar{\alpha}_t $$

**단계 그래디언트 노이징 점프** (테스트 시):

$$
\hat{Y}_{clean} = \hat{Y} - \sigma_0^2 \nabla_{\hat{Y}} E(\hat{Y}; \zeta)
$$

이 항은 예측의 추정 불확실성으로 해석 가능

#### 2.2.4 잠재변수 디엔탱글링

**목적**: 다양한 시계열 패턴(추세, 계절성 등)을 구분되는 잠재 차원으로 매핑

**전체 상관관계(Total Correlation) 최소화**:

$$
TC(z_i) = D_{KL}(p_\phi(z_i) || \bar{p}_\phi(z_i))
$$

여기서:

$$
\bar{p}_\phi(z_i) = \prod_{j=1}^{m} p_\phi(z_{i,j})
$$

- $$z_i $$의 차원들 간 의존성 측정
- 낮은 TC = 더 나은 디엔탱글링

평균 TC 손실:

$$
L_{TC} = \frac{1}{n} \sum_{i=1}^{n} TC(z_i)
$$

#### 2.2.5 전체 학습 목적 함수

$$
L = \psi \cdot D_{KL}(q(Y^{(t)})||p_\theta(\hat{Y}^{(t)})) + \lambda \cdot L(\zeta, t) + \gamma \cdot L_{TC} + L_{mse}(\hat{Y}^{(t)}, Y^{(t)})
$$

여기서:
- $$\psi $$ : KL 발산 가중치
- $$\lambda $$ : DSM 손실 가중치
- $$\gamma $$ : 디엔탱글링 가중치
- $$L_{mse} $$ : 평균제곱오차

#### 2.3 모델 구조

**D3VAE 전체 아키텍처** (Figure 1):

1. **입력 처리**: 임베딩 + GRU를 통한 시간 특성 추출

$$
   X_{input} = CONCAT(RNN(E(X)), E(X))
   $$

2. **결합 확산**: 입력 $$X^{(0)} $$과 목표 $$Y^{(0)} $$를 동시에 확산
   - 입력: $$X^{(t)} = \sqrt{\bar{\alpha}_t}X^{(0)} + (1-\bar{\alpha}_t)\delta_X $$
   - 목표: $$Y^{(t)} = \sqrt{\bar{\alpha}'_t}Y^{(0)} + (1-\bar{\alpha}'_t)\delta_Y $$

3. **BVAE 추론**: 확산된 입력에서 잠재 표현 학습
   - 인코더 (양방향): $$q(Z^{(t)}|X^{(t)}) $$
   - 디코더 (양방향): $$p(Z_{i+1}|Z_i, X) $$

4. **DSM 정제**: 생성된 시계열 정제

$$
   \hat{Y}_{clean} = \hat{Y} - \sigma_0^2 \nabla_{\hat{Y}} E(\hat{Y}; \zeta)
   $$

5. **출력**: 정제된 예측 $$\hat{Y}_{clean} $$ 및 불확실성 추정값

***

### 3. 성능 향상 및 실험 결과

#### 3.1 성능 지표
- **MSE (Mean Squared Error)**: 낮을수록 좋음
- **CRPS (Continuous Ranked Probability Score)**: 분포 유사성 평가, 낮을수록 좋음

#### 3.2 실험 결과

**합성 데이터 (Table 1)**:

$$
w_t = a \cdot w_{t-1} + \tanh(b \cdot w_{t-2}) + \sin(w_{t-3}) + N(0, 0.5I)
$$

- D1 (a=0.9, b=0.2): 예측 길이 8에서 **MSE 0.512** (NVAE: 1.201)
- D2 (a=0.5, b=0.5): 예측 길이 8에서 **MSE 0.599** (β-TCVAE: 3.096)

**실제 데이터 (Table 2)**:

| 데이터셋 | 예측 길이 | D3VAE MSE | 기존 최고 | 개선율 |
|---------|----------|----------|---------|--------|
| Traffic | 8 | 0.081 | 0.794 | 90% ↓ |
| Electricity | 8 | 0.251 | 0.853 | 71% ↓ |
| Wind | 8 | 0.681 | 2.006 | 48% ↓ |
| ETTm1 | 8 | 0.527 | 2.375 | 43% ↓ |
| ETTh1 | 8 | 0.292 | 1.006 | 40% ↓ |
| Weather | 8 | 0.169 | 0.560 | 28% ↓ |

**CRPS 감소율**:
- Traffic (예측 길이 8): **73% ↓**
- Wind (예측 길이 8): **31% ↓**
- Electricity (예측 길이 8): **27% ↓**

#### 3.3 절제 연구 (Table 3)

각 구성 요소의 기여도 분석 (Traffic, Electricity 데이터):

| 모델 변형 | 설명 | 성능 영향 |
|---------|------|---------|
| D3VAE (전체) | 모든 구성 요소 포함 | **기준선** |
| D3VAE-Ŷ | 목표 확산 제거 | MSE ↑ 51% (0.081→0.122) |
| D3VAE-Ŷ-DSM | 목표 확산 + DSM 제거 | MSE ↑ 19% (0.081→0.096) |
| D3VAE-X̂ | 입력 확산 제거 | MSE ↑ 52% (0.081→0.123) |
| D3VAE-CDM | 전체 확산 제거 | MSE ↑ 52% (0.081→0.123) |
| D3VAE-CDM-DSM | 확산 + DSM 제거 | MSE ↑ 52% (0.081→0.123) |

결론: **결합 확산 프로세스와 DSM이 각각 성능 개선에 핵심 역할**

#### 3.4 불확실성 추정

Figure 3에서 Traffic 데이터셋의 마지막 6개 차원 예측:
- 극값 인접 영역에서 추정 불확실성 급증
- 모델이 신뢰도 낮은 부분을 올바르게 식별

***

### 4. 일반화 성능 향상 메커니즘 (핵심)

#### 4.1 알레아토릭 불확실성 감소

**핵심 아이디어**: 데이터의 노이즈 성분을 명시적으로 모델링하여 신호 성분만 학습

$$
\text{예측 오류} = ||Y - \hat{Y}|| = ||\epsilon_Y - \epsilon_{\hat{Y}}|| > 0
$$

결합 확산의 효과:
- Lemma 2: $$\lim_{t \to \infty} D_{KL}(q(\delta_{\hat{Y}}^{(t)})||p_\theta(\delta_{\hat{Y}}^{(t)}|Z^{(t)})) < D_{KL}(q(\epsilon_Y)||p_\theta(\epsilon_{\hat{Y}})) $$
- 생성 노이즈와 확산 노이즈 간격 점진적 감소
- 결과: **더 깨끗한 신호에 학습 집중**

#### 4.2 데이터 증강 효과

**짧은 시계열의 문제점**:
- Appendix G: 400개 시점 → 심한 과적합 발생
- 800개 이상 시점 필요

**확산의 해결책**:
- 입출력 동시 증강 → 분포 공간 확대
- 유용한 신호 패턴 보존 (분산 스케줄 조절)
- Figure 15: 적절한 $$\beta_t $$와 T 선택으로 최적 균형 달성

#### 4.3 멀티스케일 노이징의 역할

DSM은 각 확산 단계에서:
1. **노이즈 레벨별 맞춤 정제**: $$l(\sigma_t) = \sigma_t $$로 가중
2. **생성-목표 간격 좁힘**: $$Y - \hat{Y} + \sigma_0^2 \nabla_{\hat{Y}} E(\hat{Y}; \zeta) $$
3. **확률적 해석**: 추정 불확실성 $$\sigma_0^2 \nabla_{\hat{Y}} E(\hat{Y}; \zeta) $$로 정량화

#### 4.4 디엔탱글링의 기여

**안정성 증대**:
- 낮은 TC → 각 차원이 독립적 시계열 패턴 표현
- 예측 시 특정 요인(추세 vs 계절성)의 영향 명확화
- Robustness 향상: 새로운 패턴에 대한 일반화 개선

**Figure 14 (MIG 분석)**:
- $$\gamma $$ 증가 시 MIG 향상 (더 나은 디엔탱글링)
- 팩터 수 증가 시 어려움 증가 (복잡도 trade-off)

***

### 5. 한계와 제약사항

#### 5.1 구조적 한계

1. **편향 도입 (Bias Introduction)**:
   - 확산 과정이 새로운 편향 도입 가능
   - 다양한 시계열 데이터에 자동으로 적용 불가
   - 분산 스케줄 $$\beta_t $$와 단계 수 T를 신중히 선택 필요

2. **하이퍼파라미터 민감도**:
   - Figure 4: $$\beta_T $$ 범위와 T 선택이 성능에 큰 영향
   - 너무 작은 $$\beta $$ 또는 부족한 T → 의미없는 확산
   - 너무 큰 $$\beta $$ 또는 과도한 T → 제어 불가능한 확산

3. **디엔탱글링의 선험적 지식 부족**:
   - 비지도 학습으로만 가능 (라벨 부재)
   - 정확한 시계열 팩터 라벨링 불가능
   - 인위적 평가 지표(MIG) 사용

#### 5.2 실험적 한계

1. **단계 그래디언트 점프의 한계**:
   - 단일 단계 샘플링만 사용
   - Langevin dynamics의 다단계 샘플링 검토 (Figure 5)
   - 결과: 추가 단계가 크게 도움이 안 됨 + 계산 복잡도 증가

2. **확장성 문제**:
   - 긴 시계열에 대한 확대 성능 미검증
   - Table 6: 예측 길이 32, 64일 때 성능이 다소 감소
   - 매우 긴 예측 범위에서의 안정성 불명확

3. **사회적 영향 우려**:
   - 불법적 응용 가능성 경고
   - 의료, 금융 등 민감 분야 적용 시 윤리성 검토 필요

#### 5.3 방법론적 한계

1. **VAE의 일반적 문제**:
   - 입력의 편향 → 출력의 편향 전파
   - 후방 붕괴(posterior collapse) 가능성 미논의

2. **이론적 완결성**:
   - Proposition 1의 독립성 가정 현실성 의문
   - Lemma 1, 2의 증명 - 근사 오차의 정량적 경계 미제시

***

### 6. 일반화 성능 관련 내용 (심화)

#### 6.1 이론적 근거

**Proposition 1 (노이즈 분해)**:
시계열을 이상적 신호와 노이즈로 독립적 분해:

$$
X = \langle X_r, \epsilon_X \rangle, \quad X_r \perp \epsilon_X
$$

이를 통해 **알레아토릭 불확실성**을 명시적 대상으로:
- 전통 모델: 총 오차 최소화 (신호+노이즈 혼합)
- D3VAE: 노이즈 감소에 중점 + 신호 학습 효율화

**Lemma 1 (수렴성)**:
임의의 $$\epsilon > 0 $$에 대해 모델 $$f_{\phi,\theta} $$가 존재하여:

$$
D_{KL}(q(\hat{Y}^{(t)}_r)||p_\theta(\hat{Y}^{(t)}_r)) < \epsilon
$$

의미: 충분한 모델 용량 → 이상적 신호 완벽 복원 가능

**Lemma 2 (불확실성 감소)**:

$$
\lim_{t \to \infty} D_{KL}(q(\delta_{\hat{Y}}^{(t)})||p_\theta(\delta_{\hat{Y}}^{(t)}|Z^{(t)})) < D_{KL}(q(\epsilon_Y)||p_\theta(\epsilon_{\hat{Y}}))
$$

의미: 확산 과정을 통해 **생성 노이즈가 실제 데이터 노이즈로 수렴**

#### 6.2 경험적 증거

**절제 연구 (Table 3) - 각 구성 요소의 필요성**:

결합 확산 제거 시 Traffic (16-step) MSE: 0.081 → 0.123 (52% 악화)
- 입력 확산(-Ŷ): MSE 0.122
- 목표 확산(-X̂): MSE 0.123
→ 두 구성 요소 모두 필수

DSM 제거 (CDM-DSM) MSE: 0.081 → 0.123 (52% 악화)
- DSM 없으면 생성 시계열이 손상된 목표로 학습

#### 6.3 데이터 가용성에 따른 성능 개선

**짧은 시계열 특화 (Appendix G)**:

RNN 모델 비교 (400-1600 시점):
- 400 시점: 급격한 train-test gap (심한 과적합)
- 800 시점: gap 감소
- 1200+ 시점: 안정적 학습

→ D3VAE의 **동시 증강 전략**이 부족한 데이터에서 특히 효과적

#### 6.4 하이퍼파라미터 튜닝과 일반화

**분산 스케줄 $$\beta_t $$와 단계 수 T의 영향 (Figure 4)**:
- $$\beta_T $$ 너무 작음 → 약한 확산, 데이터 증강 불충분
- $$\beta_T $$ 너무 큼 → 강한 노이즈, 신호 손실
- **최적 범위**: 데이터셋별 다름 (0.01~0.1, T=100~1000)

예: Electricity의 경우 $$\beta_T = 0.1, T = 1000 $$ 최적

***

### 7. 연구 영향 및 향후 방향

#### 7.1 기존 연구에 미치는 영향

**패러다임 전환**:
1. **VAE 기반 시계열 예측의 새 기준**: 생성 모델과 확산 모델 결합의 가능성 제시
2. **불확실성 정량화**: 알레아토릭 불확실성을 **첫 직접 대응** → 예측 신뢰도 향상
3. **데이터 부족 상황 대처**: 짧은 시계열이 흔한 실무 영역에 실질적 기여

**학술적 기여**:
- 확산 모델을 시계열 예측에 적용한 선구적 연구
- 디엔탱글링과 시계열 분해의 연결
- 멀티스케일 노이징 스코어 매칭의 실제 응용

#### 7.2 향후 연구 시 고려할 점

**1. 방법론 개선**:
- **적응형 분산 스케줄**: 데이터 특성에 따른 자동 $$\beta_t $$, T 결정
- **Langevin 샘플링 확장**: 다단계 샘플링으로 생성 품질 향상 탐색
- **VAE 개선**: 후방 붕괴 문제 해결을 위한 고급 기법 통합

**2. 확장성 강화**:
- 매우 긴 시계열(수천 시점) 성능 검증
- 매우 긴 예측 범위(100+ 단계) 안정성 평가
- 고차원 다변수 시계열(수백 개 변수) 확대

**3. 해석 가능성 심화**:
- 라벨된 시계열 팩터 학습으로 감독 디엔탱글링 탐색
- 시계열 특정 패턴(추세, 계절성, 이상치)의 명시적 모델링
- 인과관계 기반 해석 틀 개발

**4. 실제 응용 고려**:
- **도메인별 적응**: 금융(주식), 에너지(전력 소비), 날씨 등 특화 버전
- **결측치 처리**: 불완전한 시계열 입력 수용
- **다중 스케일 예측**: 서로 다른 시간 단위의 동시 예측

**5. 이론 강화**:
- Proposition 1의 독립성 가정 완화
- Lemma 1, 2의 **정량적 오차 경계** 유도
- 일반화 오류 한계(generalization bounds) 증명

**6. 계산 효율성**:
- 확산 단계 감소 while 성능 유지
- 추론 속도 최적화 (실시간 예측 적용)
- GPU 메모리 효율화

***

### 8. 결론 종합

**핵심 성과**: D3VAE는 결합 확산, 다단계 노이징, 디엔탱글링을 통해 **짧고 노이즈한 실세계 시계열에서 평균 43% 성능 향상**을 달성하며, **알레아토릭 불확실성을 정량적으로 추정**함으로써 예측의 신뢰도를 높였습니다.

**제한사항**: 하이퍼파라미터 민감도, 확산 편향 도입, 비지도 디엔탱글링의 한계 등이 존재하며, 매우 긴 시계열과 극단적 예측 범위에서의 성능은 추가 검증이 필요합니다.

**미래 방향**: 자동 하이퍼파라미터 선택, 감독 디엔탱글링, 도메인 특화 확장, 이론적 기초 강화가 중요한 연구 과제입니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/e3539372-86b5-4bc3-ac3c-b22f5ad9a16e/2301.03028v1.pdf)
