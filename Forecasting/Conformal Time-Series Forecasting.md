# Conformal Time-Series Forecasting 

## 1. 핵심 주장과 주요 기여

**Conformal Time-Series Forecasting (CF-RNN)** 논문의 핵심 주장은 기존의 RNN 기반 시계열 예측 방법들이 점 추정(point estimate)만 제공하며, 불확실성 정량화 방법들이 여러 한계를 가지고 있다는 것입니다. 이를 해결하기 위해 **Inductive Conformal Prediction (ICP) 프레임워크를 시계열 예측에 확장**하여 다음의 주요 기여를 제시합니다:[1]

1. **이론적 보증을 가진 불확실성 정량화**: 빈도주의 관점에서 다중 지평선(multi-horizon) 예측 구간에 대한 유한 샘플 커버리지 보증을 제공합니다.

2. **구조 수정 최소화**: 기존 예측 모델에 가벼운 후처리(post-hoc) 절차만 적용하여 불확실성 구간을 생성하므로, 모델 아키텍처의 실질적인 변경이 불필요합니다.

3. **다중 시계열 설정 지원**: 단일 시계열이 아닌 독립적인 다중 시계열 관측 데이터를 활용하면서도 교환 가능성(exchangeability) 가정을 만족하는 방법론적으로 타당한 접근을 제시합니다.

---

## 2. 해결 문제, 제안 방법, 모델 구조 및 성능

### 2.1 해결하고자 하는 문제

기존의 RNN 기반 불확실성 정량화 방법들의 한계:[1]

- **Bayesian RNNs**: 모델 파라미터 수 증가, 사전분포(prior) 선택의 어려움, 보정(calibration) 어려움
- **Quantile RNNs**: 양자 교차(quantile crossing) 문제, 샘플 복잡도 증가로 인한 과적합 위험
- **Bootstrapping/Jackknife 방법**: $$O(P^3)$$ 시간 복잡도로 인한 확장성 부족
- **일반적 한계**: 이론적 보증 부재, 높은 계산 복잡도, 보정 어려움, 높은 샘플 복잡도

### 2.2 제안 방법 및 수식

#### 기본 설정

다중 지평선 시계열 예측 문제를 다음과 같이 정의합니다:[1]

시계열 $$y_{t:t'} = (y_t, y_{t+1}, \ldots, y_{t'})$$에서 역사 $$y_{1:t'}$$가 주어졌을 때, $$H$$ 스텝 앞의 값들을 예측합니다:

$$
\hat{y}_{(t'+1):(t'+H)} = (\hat{y}_{t'+1}, \ldots, \hat{y}_{t'+H}) \in \mathbb{R}^{H \times d}
$$

목표는 다음의 조건을 만족하는 예측 구간을 얻는 것입니다:[1]

$$
P\left(y_{t+h} \in [\hat{y}^L_{t+h}, \hat{y}^U_{t+h}], \forall h \in \{1, \ldots, H\}\right) \geq 1 - \alpha
$$

#### Inductive Conformal Prediction (ICP)

ICP의 핵심은 **비순응성 점수(nonconformity score)**를 통해 예측 구간을 구성하는 것입니다:[1]

$$
R_i = \Delta(M(x^{(i)}|D), y^{(i)}) = |\hat{y}^{(i)} - y^{(i)}|
$$

여기서 $$M$$은 학습된 예측 모델, $$\Delta$$는 거리 메트릭입니다.

보정 집합에서 계산한 비순응성 점수 분포로부터 임계값 $$\hat{\varepsilon}$$를 구합니다:[1]

$$
\hat{\varepsilon} = \lceil (m+1)(1-\alpha) \rceil \text{-th smallest residual}
$$

예측 구간은 다음과 같이 구성됩니다:[1]

$$
\Gamma_\alpha(x^{(l+1)}) = [\hat{y}^{(l+1)} - \hat{\varepsilon}, \hat{y}^{(l+1)} + \hat{\varepsilon}]
$$

#### CF-RNN의 확장

다중 지평선 예측의 경우, 각 스텝 $$h$$에 대해 개별 비순응성 점수를 계산합니다:[1]

$$
R_i = (|y^{(i)}_{t+1} - \hat{y}^{(i)}_{t+1}|, \ldots, |y^{(i)}_{t+H} - \hat{y}^{(i)}_{t+H}|)^\top
$$

**Bonferroni 보정**을 적용하여 다중 비교 문제를 해결합니다:[1]

$$
\hat{\varepsilon}_h = \lceil (m+1)(1-\alpha/H) \rceil \text{-th smallest residual}
$$

최종 예측 구간:[1]

$$
\Gamma^\alpha_h(y^{(l+1)}_{1:t}) = [\hat{y}^{(l+1)}_{t+h} - \hat{\varepsilon}_h, \hat{y}^{(l+1)}_{t+h} + \hat{\varepsilon}_h], \quad \forall h \in \{1, \ldots, H\}
$$

### 2.3 모델 구조

CF-RNN의 아키텍처는 두 가지 주요 구성 요소로 이루어집니다:[1]

1. **기저 예측 모델 (M)**: LSTM 또는 GRU 기반의 RNN으로 점 예측을 생성합니다. 재귀적 예측이 아닌 **직접 다중 지평선 예측(direct multi-horizon forecasting)** 방식을 사용합니다. 이는 오류 누적을 방지하고 조건부 독립성을 보장합니다.

2. **보정 절차**: 학습된 모델을 보정 집합에 적용하여 비순응성 점수를 수집하고, 원하는 커버리지 수준에 맞춰 임계값을 계산합니다.

알고리즘 요약:[1]
- 학습 집합 $$D_{train}$$으로 모델 $$M$$ 학습
- 보정 집합 $$D_{cal}$$에서 모든 $$H$$ 스텝에 대한 예측 오류 계산
- 각 스텝별로 Bonferroni 보정된 임계값 $$\hat{\varepsilon}_h$$ 계산
- 새로운 시계열에 대해 $$M$$의 점 예측 ± $$\hat{\varepsilon}_h$$로 구간 생성

### 2.4 성능 향상

**합성 데이터 실험 결과**:[1]

CF-RNN은 다음과 같은 성능 우위를 보여줍니다:

- **커버리지 보증**: 목표 커버리지 90% (α=0.1)을 일관되게 달성 (92-95%)
- **적응형 구간 폭**: 시간 종속 노이즈가 있는 데이터에서 노이즈 증가에 따라 구간이 자동으로 확장되어 예측 불확실성에 적응
- **기저 모델과 무관**: 임의의 점 예측 모델에 적용 가능

| 모델 | 커버리지 | 특징 |
|------|---------|------|
| CF-RNN | 92-96% | 이론적 보증, 효율적 계산 |
| BJ-RNN | 97-100% | 매우 넓은 구간 (98.45 vs 16.45) |
| MQ-RNN | 57-67% | 불완전한 커버리지 |
| DP-RNN | 0-5% | 심각한 미달 |

**실제 데이터 실험 결과** (MIMIC-III, EEG, COVID-19):[1]

| 데이터셋 | CF-RNN 커버리지 | MQ-RNN | DP-RNN |
|---------|----------------|--------|--------|
| MIMIC-III | 94.0% | 89.3% | 40.2% |
| EEG | 96.5% | 48.0% | 3.3% |
| COVID-19 | 89.7% | 15.0% | 0.0% |

### 2.5 한계

논문에서 인정하는 주요 한계들:[1]

1. **구간 폭의 비효율성**: CF-RNN의 예측 구간이 다른 방법보다 더 넓을 수 있습니다 (특히 COVID-19 데이터셋에서 733.95 vs MQ-RNN 136.56). 이는 보수적인 보증의 대가입니다.

2. **교환 가능성 가정**: 다중 시계열 설정에서는 작동하지만, 단일 시계열만 있는 경우 이 가정이 위반될 수 있습니다.

3. **다변량 시계열 미지원**: 현재 구현은 단변량 시계열 ($$d=1$$)에만 초점을 맞추고 있으며, 다변량 확장은 향후 작업으로 남겨졌습니다.

4. **개별 관측에 대한 적응성 부족**: 예측 구간이 전체 보정 집합을 기반으로 하므로, 개별 입력의 난이도에 따른 세밀한 조정이 어렵습니다.

---

## 3. 모델의 일반화 성능 향상 가능성

### 3.1 데이터셋 크기와 일반화

Figure 3 (좌측 및 중앙 패널)에서 보여주듯이, CF-RNN의 일반화 성능은 **보정 집합 크기에 정적으로 의존**합니다:[1]

$$
\text{더 많은 보정 데이터} \rightarrow \text{더 정확한 비순응성 점수 분포} \rightarrow \text{더 좁고 신뢰할 수 있는 구간}
$$

실험에서 학습 데이터셋 크기가 2000에서 10000으로 증가할 때:
- **커버리지는 안정적으로 90% 이상 유지됨**
- **평균 구간 폭은 약 30-50% 감소**

이는 더 많은 데이터가 모델의 불확실성 정량화를 개선함을 의미합니다.

### 3.2 예측 지평선과 커버리지 트레이드오프

Figure 3 (우측 패널)은 고정된 예측 구간 폭을 유지하면서 달성 가능한 최대 커버리지를 지평선 $$H$$의 함수로 보여줍니다:[1]

$$
\text{지평선이 길수록} \rightarrow \text{달성 가능한 커버리지 하락}
$$

이는 **시간 종속성의 영향을 반영**합니다. 더 멀리 예측할수록 불확실성이 누적되므로, 동일한 커버리지를 유지하려면 구간이 더 커져야 합니다.

### 3.3 Bonferroni 보정의 중요성

Table 6의 분석에서, Bonferroni 보정 없이는 **결합 커버리지(joint coverage)가 심각하게 하락**합니다:[1]

| 데이터셋 | Bonferroni 적용 | 미적용 | 하락폭 |
|---------|---------------|-------|-------|
| MIMIC-III | 94.0% | 89.0% | -5.0% |
| EEG | 96.5% | 59.4% | -37.1% |
| COVID-19 | 89.7% | 55.5% | -34.2% |

이는 다중 지평선 예측에서 각 시점의 오류가 **독립적이지 않기 때문**입니다. Bonferroni 보정은 이러한 의존성을 보수적으로 보정하여 이론적 보증을 유지합니다.

### 3.4 비순응성 점수의 적응성

CF-RNN의 일반화 메커니즘은 **비순응성 점수 분포의 경험적 추정**에 기반합니다:[1]

$$
\hat{\varepsilon}_h = \text{empirical quantile of } \{|y^{(i)}_{t+h} - \hat{y}^{(i)}_{t+h}|\}_{i=1}^m
$$

따라서 다양한 데이터 특성(노이즈 프로파일, 비정상성, 시간 종속성)에 자동으로 적응합니다. 예를 들어:
- **정적 노이즈**: 구간 폭이 안정적으로 유지됨
- **시간 종속 노이즈**: 구간이 점진적으로 확장되어 누적 불확실성을 반영

***

## 4. 향후 연구 영향 및 고려 사항

### 4.1 향후 연구에 미치는 영향

1. **비매개변수적 접근의 확립**: CF-RNN은 분포에 무관한(distribution-free) 불확실성 정량화의 실용적 가능성을 입증했습니다. 이는 향후 시계열 예측 연구에서 **비매개변수적 방법론의 채택**을 촉진할 것입니다.

2. **이론적-실무적 격차 해소**: 기존 방법들은 이론적 보증이 부족하거나 실행 불가능했던 반면, CF-RNN은 **간단한 구현으로도 이론적 보증을 제공**하여, 고위험 응용(의료, 금융)에서의 신뢰성 있는 예측 구간 생성을 가능하게 합니다.

3. **Conformal Prediction의 시계열 확장**: 이 작업은 ICP의 **표준 교환 가능성 가정을 시간 종속적 설정으로 확장**하는 새로운 연구 방향을 열었습니다. 향후 연구는 더 약한 가정(예: 혼합성, 약한 교환 가능성)을 탐구할 것으로 예상됩니다.

### 4.2 향후 연구 시 고려할 점

1. **구간 효율성 개선**
   - **문제**: CF-RNN의 구간이 보수적으로 넓음
   - **개선 방향**: 개별 관측에 대해 적응형 비순응성 점수를 개발하거나, 계층화된(stratified) 보정 절차를 도입하여 구간을 압축

2. **다변량 시계열 확장**
   - **현재 제약**: 단변량 시계열만 지원
   - **개선 방향**: 다변량 비순응성 점수(예: Mahalanobis 거리)를 정의하고, 각 변수별 또는 결합 커버리지 보증을 개발

3. **약한 교환 가능성 가정 완화**
   - **현재 가정**: 완전한 교환 가능성 필요
   - **개선 방향**: EnbPI와 같이 단일 시계열에서도 작동하는 방법론 개발, 또는 혼합된(mixing) 시계열에 대한 이론 정립

4. **보정 집합 크기의 최적화**
   - **문제**: 보정 집합 크기가 성능에 영향을 미침 (Figure 3 참고)
   - **개선 방향**: 원하는 커버리지와 효율성에 대한 보정 집합 크기의 이론적 경계(bounds) 개발

5. **비정상 시계열에 대한 처리**
   - **문제**: 현재 방법은 정상성을 가정하지 않으나, 명시적인 검증 없음
   - **개선 방향**: 비정상 시계열에서의 커버리지 보증에 대한 이론적 분석 및 실증 연구

6. **계산 효율성 개선**
   - **현재 장점**: 선형 시간 복잡도 ($$O(m)$$)
   - **향후 방향**: 온라인 학습(online learning) 설정에서의 적응형 보정 절차 개발

***

## 결론

**Conformal Time-Series Forecasting** 논문은 복잡한 시계열 예측 문제에 **이론적으로 보증된 불확실성 정량화**를 제공하는 우아한 해결책을 제시합니다. 구조 수정 최소화, 계산 효율성, 그리고 강력한 이론적 기초는 이를 미래 시계열 예측 연구의 중요한 기준점으로 만들었습니다. 향후 연구는 구간 효율성 개선, 다변량 확장, 약한 가정 하에서의 작동성 강화에 초점을 맞출 것으로 예상됩니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/8562f7eb-c723-4cd7-aab3-21a126e5c75a/NeurIPS-2021-conformal-time-series-forecasting-Paper.pdf)
