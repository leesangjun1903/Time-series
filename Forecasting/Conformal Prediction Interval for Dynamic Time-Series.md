# Conformal Prediction Interval for Dynamic Time-Series

### 1. 핵심 주장과 주요 기여

**EnbPI(Ensemble Bootstrap Prediction Intervals)** 방법은 동적 시계열 데이터에 대한 **분포-자유(distribution-free) 예측 구간**을 구성하는 새로운 접근 방식입니다. 이 논문의 핵심 주장은 기존 Conformal Prediction(CP) 프레임워크와 달리 **데이터 교환가능성(exchangeability) 가정을 제거**하면서도 유한표본 근사적 유효 한계 적용률(finite-sample approximately valid marginal coverage)을 달성할 수 있다는 것입니다.[1]

주요 기여는 다음과 같습니다:[1]

- **계산 효율성**: 데이터 분할이 필요 없으며, 이미 훈련된 부트스트랩 앙상블 추정기를 효율적으로 집계하여 순차적 예측 구간을 생성합니다
- **이론적 보장**: 강하게 혼합된 확률 오류(strongly mixing stochastic errors)를 가진 시계열에서 근사적으로 유효한 한계 적용률을 증명합니다
- **광범위한 적용성**: 깊은 신경망 등 임의로 복잡한 회귀 함수와 비정상(non-stationary) 시계열에 적합합니다

---

### 2. 문제 정의, 제안 방법, 모델 구조 및 성능

#### 2.1 해결하고자 하는 문제

시계열 데이터는 공간-시간적으로 상관되어 있으며 비정상적이고 복잡한 의존성을 가집니다. 기존 문제는:[1]

- 복잡한 회귀 모델(예: 앙상블 추정기, 깊은 신경망)에 대해 **예측 구간을 효율적으로 생성하기 어려움**
- 시계열의 교환가능성 가정이 타당하지 않음
- 데이터 분할로 인한 샘플 크기 감소 및 계산 비용 증가

#### 2.2 제안 방법과 수식

**문제 설정**:[1]

관측값은 다음 모델을 따릅니다:

$$
Y_t = f(X_t) + \epsilon_t, \quad t = 1, 2, \ldots
$$

여기서 $$\epsilon_t$$는 공통 누적분포함수(CDF) F를 따릅니다(독립성 불필요).

**예측 구간 구성**:[1]

$$
C^{\alpha}\_{T,t} := \hat{f}_{-t}(x_t) \pm (1-\alpha) \text{ quantile of } \{\hat{\epsilon}_i\}^{t-1}_{i=t-T}
$$

여기서 $$\hat{\epsilon}\_i = |y_i - \hat{f}_{-i}(x_i)|$$는 **Leave-One-Out(LOO) 예측 잔차**입니다[1].

**한계 적용률 보장**:[1]

$$
P(Y_t \in C^{\alpha}_{T,t}) \geq 1 - \alpha
$$

#### 2.3 EnbPI 알고리즘 구조

**Algorithm 1**의 핵심 절차:[1]

1. **부트스트랩 모델 훈련** (O(B)): B개의 부트스트랩 추정기 생성
2. **LOO 앙상블 구성**: 각 훈련 데이터 i에 대해, i를 제외한 모든 부트스트랩 모델을 집계하여 $$\hat{f}^{\phi}_{-i}$$ 생성
3. **잔차 계산**: $$\hat{\epsilon}^{\phi}_i$$를 계산하고 슬라이딩 윈도우로 유지
4. **순차적 예측 구간 생성**: 테스트 시점 t에서
   - 중심: $$\hat{f}^{\phi}_{-t}(x_t)$$ (LOO 앙상블 의 1-α 분위수)
   - 폭: 과거 T개 잔차의 (1-α) 분위수 $$w^{\phi}_t$$

**계산 효율성**: 순진한 LOO 방법은 O(BT) 비용이 들지만, EnbPI는 **O(B)** 비용으로 T개의 LOO 앙상블 추정기를 구성합니다.[1]

#### 2.4 이론적 보장

**가정**:[1]

- **가정 1**: 오류 프로세스 $$\{\epsilon_t\}_{t \geq 1}$$는 정상이고 강하게 혼합되며, 혼합 계수의 합이 M으로 제한됨
- **가정 2**: 추정기 품질 조건 - $$\sum^T_{t=1}(\hat{\epsilon}_t - \epsilon_t)^2/T \leq \delta^2_T$$ (단, $$\delta_T \to 0$$)

**주요 정리**:[1]

$$
|P(\hat{p}_{T+1} \leq \alpha) - \alpha| \leq 12C_1\left(\frac{\log T}{T}\right)^{1/3} + 2C_2\delta^{2/3}_T
$$

여기서:
- $$C_1 = (M/2)^{1/3}$$
- $$C_2 = L + 1$$
- 수렴 속도: $$O\left(\left(\frac{\log T}{T}\right)^{1/3} + \delta^{2/3}_T\right)$$

**수렴 속도 개선**: 가정을 강화하면 더 빠른 수렴이 가능합니다:[1]
- 독립 오류: $$O\left(\left(\frac{\log(16T)}{T}\right)^{1/2}\right)$$
- 선형 프로세스: $$O\left(\frac{\log T}{\sqrt{T}}\right)$$

***

### 3. 성능 향상 및 일반화 가능성

#### 3.1 성능 향상 측면

**실험 결과**:[1]

| 방법 | 적용률 | 구간 폭 | 비고 |
|------|-------|--------|------|
| EnbPI | ~90% (목표) | 중간 | 안정적, 모든 회귀 모델에서 유효 |
| ICP | <60% | 매우 짧음| 시계열에서 심각한 부적용 |
| WeightedICP | <60% | 짧음| 교환가능성 가정으로 인해 실패 |
| ARIMA | <80% (α 증가시 악화) | 가장 짧음| 작은 α에서 심각한 부적용 |

**EnbPI의 장점**:[1]

1. **작은 샘플 문제에 강함**: 훈련 데이터 크기(10%-28%)에 걸쳐 적용률 분산 최소
2. **강건성**: 결측 데이터(25% 손실)에서도 적용률 유지
3. **조건부 적용률 잠재력**: 특정 시간 구간(10AM-2PM)에서 조건부 적용률 달성 가능

#### 3.2 일반화 성능 향상 가능성

**일반화 개선의 핵심 메커니즘**:[1]

1. **앙상블 효과**: LOO 앙상블 구성이 함수 근사 오류를 감소시켜 **Assumption 2 조건** (추정기 품질)을 더 쉽게 만족합니다

2. **동적 캘리브레이션**: 슬라이딩 윈도우를 통해 새로운 관찰값을 활용하므로, 개념 드리프트(concept drift)나 데이터 시프트 상황에서도 적응적으로 구간 폭을 조정할 수 있습니다[1]

3. **오버피팅 회피**: 데이터 분할 없이도 LOO 부트스트랩 집계를 통해 자동으로 오버피팅을 피합니다[1]

**조건부 적용률 달성 가능성**:[1]

조건부 적용률 $$P(Y_t \in C^{\alpha}_{T,t}|X_t \in \mathcal{X}) \geq 1-\alpha$$는 한계 적용률보다 어렵지만:
- 실험에서 특정 조건(예: 시간 범위 제한, s 조정)에서 달성됨
- 이는 **비조건부 방법으로는 불가능**한 추가 장점입니다

**수렴 속도와 일반화**:[1]

- 비독립 오류에서도 $$O\left(\left(\frac{\log T}{T}\right)^{1/3}\right)$$ 속도는 실무에서 빠르게 작동
- 경험적으로 작은 T에서도 $$|P(\hat{p}_{T+1} \leq \alpha) - \alpha| \approx 0$$

#### 3.3 한계 (제약사항)

**Assumption 2의 도전**:[1]

- LOO 앙상블 추정기가 미지의 함수 f를 충분히 근사해야 함
- No Free Lunch 정리로 인해 모든 함수 클래스에 대해 성립하지 않음
- 앙상블 메커니즘이 이를 개선하지만, 이론적 분석은 모델 특정적

**개념 드리프트 처리 (Remark 2)**:[1]

- 변화점이 발생하면 f가 변하고, 사전 잔차가 사후 변화 구간을 캘리브레이션하는 데 부적절
- 배치 크기 s가 크면 커버리지 저하 가능 (그림 3에서 10AM-2PM 시간대 조건부 적용률 76%)

---

### 4. 미래 연구에 미치는 영향과 고려 사항

#### 4.1 이론적 기여

**기존 CP 이론의 확장**:[1]

EnbPI는 Chernozhukov et al.(2018, 2020)의 증명 기법을 정제하여 **수렴 속도를 개선**했습니다. 특히:
- 강 혼합 오류에서의 $$O((\log T/T)^{1/3})$$ 속도 달성
- 다양한 오류 구조에 대한 여러 추론(Corollary 1-3) 제시

**조건부 적용률 이론**:[1]

- 현재 한계 적용률에만 이론적 보장이 있음
- Barber et al.(2019a), Izbicki et al.(2020) 스타일의 **조건부 보장** 개발이 향후 과제

#### 4.2 실무 적용 가능성

**확장 가능한 응용 분야**:[1]

1. **이상 탐지**: 비지도 및 지도 학습 모두에 적용 가능 (ECAD 변형, F1 점수에서 경쟁 방법 능가)
2. **네트워크 예측**: 공간-시간 상관성을 고려하여 K개 노드에 동시 적용
3. **결측 데이터 처리**: 25% 손실에서도 안정적
4. **컴퓨터 비전**: 향후 연구로 분류 문제 확장 가능

#### 4.3 향후 연구 시 고려할 점

**1. 추정기 품질 분석 (Assumption 2 개선)**:[1]

- LOO 앙상블 예측기가 일반 앙상블보다 Assumption 2를 **더 잘 만족하는 이유**를 이론적으로 분석
- 이를 통해 Theorem 1의 상한을 더 타이트하게 개선 가능
- **특정 함수 클래스(부드러운 함수, 희소 모델 등)에서 $$\delta_T$$ 명시적 도출**

**2. 조건부 적용률 보장**:[1]

- 현재 한계 적용률 $$P(Y_t \in C^{\alpha}_{T,t}) \geq 1-\alpha$$에서 발전
- 조건부 보장 $$P(Y_t \in C^{\alpha}_{T,t}|X_t \in \mathcal{X}) \geq 1-\alpha$$ 이론화
- 환자의 나이 그룹 같은 부그룹별 정확한 구간 제공 가능

**3. 구간 폭 최적화**:[1]

- Oracle(최적) 구간과 추정 구간 폭의 편차 상한 제시 (Lei et al., 2018의 i.i.d. 케이스 일반화)
- 배치 크기 s 선택의 이론적 가이드라인 개발

**4. 개념 드리프트 적응**:[1]

- 변화점 근처에서 Assumption 2 위반 시 복구 메커니즘 개발
- 적응적 학습률 또는 가중 슬라이딩 윈도우 도입

**5. 분류 확장**:[1]

- 회귀에서 성공한 EnbPI를 분류, 특히 컴퓨터 비전 문제로 확장
- 신뢰도 집합(confidence sets) 생성

**6. 실무 배포 고려사항**:[1]

- 부트스트랩 개수 B의 선택 기준 (현재 B=20-30 경험적 제안)
- 배치 크기 s와 시스템 응답성의 트레이드오프 최적화
- 강제된 새 데이터 도착 지연 상황에서의 강건성

***

### 결론

**EnbPI**는 시계열 예측 불확실성 정량화의 **패러다임 전환**을 제시합니다. 교환가능성 가정을 제거하면서도 **이론적 보장, 계산 효율성, 실무 강건성**을 동시에 달성한 첫 번째 방법 중 하나입니다. 특히 **작은 샘플 환경에서의 안정성**과 **결측 데이터, 네트워크 구조, 비정상성 처리 능력**은 재생 에너지, 이상 탐지, 의료 예측 등 실제 응용에서 높은 가치를 제공합니다.[1]

앞으로의 연구는 **조건부 적용률 이론화**, **Assumption 2의 구체적 검증**, **개념 드리프트 적응**, **분류 문제 확장**에 집중할 것으로 예상되며, 이를 통해 **신뢰할 수 있는 기계학습 예측** 분야의 실무 표준화에 기여할 것입니다.[1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/7e9a236a-a418-4c08-953b-b0dc30506d3b/xu21h.pdf)
