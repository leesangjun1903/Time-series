# Recurrence Plot(RP)

재귀 도표(Recurrence Plot, RP)는 시계열 데이터나 동역학 시스템의 재귀성(Recurrence), 즉 "상태가 일정 시간 후에 다시 자기 자신과 유사한 상태로 돌아오는 성질"을 시각화하여 분석하는 기법입니다.

## 1. 핵심 개념: "상태의 재방문"
복잡한 시스템(예: 기상 데이터, 주가, 심박수 등)은 겉보기에 불규칙해 보여도 특정 패턴이 반복되는 경향이 있습니다.  
RP는 위상 공간(Phase Space) 상의 궤적이 과거에 지났던 지점 근처로 다시 돌아왔을 때를 점(Dot)으로 표시합니다.

## 2. 수학적 정의 
길이가 $\(N\)$ 인 상태 벡터 시퀀스 $\(\vec{x}\_{i}\)$ 에 대하여, RP를 나타내는 행렬 $\(R_{i,j}\)$ 는 다음과 같이 정의됩니다. 

$$\(R_{i,j}=\Theta (\epsilon -\|\vec{x}\_{i}-\vec{x}\_{j}\|)\)$$ 

- $\(\vec{x}\_{i},\vec{x}_{j}\)$ : 시간 $\(i\)$ 와 $\(j\)$ 에서의 시스템 상태 벡터.
- $\(\|\cdot \|\)$ : 두 상태 사이의 거리(주로 유클리드 거리).
- $\(\epsilon \)$ : 임계값(Threshold). 이 거리보다 가까우면 "재귀했다"고 판단합니다.
- $\(\Theta \)$ : 헤비사이드 계단 함수(Heaviside function). 조건이 맞으면 1(검은 점), 아니면 0(흰 점)을 반환합니다.

재귀 도표(Recurrence Plot, RP)의 작동 원리를 위상 공간 재구성부터 거리 행렬 연산까지 단계별 수식과 함께 전문적으로 설명해보겠습니다.

### 단계 1: 위상 공간 재구성 (Phase Space Reconstruction)
대부분의 관측 데이터는 1차원 시계열 $\(x(t)\)$ 형태입니다.  
하지만 시스템의 전체 동역학을 파악하려면 다차원 상태 공간으로 확장해야 합니다.  
이때 타임 딜레이 임베딩(Time Delay Embedding) 기법을 사용합니다.  
관측된 시계열 $\(s=\{s_{1},s_{2},...,s_{n}\}\)$ 이 있을 때, 재구성된 상태 벡터 $\(\vec{x}\_{i}\)$ 는 다음과 같습니다. 

$$\vec{x}\_{i}=[s_{i},s_{i+\tau },s_{i+2\tau },\dots ,s_{i+(m-1)\tau }]$$ 

- $\(m\)$ (Embedding Dimension): 임베딩 차원. 시스템의 자유도를 결정합니다.
- $\(\tau \)$ (Time Delay): 시간 지연. 데이터 간의 독립성을 확보하기 위한 간격입니다.
이렇게 생성된 $\(\vec{x}_{i}\)$ 는 $\(m\)$ 차원 공간상의 한 점이 됩니다.

#### 어떻게 계산하나요?

타임 딜레이 임베딩을 통한 상태 벡터 $\(\vec{x}_{i}\)$ 의 계산은 주어진 시계열 데이터에서 일정한 간격 $(\(\tau \))$ 으로 $\(m\)$ 개의 데이터를 뽑아 하나의 묶음(벡터)으로 만드는 과정입니다.

#### 1단계: 파라미터 결정 및 생성 가능 벡터 수 파악 
먼저 임베딩 차원 $\(m\)$ 과 시간 지연 $\(\tau \)$ 를 정해야 합니다.  
전체 시계열 데이터의 개수가 $\(n\)$ 개일 때, 마지막 벡터의 마지막 원소 인덱스가 $\(n\)$ 을 넘지 않아야 하므로, 생성 가능한 벡터의 총 개수 $\(N_{vec}\)$ 는 다음과 같습니다.

$`N_{vec}=n-(m-1)\tau `$ 

따라서 인덱스 $\(i\)$ 는 $\(1\)$ 부터 $\(N_{vec}\)$ 까지 변하며 각 벡터를 생성합니다.

이 수식은 "마지막 벡터 $(\(\vec{x}\_{i}\))$ 를 만들 때, 시계열 데이터의 끝 $(\(s_{n}\))$ 을 넘어가지 않아야 한다"는 제약 조건에서 도출됩니다.

##### 직관적인 이유 
하나의 벡터 $\(\vec{x}\_{i}\)$ 를 구성하기 위해서는 단순히 현재 시점의 데이터 $\(s_{i}\)$ 만 필요한 것이 아니라, 미래의 데이터들 $(\(s_{i+\tau },s_{i+2\tau },\dots \))$ 을 빌려와야 합니다.  
벡터 하나를 만드는 데 쓰이는 가장 먼 미래의 인덱스는 $\(\vec{x}_{i}\)$ 의 수식에서 마지막 항인 $\(i+(m-1)\tau \)$ 입니다.  
이 값이 우리가 가진 데이터의 전체 개수 $\(n\)$ 보다 커지면 데이터를 구할 수 없어 벡터를 만들지 못합니다. 

###### $\(i+(m-1)\tau \)$ 가 갑자기 튀어나왔는데?

$\(i\)$ 번째 시점부터 시작하여 $\(\tau \)$ 간격으로 총 $\(m\)$ 개의 데이터를 뽑았을 때, 마지막 데이터가 위치한 지점이 시작점으로부터 $\((m-1)\)$ 번의 간격만큼 떨어져 있기 때문입니다. 

###### 벡터 내 원소의 인덱스 나열 
벡터 $\(\vec{x}\_{i}\)$ 는 $\(m\)$ 차원이므로 총 $\(m\)$ 개의 원소를 가집니다.  
각 원소의 인덱스를 순서대로 나열하면 다음과 같습니다. 
- 1번째 원소: $\(s_{i}=s_{i+0\tau }\)$
- 2번째 원소: $\(s_{i+\tau }=s_{i+1\tau }\)$
- 3번째 원소: $\(s_{i+2\tau }=s_{i+2\tau }\)...$
- $\(k\)$ 번째 원소: $\(s_{i+(k-1)\tau }\)$ 

###### 등차수열 원리 적용 
각 원소의 인덱스는 시작점 $\(i\)$ 에서 공차가 $\(\tau \)$ 인 등차수열을 이룹니다.  
$\(k\)$ 번째 항의 일반항은 다음과 같이 표현됩니다. : $\(Index(k)=i+(k-1)\tau \)$ 

벡터의 마지막 원소는 $\(m\)$ 번째 원소이므로, $\(k\)$ 대신 $\(m\)$ 을 대입하면 마지막 인덱스가 도출됩니다. : $\(Index(m)=i+(m-1)\tau \)$

###### 간격(Interval)의 개수 이해 
$\(m\)$ 개의 점을 일정한 간격으로 배치하면 점 사이의 간격(Gap)은 $\((m-1)\)$ 개가 생깁니다.  
예를 들어, 나무 3그루 $(\(m=3\))$ 를 2m 간격 $(\(\tau =2\))$ 으로 심으면 첫 번째 나무와 마지막 나무 사이의 거리는 간격 2개분인 $\(2\times 2=4\)$ m가 됩니다.  
즉, 시작 인덱스 $\(i\)$ 로부터 $\((m-1)\)$ 번의 $\(\tau \)$ 만큼 더 나아간 지점이 가장 먼 미래의 데이터 위치가 됩니다.

벡터 $\(\vec{x}_{i}\)$ 는 시점 $\(i\)$ 에서 시작하여 $\(\tau \)$ 크기의 간격을 총 $\((m-1)\)$ 번 건너뛰어 $\(m\)$ 개의 데이터를 채우기 때문에, 마지막 항의 인덱스는 $\(i+(m-1)\tau \)$ 가 됩니다.  
이는 해당 벡터를 구성하기 위해 참조해야 하는 가장 마지막(미래) 시점의 데이터를 의미합니다.

##### 인덱스 개수 수식 유도 과정 
우리가 만들 수 있는 마지막 벡터의 인덱스를 $\(i_{max}\)$ 라고 할 때, 다음 부등식이 성립해야 합니다. 

$$\(i_{max}+(m-1)\tau \le n\)$$ 

이 식을 $\(i_{max}\)$ 에 대해 정리하면 다음과 같습니다. 

$$\(i_{max}\le n-(m-1)\tau \)$$ 

따라서 인덱스 $\(i\)$ 가 1부터 시작한다면, 생성 가능한 벡터의 총 개수 $(\(N_{vec}\))는 \(n-(m-1)\tau \)$ 개가 됩니다. 

##### 쉬운 예시 
데이터가 총 10개 $(\(n=10\))$ 있고, 임베딩 차원 $\(m=3\)$ , 시간 지연 $\(\tau =2\)$ 라고 가정해 봅시다.  

- $\(\vec{x}\_{1}=[s_{1},s_{3},s_{5}]\)$ (가능)
- $\(\vec{x}\_{2}=[s_{2},s_{4},s_{6}]\)$ (가능)
- $\(\vec{x}\_{3}=[s_{3},s_{5},s_{7}]\)$ (가능)
- $\(\vec{x}\_{4}=[s_{4},s_{6},s_{8}]\)$ (가능)
- $\(\vec{x}\_{5}=[s_{5},s_{7},s_{9}]\)$ (가능)
- $\(\vec{x}\_{6}=[s_{6},s_{8},s_{10}]\)$ (가능, 마지막)
- $\(\vec{x}\_{7}=[s_{7},s_{9},s_{11}]\)$ (불가능, $\(s_{11}\)$ 이 없음) 

수식 적용: $\(N_{vec}=10-(3-1)\times 2=10-4=6\)$  
실제로 위에서 확인한 것처럼 딱 6개의 벡터만 생성됩니다.

##### 결론 
$\((m-1)\tau \)$ 는 하나의 벡터를 완성하기 위해 현재 시점 $(\(i\))$ 으로부터 추가적으로 필요한 데이터의 길이를 의미합니다.  
전체 길이 $\(n\)$ 에서 이 '추가 필요분'만큼을 뺀 지점까지만 벡터의 시작점 $(\(i\))$ 이 될 수 있기 때문입니다.

### 단계 2: 거리 행렬(Distance Matrix) 계산 
재구성된 모든 상태 벡터들 사이의 거리를 계산합니다.  
시간 $\(i\)$ 일 때의 상태와 시간 $\(j\)$ 일 때의 상태가 얼마나 닮았는지(가까운지)를 수치화하는 과정입니다. 

$$\(D_{i,j}=\|\vec{x}\_{i}-\vec{x}_{j}\|\)$$ 

- $\(\|\cdot \|\)$ 은 일반적으로 유클리드 거리(Euclidean norm) 또는 최대 거리(Supremum norm)를 사용합니다.
- 이 결과로 $\(N\times N\)$ 크기의 대칭 행렬이 생성됩니다.

### 단계 3: 임계값 적용 및 이진화 (Thresholding) 
RP의 핵심은 "충분히 가까우면 재귀(Recurrence)한 것으로 간주한다"는 점입니다.  
거리 행렬에 임계값 $\(\epsilon \)$ 을 적용하여 앞서 소개된 수학적 정의에 따른 이진 행렬 $\(R_{i,j}\)$ 를 만듭니다. 

$`R_{i,j}=\Theta (\epsilon -\|\vec{x}_{i}-\vec{x}_{j}\|),\quad i,j=1,\dots ,N`$ 

- $\(\Theta (x)\)$ (Heaviside Step Function):
  - $\(x\ge 0\)$ 이면 $\(1\)$ (검은 점: 재귀 발생)
  - $\(x<0\)$ 이면 $\(0\)$ (흰 점: 재귀 없음)
- $\(\epsilon \)$ (Threshold): 노이즈 레벨보다는 크고, 시스템 변동 폭보다는 작게 설정해야 합니다. (보통 전체 표준편차의 5~10% 수준) 

## RP의 주요 패턴 해석
RP를 통해 시각화된 이미지의 기하학적 구조를 통해 데이터의 특성을 파악할 수 있습니다.  

### 대각선 패턴 $(\(l\))$ : "미래의 변화 양상이 과거와 닮았다"
- 대각선 패턴 (Diagonal Lines): 시스템의 국소적 궤적이 평행하게 이동함을 의미합니다. 대각선이 길수록 시스템의 결정론적(Deterministic) 성격이 강하며 예측 가능성이 높습니다.

$\(R_{i,i}\)$ 는 항상 1입니다. 자기 자신과의 거리는 0이므로 $\(\epsilon \)$ 보다 항상 작기 때문입니다. 이를 LOI (Line of Identity)라고 부르며, RP의 정중앙을 가르는 주 대각선이 됩니다.

$`R_{i+k,j+k}=1\quad \text{for\ }k=1,\dots ,l`$ 

위 수식은 시간 $\(i\)$ 에서의 궤적과 시간 $\(j\)$ 에서의 궤적이 $\(l\)$ 이라는 시간 동안 평행하게 이동했음을 의미합니다.

  - 결정론적 시스템: 시스템이 법칙을 가지고 움직이면 이런 평행 궤적이 자주 나타나 긴 대각선이 형성됩니다.
  - 카오스 시스템: 대각선이 나타나지만, 궤적이 금방 멀어지기 때문에 대각선의 길이가 짧습니다.

대각선 패턴은 시간 $\(i\)$ 일 때 일어났던 변화의 흐름(궤적)이, 훨씬 나중인 시간 $\(j\)$ 에서 똑같이 반복될 때 나타납니다.

  - 시계열 상의 흐름: $\(s_{i},s_{i+1},s_{i+2}\)$ 의 변화 모습이 $\(s_{j},s_{j+1},s_{j+2}\)$ 와 매우 유사합니다.
  - 물리적 의미: 시스템이 결정론적(Deterministic)으로 작동하고 있음을 뜻합니다. 예를 들어 시계추가 왔다 갔다 할 때, 어제 오후 1시의 움직임과 오늘 오후 1시의 움직임이 평행하게 진행되는 것과 같습니다.

### 수직/수평 패턴 $(\(v\))$ : "상태가 변하지 않고 멈춰 있다"
- 수직/수평 패턴 (Vertical/Horizontal lines): 시스템이 특정 상태에 오랫동안 머물러 있음을 의미합니다 (Laminar states). 층류(Laminarity) 현상이나 간헐성(Intermittency)을 분석할 때 중요합니다.

$`R_{i,j+k}=1\quad \text{for\ }k=1,\dots ,v`$

시간 $\(i\)$ 에서의 상태가 변화하지 않고 $\(v\)$ 시간 동안 특정 상태(또는 좁은 영역)에 머물러 있음을 의미합니다. 시스템의 정지 상태(Laminar states) 또는 간헐성을 나타냅니다. 

수직 또는 수평선은 특정 시간 $\(i\)$ 의 상태가 고정되어 있는데, 시간 $\(j\)$ 가 $\(j+1,j+2,\dots \)$ 로 흘러가도 계속 $\(i\)$ 시점의 상태와 비슷한 값을 유지할 때 나타납니다.

  - 시계열 상의 흐름: $\(s_{j},s_{j+1},s_{j+2},\dots \)$ 값들이 거의 변하지 않고 일정하게 유지됩니다(Laminar phase). 즉, 데이터가 정체(Stagnation)된 구간입니다.
  - 물리적 의미: 시스템이 층류(Laminar) 상태에 있거나, 일시적으로 평형 상태에 머물러 있음을 뜻합니다. 화학 반응에서 평형을 유지하거나, 심박수가 일정 구간 동안 거의 변하지 않고 고정된 상태일 때 발생합니다.

#### 왜 혼동될 수 있나요?
만약 시계열 데이터가 아주 느리게 변하는 상수값이라면, 대각선과 수직선이 동시에 나타나면서 격자 모양이나 굵은 블록 형태를 띠게 됩니다.  
이 경우 "변화의 반복(대각선)"과 "상태의 유지(수직선)"가 동시에 일어나기 때문입니다.

결론적으로, 대각선은 "예전에 했던 행동을 지금 다시 똑같이 하고 있다"는 뜻이고, 수직/수평선은 "지금 이 상태에서 한참 동안 안 변하고 있다"는 뜻으로 구분하시면 정확합니다.

### 균일한 분포 (Uniformly distributed dots): 화이트 노이즈(White noise)와 같은 무작위 프로세스에서 나타납니다.
### 주기적 격자 (Faded/Grid patterns): 시스템이 주기적인 진동을 하고 있음을 나타냅니다.

#### 요약: 알고리즘 흐름도 
- 입력: 1차원 시계열 데이터 $\(s(t)\)$
- 임베딩: 파라미터 $\(m,\tau \)$ 를 사용하여 $\(m\)$ 차원 벡터 $\(\vec{x}\_{i}\)$ 생성
- 거리 측정: 모든 $\(i,j\)$ 쌍에 대해 $\(\|\vec{x}\_{i}-\vec{x}_{j}\|\)$ 계산
- 이진화: 임계값 $\(\epsilon \)$ 을 기준으로 $\(1\)$ 또는 $\(0\)$ 부여
- 시각화: $\(1\)$인 지점에 점을 찍어 $\(N\times N\)$ 평면에 표시

이 과정을 거치면 복잡한 수치 데이터가 기하학적 패턴으로 변환되어, 인간의 눈이나 머신러닝 모델이 시스템의 특성(주기성, 카오스성, 노이즈 등)을 쉽게 파악할 수 있게 됩니다.

## 4. 왜 사용하는가? (전문적 용도)
- 비선형 분석: 전통적인 선형 분석(Fourier Transform 등)으로 찾기 힘든 데이터 내의 숨겨진 비선형 구조를 파악합니다.
- 짧고 노이즈 섞인 데이터: 데이터의 길이가 충분하지 않거나 노이즈가 많아도 시스템의 동역학적 특성을 비교적 정확하게 추출할 수 있습니다.
- RQA (Recurrence Quantification Analysis): RP에서 나타나는 점들의 밀도, 대각선 길이 등을 수치화하여 시스템의 복잡도, 엔트로피, 결정론적 정도를 정량적으로 계산합니다.

### RQA(Recurrence Quantification Analysis) 
RQA(Recurrence Quantification Analysis)는 재귀 도표(RP)에 나타난 복잡한 점들의 분포를 수치화하여, 시스템의 동역학적 특성(결정론, 복잡성, 정지 상태 등)을 객관적으로 측정하는 정량적 분석 기법입니다.

RP가 "눈으로 보는 패턴"이라면, RQA는 그 패턴을 "데이터로 요약"하는 과정입니다.

#### RR (Recurrence Rate, 재귀율) 
전체 행렬에서 점(Recurrence point)이 찍힌 비율입니다. 
- 수식: $\(RR=\frac{1}{N^{2}}\sum_{i,j=1}^{N}R_{i,j}\)$
- 의미: 시스템 내에서 재귀 상태가 얼마나 자주 발생하는지 나타내는 밀도입니다.

#### DET (Determinism, 결정론) 
전체 점들 중 대각선(Diagonal line) 구조를 형성하는 점들의 비율입니다.  
2026년 현재에도 비선형 동역학 분석에서 시스템의 규칙성을 판단하는 핵심 지표로 쓰입니다. 
- 수식: $\(DET=\frac{\sum_{l=l_{min}}^{N}lP(l)}{\sum_{i,j=1}^{N}R_{i,j}}\)$

  - ( $\(P(l)\)$ : 길이가 $\(l\)$ 인 대각선의 개수)

- 의미: 시스템이 얼마나 법칙에 따라 움직이는지 보여줍니다. 카오스 시스템은 DET가 높게 나타나지만, 완전한 무작위 노이즈는 대각선이 거의 없어 DET가 0에 가깝습니다.

#### $\(L\)$ (Average Diagonal Line Length, 평균 대각선 길이) 
형성된 대각선들의 평균적인 길이입니다. 

- 의미: 시스템의 예측 가능성(Predictability)과 직결됩니다. 대각선이 길다는 것은 두 궤적이 오랜 시간 동안 비슷하게 이동했다는 뜻이므로, 미래 상태를 예측하기가 상대적으로 수월함을 의미합니다.

#### LAM (Laminarity, 층류성) 
전체 점들 중 수직선(Vertical line) 구조를 형성하는 점들의 비율입니다. 

- 수식: $\(LAM=\frac{\sum_{v=v_{min}}^{N}vP(v)}{\sum_{i,j=1}^{N}R_{i,j}}\)$
  - ( $\(P(v)\)$ : 길이가 $\(v\)$ 인 수직선의 개수)

- 의미: 시스템이 특정 상태에 머물러 있는 정체성을 나타냅니다. 특정 상태에서의 정체(Laminar) 현상이 잦고 간헐성(Intermittency)이 강한 시스템일수록 이 수치가 높습니다.

#### ENTR (Entropy, 엔트로피) 
대각선 길이 분포 $(\(P(l)\))$ 의 복잡성을 샤논 엔트로피(Shannon entropy)로 계산한 값입니다. 
- 의미: 대각선 길이들이 얼마나 다양하게 분포하는지를 나타냅니다. 엔트로피가 높을수록 시스템의 반복 패턴이 복잡하고 정교하다는 것을 의미합니다.

#### 전문적 활용:
- 심장 박동(ECG) 분석: 부정맥 발생 전후의 RR, DET 변화를 통해 전조 증상 감지.
- 금융 시장: 주가 지수의 RP를 분석하여 시장이 효율적(무작위)인지, 특정 세력이나 규칙에 의한 결정론적 흐름이 있는지 판별.
- 지진/기상 데이터: 기후 변화의 임계점(Tipping point)에서 나타나는 정체 현상을 LAM 수치로 포착.

RQA 분석을 수행할 때는 Python의 PyRQA 라이브러리나 R의 crqa 패키지를 사용하면 위 수식들을 자동으로 계산할 수 있습니다.

## 관련 도구 및 학습 자원
실제 분석을 위해서는 Python이나 R의 라이브러리를 활용하는 것이 좋습니다. 
- Python: PyRQA 또는 Giotto-tda를 통해 시계열 데이터를 RP로 변환할 수 있습니다.
- 상세 이론: RP에 대한 가장 권위 있는 정보는 Recurrence-plot.tk에서 확인할 수 있습니다.
요약하자면, RP는 시계열 데이터를 2차원 이미지로 변환하여 그 안에 숨겨진 반복 패턴과 동역학적 규칙성을 시각적·정량적으로 분석하는 강력한 도구입니다.

## 단점
재귀 도표(Recurrence Plot, RP)와 그 정량적 분석법(RQA)은 비선형 데이터 분석에 강력한 도구이지만, 실무 및 연구 적용 시 다음과 같은 명확한 단점과 한계가 존재합니다.

### 파라미터 설정에 대한 높은 의존도 (Sensitivity to Parameters) 
RP의 결과는 분석자가 설정하는 세 가지 핵심 파라미터( $\(m,\tau ,\epsilon \)$ )에 따라 극적으로 변합니다. 
- 임계값( $\(\epsilon \)$ ) 결정의 어려움: $\(\epsilon \)$ 을 너무 작게 잡으면 점이 찍히지 않아 정보를 잃고, 너무 크게 잡으면 모든 곳에 점이 찍혀 구조가 왜곡됩니다. "적절한 $\(\epsilon \)$"에 대한 절대적인 기준이 없어 시행착오가 필요합니다.
- 임베딩 파라미터: $\(m\)$ (차원)과 $\(\tau \)$ (지연 시간)를 잘못 설정하면 위상 공간이 제대로 재구성되지 않아, 잘못된 물리적 해석을 낳을 수 있습니다. 

### 계산 복잡도 및 메모리 문제 (Computational Cost) 
데이터의 길이가 $\(N\)$ 일 때, RP는 $\(N\times N\)$ 크기의 행렬을 생성합니다. 
- 메모리 점유: 시계열 데이터가 조금만 길어져도(예: $\(N=100,000\)$ ) 필요한 메모리가 기하급수적으로 늘어납니다( $\(10^{10}\)$ 개 요소). 2026년 현재 고성능 컴퓨팅 환경에서도 초고주파 데이터나 장기 시계열을 실시간으로 처리하기에는 부담이 큽니다.
- 연산 속도: 모든 점 쌍 간의 거리( $\(N^{2}\)$ )를 계산해야 하므로 연산 시간이 오래 걸립니다.

### 정지성(Stationarity) 가정의 한계
RP는 기본적으로 시스템의 동역학이 일정하다는 가정하에 패턴을 찾습니다.  
시계열에 강한 추세(Trend)가 있거나, 시간이 지남에 따라 시스템의 성질 자체가 변하는 비정지성(Non-stationary) 데이터의 경우, RP 상에서 한쪽 구석으로 점이 몰리거나 패턴이 왜곡되어 나타납니다.  
이를 해결하기 위해 데이터를 사전에 미분하거나 추세를 제거하는 전처리가 필수적입니다.

### 정량적 지표(RQA)의 상호 의존성 
RQA를 통해 산출되는 $\(DET,L,ENTR\)$ 등의 지표들은 서로 완전히 독립적이지 않습니다.  
예를 들어, 재귀율 $(\(RR\))$ 이 변하면 $\(DET\)$ 수치도 함께 영향을 받는 경우가 많습니다.  
이로 인해 특정 수치의 변화가 시스템의 순수한 결정론적 변화 때문인지, 단순히 데이터 밀도의 변화 때문인지 구별하기 어려운 해석의 모호성이 발생할 수 있습니다.

### 노이즈(Noise)에 대한 취약성 
RP는 노이즈에 비교적 강하다고 알려져 있으나, 관측 노이즈(Observational Noise)가 매우 클 경우 대각선 구조가 끊어지게 됩니다.  
대각선이 미세하게 끊어지면 $\(DET\)$ 나 $\(L\)$ 수치가 급격히 하락하여, 실제로는 결정론적인 시스템임에도 불구하고 무작위 시스템(Stochastic system)으로 오인할 위험이 있습니다.

RP는 "파라미터 설정이 까다롭고 대용량 데이터 처리에 비효율적"이라는 단점이 있습니다.  
따라서 이를 보완하기 위해 2026년 현재는 앙상블 기법이나 딥러닝(CNN)의 입력 데이터로 RP 이미지를 활용하여 패턴 인식의 정확도를 높이는 방향으로 단점을 극복하고 있습니다.

## 해결 방법
재귀 도표(RP)의 고질적인 문제인 파라미터 의존성, 계산 복잡도, 노이즈 취약성을 해결하기 위해 2026년 현재 학계와 산업계에서 주로 사용되는 진화된 기법들을 소개합니다.

### 1. 파라미터 설정을 자동화한 기법: Unthresholded RP 
가장 큰 단점인 임계값 $(\(\epsilon \))$ 설정 문제를 해결하기 위해, 이진화(0 또는 1) 과정을 생략합니다.  
- 작동 원리: 거리 행렬 $\(D_{i,j}\)$ 를 그대로 이미지화하거나, 거리의 역수를 취하여 Recurrence Matrix를 연속적인 값으로 유지합니다.
- 장점: 정보를 손실하지 않으며, 최근에는 이 연속적인 거리 행렬을 CNN(합성곱 신경망)의 입력값으로 바로 사용하여 딥러닝 모델이 스스로 특징을 추출하게 합니다.

### 2. 계산 복잡도를 해결한 기법: 가시성 그래프 (Visibility Graph, VG) 
$\(N\times N\)$ 연산의 부담을 줄이고자 시계열을 네트워크(그래프) 형태로 변환하는 방식입니다. 
- 작동 원리: 시계열의 각 데이터 포인트를 노드(Node)로 간주하고, 두 지점 사이에 다른 데이터가 가리지 않아 서로 "보이는" 경우에만 연결(Edge)합니다.
- 해결책: RP보다 계산량이 적으면서도 시스템의 카오스적 특성을 잘 보존합니다. Visibility Graph 관련 연구를 통해 시계열의 위상적 성질을 더 빠르게 파악할 수 있습니다.

### 3. 노이즈 및 비정지성 문제를 해결한 기법: Joint/Cross Recurrence Plot (CRP/JRP)
단일 시계열의 한계를 넘어 두 개 이상의 시계열을 비교함으로써 노이즈 영향을 상쇄합니다.
- 작동 원리: 두 개의 서로 다른 시스템(예: 심박수와 호흡량) 간의 재귀를 분석합니다.
- 해결책: 서로 다른 두 데이터가 동시에 같은 패턴을 보일 때만 점이 찍히므로, 개별 데이터에 포함된 무작위 노이즈를 효과적으로 필터링하고 시스템 간의 동기화(Synchronization) 정도를 정확히 측정할 수 있습니다.

### 4. 고차원 데이터 처리를 위한 위상적 데이터 분석 (TDA) 
RP의 기초가 되는 '위상 공간 재구성' 자체의 한계를 수학적으로 극복한 기법입니다. 
- 작동 원리: 지속적 호몰로지(Persistent Homology)를 사용하여 데이터의 형태(구멍, 연결성 등)가 임계값 변화에 따라 어떻게 유지되는지 분석합니다.
- 해결책: 특정 $\(\epsilon \)$ 하나에 의존하지 않고, 모든 가능한 임계값 범위에서의 구조적 안정성을 측정하므로 파라미터 민감도 문제에서 매우 자유롭습니다.
Python의 Giotto-tda 라이브러리가 대표적인 구현체입니다. 

### 5. 인공지능 결합형 기법: RP-CNN (Hybrid Approach)
2026년 기준 가장 실무적인 해결책으로, RP를 별도로 해석하지 않고 이미지 분류 문제로 치환합니다.
- 작동 원리: 시계열을 RP로 변환한 후, 이를 ResNet이나 EfficientNet 같은 이미지 인식 AI에 학습시킵니다.
- 해결책: 인간이 RQA 지표를 정하고 계산할 필요 없이, AI가 이미지 내의 미세한 패턴(노이즈 섞인 대각선 등)을 스스로 학습하여 정상/이상을 분류합니다. 파라미터가 조금 틀려도 AI의 일반화 성능으로 이를 극복합니다.

##
- 파라미터 설정이 너무 귀찮다면? → TDA (위상적 데이터 분석)
- 데이터가 너무 커서 계산이 느리다면? → Visibility Graph
- 정확한 분류 성능이 최우선이라면? → RP + CNN 딥러닝 결합
- 두 데이터 사이의 관계를 보고 싶다면? → Cross Recurrence Plot

단순히 RP의 단점을 보완하는 것을 넘어, 분석 목적에 맞춰 위 기법들을 혼합하여 사용하는 것이 현대적인 비선형 분석의 추세입니다.

Python의 Scikit-kinematics 등의 도구를 활용하면 이러한 발전된 기법들을 실습해 볼 수 있습니다.

## 다변량 시계열일 경우 대응방법
다변량 시계열 데이터(Multivariate Time Series)는 여러 변수가 서로 상호작용하며 시스템의 상태를 결정하므로, 단일 변수 분석보다 훨씬 복잡합니다.

### 1. 다변량 재귀 도표 (Multivariate Recurrence Plot, MRP) 
기존 RP를 다변량으로 확장한 가장 직접적인 방법입니다. 
- 작동 원리: 각 변수별로 위상 공간을 재구성한 후, 모든 변수의 상태를 결합한 고차원 통합 상태 벡터를 만듭니다.
  - $\(\vec{X}\_{total}(t)=[\vec{x}\_{1}(t),\vec{x}\_{2}(t),\dots ,\vec{x}_{d}(t)]\)$
  - 이 통합 벡터들 사이의 거리를 계산하여 하나의 RP를 생성합니다.

- 장점: 여러 변수 간의 복합적인 상호의존성을 하나의 도표로 요약할 수 있습니다.
- 적합한 경우: 변수들이 서로 밀접하게 연관되어 하나의 시스템(예: 로봇 팔의 각 관절 데이터, 엔진의 온도와 압력 등)을 이룰 때 유리합니다.

### 2. 교차 재귀 도표 (Cross Recurrence Plot, CRP) 
두 변수(또는 두 시스템) 사이의 동기화 및 유사성을 분석하는 데 특화된 기법입니다. 
- 작동 원리: 변수 A의 궤적과 변수 B의 궤적을 비교하여, "A의 과거 상태가 B의 현재 상태와 얼마나 닮았는가"를 점으로 찍습니다.
  - $\(R\_{i,j}^{AB}=\Theta (\epsilon-\|\vec{x}\_{i}^{A}-\vec{x}_{j}^{B}\|)\)$
- 장점: 변수들 사이의 시차(Time lag)나 리드-랙(Lead-lag) 관계를 파악하기 좋습니다.
- 적합한 경우: 원인과 결과 관계가 있는 변수들(예: 마케팅 비용과 매출액, 미세먼지 농도와 호흡기 질환자 수) 분석에 탁월합니다.

### 3. 다층 재귀 네트워크 (Multilayer Recurrence Networks, MRN)
최근 복잡계 과학에서 가장 주목받는 기법으로, 각 변수를 별도의 레이어(Layer)로 구성하는 방식입니다.
- 작동 원리:
  - 각 변수마다 개별적인 RP를 생성합니다.
  - 각 RP를 네트워크(그래프)로 변환합니다.
  - 이 네트워크들을 층층이 쌓고(Multilayer), 층 사이의 연결성(Inter-layer coupling)을 계산합니다.
- 장점: 특정 변수가 전체 시스템의 붕괴나 변화를 주도하는지(중요도 평가)를 통계적으로 파악할 수 있습니다.
- 적합한 경우: 변수 개수가 매우 많고(예: 수백 개의 주식 종목, 뇌의 여러 부위 신호), 각 변수의 개별 특성과 전체 구조를 동시에 봐야 할 때 가장 강력합니다.

### 4. 실무적 추천: 딥러닝 결합 모델 (MTF-CNN) 
만약 분석 목적이 '예측'이나 '분류'라면, 시계열을 Markov Transition Field (MTF)나 Gramian Angular Field (GAF)를 통해 다채널 이미지로 변환한 후 CNN에 넣는 방식이 2026년 현재 표준입니다. 
- 방법: $\(d\)$ 개의 변수를 각각 이미지로 변환하여 $\(d\)$ 개의 채널(RGB 채널처럼)을 가진 입력 데이터로 만듭니다.
- 효과: 다변량 데이터 사이의 복잡한 상관관계를 AI가 스스로 학습하므로, 사람이 직접 RQA 지표를 계산하는 것보다 정확도가 압도적으로 높습니다. 

##
- 변수 간 통합적인 규칙성을 보고 싶다 → MRP (Multivariate RP)
- 두 변수 사이의 인과관계/동기화가 중요하다 → CRP (Cross RP)
- 변수가 매우 많고 복잡한 네트워크 구조를 가진다 → MRN (Multilayer Network)
- 성능 좋은 예측/분류 모델이 필요하다 → 다채널 GAF/MTF + CNN

가장 범용적인 시작점은 MRP이며, Python의 PyRQA 라이브러리를 사용하여 다차원 벡터를 입력하면 쉽게 구현할 수 있습니다. 
