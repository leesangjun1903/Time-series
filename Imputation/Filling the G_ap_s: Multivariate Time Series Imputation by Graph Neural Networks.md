# Filling the G_ap_s: Multivariate Time Series Imputation by Graph Neural Networks

## 1. 핵심 주장 및 주요 기여[1]

**GRIN(Graph Recurrent Imputation Network)** 논문은 다변량 시계열 데이터의 결측값 복원 문제를 해결하기 위해 그래프 신경망(GNN)을 처음으로 체계적으로 적용한 연구입니다. 논문의 핵심 주장은 다음과 같습니다.[1]

기존 딥러닝 기반 결측값 대체 방법들이 센서 간의 관계 정보(relational information)와 비선형 시공간 종속성을 충분히 활용하지 못한다는 점을 지적합니다. 논문은 **메시지 패싱 신경망(MPNN)의 구조적 귀납 편향(structural inductive bias)**을 활용하면, 센서 네트워크에서의 기능적 종속성을 효과적으로 학습할 수 있다고 주장합니다.[1]

주요 기여는 다음 세 가지입니다:[1]

1. 다변량 시계열 결측값 복원(MTSI) 문제에 GNN을 적용하기 위한 방법론적 프레임워크 제시
2. 양방향 재귀적 구조와 메시지 패싱 게이트를 결합한 새로운 GRIN 아키텍처 제안
3. 다양한 실제 벤치마크 데이터셋에서 기존 최고 성능 방법을 20% 이상의 평균절대오차(MAE) 개선으로 능가

---

## 2. 문제 정의, 제안 방법 및 모델 구조

### 문제 정의[1]

다변량 시계열 결측값 복원의 공식적 정의는 다음과 같습니다.[1]

시간 단계 $$t$$에서 $$N_t$$개의 노드를 가진 가중 방향 그래프 $$G_t = (X_t, W_t)$$를 고려합니다. 여기서:
- $$X_t \in \mathbb{R}^{N_t \times d}$$: 노드 속성 행렬 (센서 측정값)
- $$W_t \in \mathbb{R}^{N_t \times N_t}$$: 인접 행렬 (센서 간의 관계)
- $$M_t \in \{0,1\}^{N_t \times d}$$: 이진 마스크 (결측값 표시)

결측값 복원 오차는 다음 식으로 정의됩니다:[1]

$$
\mathcal{L}(X_{t}^*, M_t) = \sum_{t} \sum_{h} \sum_{i}^{N} m_t^{i,h} \rho(x_t^{i,h}, \hat{x}_t^{i,h})
$$

여기서 $$\rho$$는 원소별 오류 함수(MAE 또는 MSE)이고, $$\hat{x}_t^{i,h}$$는 복원된 값입니다.[1]

문제 가정사항:
- **Missing at Random(MAR)** 설정 가정
- 데이터 분포의 정상성(stationarity) 가정
- 동시 센서 실패 개수와 결측 지속 기간에 대한 제약 없음

### 제안 방법: GRIN 아키텍처[1]

GRIN은 양방향 재귀적 구조로 구성되며, 각 방향에서 두 단계의 결측값 대체를 수행합니다.[1]

#### 메시지 패싱 기반 GRU (MP-GRU)[1]

표준 GRU의 게이트를 메시지 패싱 연산자로 구현합니다:[1]

$$
r_t^i = \text{MPNN}(x_t^i \odot (1-m_t^i), h_{t-1}^i, W_t)
$$

$$
u_t^i = \text{MPNN}(x_t^i \odot (1-m_t^i), h_{t-1}^i, W_t)
$$

$$
c_t^i = \tanh(\text{MPNN}(x_t^i \odot (1-m_t^i), r_t^i \odot h_{t-1}^i, W_t))
$$

$$
h_t^i = (1 - u_t^i) \odot h_{t-1}^i + u_t^i \odot c_t^i
$$

여기서 $$r_t^i$$는 리셋 게이트, $$u_t^i$$는 업데이트 게이트, $$h_t^i$$는 은닉 상태입니다.[1]

일반적인 MPNN 정의:[1]

$$
\text{MPNN}(z_t^{i,k-1}, W_t) = \gamma(\phi(z_t^{i,k-1}), \square_{j \in N(i)} \psi(z_t^{i,k-1}, z_t^{j,k-1}))
$$

여기서 $$\phi$$, $$\psi$$는 학습 가능한 함수이고, $$\square$$는 순열 불변 집계 함수(합 또는 평균)입니다.[1]

#### 시공간 인코더[1]

입력 시계열 $$X_{t:T}$$와 마스크 $$M_{t:T}$$를 처리하여 시공간 표현 $$H_{t:T}$$를 생성합니다.[1]

#### 공간적 디코더 - 2단계 결측값 복원[1]

**1단계 결측값 복원**: 선형 읽음층을 통한 일단계 예측[1]

$$
Y_t^1 = H_{t-1}V_h + b_h
$$

**Filler 연산자**: 결측값을 예측값으로 대체[1]

$$
X_t^1 = X_t \odot M_t + Y_t^1 \odot (1-M_t)
$$

**2단계 결측값 복원**: 이웃 노드로부터의 공간 정보를 활용[1]

공간적 복원 표현을 계산하되, **중요한 제약**: 각 노드의 복원 표현은 자신의 입력 특성을 사용하지 않고 이웃 노드의 정보만 사용[1]

$$
s_t^i = \text{MPNN}(h_{t-1}^i, \square_{j \in N(i)} x_t^{1,j} \parallel h_{t-1}^j \parallel m_t^j)
$$

이는 모델이 이웃 노드의 정보에만 집중하도록 강제하는 **정규화 효과**를 제공합니다.[1]

최종 2단계 결측값 복원:[1]

$$
Y_t^2 = [S_t \parallel H_{t-1}]V_s + b_s
$$

$$
X_t^2 = X_t \odot M_t + Y_t^2 \odot (1-M_t)
$$

#### 양방향 모델[1]

전방향(forward)과 후방향(backward) 모듈이 각각 시계열을 처리한 후, 최종 결측값 복원은 다층 퍼셉트론(MLP)으로 두 방향의 표현을 통합합니다:[1]

$$
\hat{x}_t^i = \text{MLP}(s_t^{i,\text{fwd}} \parallel h_{t-1}^{i,\text{fwd}} \parallel s_t^{i,\text{bwd}} \parallel h_{t-1}^{i,\text{bwd}})
$$

***

## 3. 성능 향상 분석

### 벤치마크 데이터셋에서의 성능[1]

| 데이터셋 | 설정 | GRIN | BRITS | 개선율(%) |
|---------|------|------|-------|---------|
| AQI-36 | Out-of-sample | 12.08 MAE | 14.50 | 16.8% |
| AQI | Out-of-sample | 14.73 MAE | 20.21 | 27.1% |
| PEMS-BAY | Block Missing | 1.14 MAE | 1.70 | 32.9% |
| METR-LA | Block Missing | 2.03 MAE | 2.34 | 13.2% |
| CER-E | Point Missing | 0.29 MAE | 0.64 | 54.7% |

GRIN은 모든 벤치마크에서 기존 최고 성능 방법인 BRITS를 능가했습니다. 특히 트래픽 데이터셋에서는 MAE를 최대 **29%** 감소시켰으며, Point Missing 설정에서는 오류를 절반으로 줄였습니다.[1]

### 주요 성능 특성[1]

1. **결측 패턴 강건성**: 블록 결측(Block Missing)과 점 결측(Point Missing) 모두에서 일관된 성능 향상
2. **그래프 구조의 영향**: 완전 연결 그래프(fully connected)나 간선 없는 구조보다 적절한 인접 행렬이 큰 성능 개선을 달성
3. **모델 효율성**: 다른 신경망 기반 방법들(200K vs 4M 파라미터)에 비해 훨씬 적은 파라미터 사용

### 절제 연구(Ablation Study)[1]

| 모델 | AQI | METR-LA | CER-E |
|------|-----|---------|-------|
| GRIN | 14.73 | 2.03 | 0.29 |
| 공간 디코더 제거 | 15.40 | 2.32 | 0.29 |
| 디노이징 디코더 | 17.23 | 2.96 | 0.32 |
| 단방향 MPGRU | 18.76 | 2.57 | 0.41 |

공간적 디코더와 양방향 구조가 특히 블록 결측 설정에서 중요한 역할을 합니다.[1]

***

## 4. 일반화 성능 향상 가능성[1]

### 현재의 일반화 성능 장점[1]

1. **아키텍처 유연성**: GRIN은 가변 입력 차원을 처리할 수 있어 다양한 센서 수에 대응 가능
2. **Inductive Bias의 영향**: 그래프 기반 메시지 패싱은 센서 네트워크의 구조적 특성을 자연스럽게 모델링
3. **가상 센싱(Virtual Sensing)**: 학습 시 없던 센서를 복원할 수 있음을 입증. 센서 1014: MAE 11.74, 센서 1031: MAE 20.00[1]

### 일반화 성능 분석: 데이터 희소성[1]

결측값 비율이 증가해도 성능 유지: 결측율 90%에서도 BRITS(4.02 MAE)보다 GRIN(2.84 MAE)이 우수[1]

### 그래프 구조와 일반화[1]

**고립된 노드에 대한 성능**: GRIN이 BRITS보다 고립된 노드(다른 센서로부터 40km 이상 떨어진 스테이션)에서도 더 나은 성능을 보임. 이는 **공간 디코더의 정규화 효과**가 센서 네트워크 구조를 효과적으로 활용함을 시사[1]

***

## 5. 모델의 한계[1]

### 현재의 주요 한계[1]

1. **정상성 가정**: 데이터가 정상 분포를 따른다고 가정하여 비정상 시계열에 적용 불가
2. **오류 누적**: 자기회귀 모델이므로 장시간 예측에서 오류 누적 가능성
3. **고정 그래프 구조**: 시간에 따라 변하는 센서 관계를 모델링하지 못함
4. **선택적 그래프 구성**: 미리 정의된 인접 행렬에 의존하며, 학습되지 않음

### 확장성 고려사항[1]

계산 복잡성은 표준 양방향 GRU 대비 $$O(|E|)$$ 또는 $$O(N^2)$$ 배수로 증가하지만, 병렬화를 통해 상당 부분 상쇄 가능[1]

---

## 6. 앞으로의 연구에 미치는 영향 및 고려사항

### 논문의 학술적 영향[1]

1. **GNN의 새로운 응용**: 시계열 결측값 복원에 GNN을 처음 체계적으로 적용한 선도적 연구
2. **메시지 패싱의 효과성**: 구조화된 시공간 데이터 처리에 메시지 패싱이 얼마나 효과적인지 입증
3. **Inductive Bias의 중요성**: 도메인 특화 구조적 편향이 딥러닝 모델의 성능을 크게 향상시킬 수 있음을 보여줌

### 향후 연구 방향[1]

논문에서 제시한 미래 연구 방향:
- **이론적 관점**: 정확한 복원을 보장하는 조건에 대한 이론적 분석
- **비정상 설정**: 시간 변동 그래프 위상과 비정상 데이터 처리 확장
- **능동 센싱(Active Sensing)**: 결측값 복원과 함께 최적 센서 배치 결정

### 실제 응용 시 고려사항[1]

1. **그래프 구성 방법**: 센서 간 관계를 효과적으로 표현하는 인접 행렬 설계가 성능에 큰 영향
   - 지리적 거리 기반 커널
   - 피어슨 상관계수
   - 학습 기반 구조(향후 발전 방향)

2. **도메인 적응성**: 
   - 공기질 데이터: 지리적 근접성이 중요
   - 교통 데이터: 도로망 위상이 중요
   - 전력망 데이터: 기능적 유사성이 중요

3. **계산 자원**: 
   - 소규모 센서 네트워크(수백 개): 현실적 실행 시간
   - 대규모 네트워크: 근처 노드만 고려하는 스파스 그래프 구조 권장

4. **데이터 품질**:
   - 센서 오류의 종류(완전 실패 vs 잡음)에 따른 성능 차이 고려
   - 충분한 학습 데이터 확보 필수

***

## 결론

GRIN은 그래프 신경망을 결측값 복원에 적용한 획기적인 연구로, **구조적 정보의 활용**과 **메시지 패싱의 효과성**을 입증했습니다. 특히 센서 네트워크 데이터에서 공간적 종속성을 효과적으로 모델링할 수 있음을 보였으며, 이는 IoT, 스마트 그리드, 교통 네트워크 등 다양한 실제 응용 분야에 즉각 적용 가능합니다. 다만 비정상 데이터, 동적 그래프 구조, 매우 대규모 네트워크로의 확장은 향후 중요한 연구 과제입니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/8ffd0aae-abb9-4ff4-889a-aee12189bde0/2108.00298v3.pdf)
